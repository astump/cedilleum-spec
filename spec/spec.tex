\documentclass{article}


% \usepackage{todonotes}
\usepackage{amsmath,amssymb,amsthm}
%\usepackage{unicode-math}
\usepackage{url}
\usepackage{fullpage}

\usepackage{subcaption}
\usepackage{cedilleverbatim}
\usepackage{proof}

\usepackage{stmaryrd}

\usepackage{soul}
\usepackage{alltt}
% \usepackage{unicode-math}

\DeclareUnicodeCharacter{03BC}{\ensuremath{\mu}}
\DeclareUnicodeCharacter{03B7}{\ensuremath{\eta}}
\DeclareUnicodeCharacter{0393}{\ensuremath{\Gamma}}
\DeclareUnicodeCharacter{21A6}{\ensuremath{\to}}
\DeclareUnicodeCharacter{25CF}{\ensuremath{\bullet}}
\DeclareUnicodeCharacter{1D48C}{\ensuremath{\kappa}}
\DeclareUnicodeCharacter{1D62}{\ensuremath{_{\texttt{D}}}} % maps _i to _d
\DeclareUnicodeCharacter{209A}{\ensuremath{_{\texttt{p}}}}
\DeclareUnicodeCharacter{2C7C}{\ensuremath{_{\texttt{j}}}} % maps _J to _j
\DeclareUnicodeCharacter{2096}{\ensuremath{_{\texttt{k}}}} % maps _J to _j
\DeclareUnicodeCharacter{1D3F}{\ensuremath{^{\texttt{R}}}}
\DeclareUnicodeCharacter{208B}{\ensuremath{_{-}}}
\DeclareUnicodeCharacter{208C}{\ensuremath{_{=}}}
\DeclareUnicodeCharacter{2098}{\ensuremath{_{m}}}
\DeclareUnicodeCharacter{2099}{\ensuremath{_{n}}}
\DeclareUnicodeCharacter{1D64}{\ensuremath{_{\texttt{y}}}}
\DeclareUnicodeCharacter{2093}{\ensuremath{_{x}}}
\DeclareUnicodeCharacter{22EF}{\ensuremath{_{..}}}
\DeclareUnicodeCharacter{2080}{\ensuremath{_0}}
\DeclareUnicodeCharacter{2083}{\ensuremath{_3}}
\DeclareUnicodeCharacter{00B9}{\ensuremath{^1}}
\DeclareUnicodeCharacter{00B2}{\ensuremath{^2}}
\DeclareUnicodeCharacter{20B8}{\ensuremath{\vars{\texttt{t}}}}
\DeclareUnicodeCharacter{015F}{\ensuremath{\vars{\texttt{c}}}}


% useful macros
\newcommand{\ann}[2]{#1\! : \! #2}
\newcommand{\abs}[4]{{#1}\, #2\! : \! #3.\, #4}
\newcommand{\absu}[3]{{#1}\, #2.\, #3}
\mathchardef\mhyph="2D % Define a "math hyphen"
\newcommand{\indast}[5]{\texttt{Ind}_{#1} [#2] (#3 : #4 = #5)}
% inductive-declaration scheme
% μ' scheme, μ scheme
\newcommand{\indsche}[6]{\texttt{Ind}[#1,#2,#3,#4,#5,#6]}
\newcommand{\mupsche}[4]{μ'[#1,#2,#3,#4]}
\newcommand{\musche}[5]{μ[#1,#2,#3,#4,#5]}
\newcommand{\lowerc}[1]{\lfloor {#1} \rfloor}
\newcommand{\lenc}[1]{\|#1\|}
\newcommand{\vars}[1]{{\overline{#1}}}

% - type inference
\newcommand{\decdir}{\vdash_{\delta}}
\newcommand{\decsyn}{\vdash_{\Uparrow}}
\newcommand{\decchk}{\vdash_{\Downarrow}}

% - inductive
\newcommand{\mufix}[3]{μ\ #1\ .\ #2\ \textbf{\{} #3 \textbf{\}}}
\newcommand{\mumat}[2]{μ'\ #1\ \textbf{\{}#2\textbf{\}}}
\newcommand{\wfpat}[4]{WF\!\mhyph\!Pat(#1,#2,#3,#4)}
\newcommand{\llbrace}{\{\!\{}
\newcommand{\rrbrace}{\}\!\}}
\newcommand{\piforall}{^{\Pi}_{\forall}}
\newcommand{\lamLam}{^{\lambda}_{\Lambda}}
\DeclareUnicodeCharacter{03A8}{\ensuremath{\piforall}} % maps Ψ to \piforall
\DeclareUnicodeCharacter{03C8}{\ensuremath{\lamLam}}   % maps ψ to \lamLam
\newcommand{\reduce}{\ensuremath{\rightsquigarrow}}

\newcommand{\difnd}{\ensuremath{di\!f\!f\ }}
\newcommand{\les}{\texttt{\,<:\,}}

\begin{document}

\title{Cedille 1.1.0 Datatype System Specification \\ \large Syntax, Typing, Reduction,
  and Elaboration }

\author{Christopher Jenkins}

\maketitle

\section{Introduction}
\label{sec:intro}
This document describes the datatype subsystem of Cedille, to be introduced in
version 1.1.0. Cedille is programming language with dependent types based on the
\textit{Calculus of Dependent Lambda Eliminations}(CDLE)\cite{St17_CDLE} -- a
compact and Curry-style pure type theory which extends the Calculus of
Constructions (CC)\cite{CH86_CC} with additional typing constructs, and in which
induction for datatypes can be \textit{generically
  derived}\cite{FBS18_Efficient-Mendler} rather than taken as primitive. The
datatype system described in this document provides users of Cedille convenient
access to this generic development by providing high-level syntax for declaring
datatypes and defining functions over them; Cedille can then elaborate these
features to \textit{Cedille Core}\cite{St18_Cedille-Core}, a minimal
implementation of CDLE.

\subsection{Background: CDLE}
\begin{figure}
  \begin{subfigure}{1\linewidth}
    \caption{Novel CDLE type constructs}
    \label{sfig:cdle-kinds}
    \[\small
      \begin{array}{ccc}
        \infer{
         \Gamma\vdash \{ t \simeq t'\} : \star
        }{
         \textit{FV}(|t|\ |t'|)\subseteq \textit{dom}(\Gamma)
        }
        & \infer{
           \Gamma\vdash\abs{\iota}{x}{T}{T'} : \star
          }{
           \Gamma \vdash T : \star \quad \Gamma,x:T\vdash T' : \star
          }
        & \infer{
           \Gamma\vdash\abs{\forall}{x}{T}{T'} : \star
          }{
           \Gamma \vdash T : \star
          \quad \Gamma,x:T\vdash T' : \star
          }
      \end{array}
    \]
  \end{subfigure}
  \begin{subfigure}{1\linewidth}
    \caption{Equality}
    \label{sfig:cdle-eq}
    \[\small
      \begin{array}{cr}
      \begin{array}{cc}
        \infer{
         \Gamma \vdash \beta : \{t ≃ t\}
        }{
         \Gamma \vdash \{t \simeq t\} : \star
        }
        &
          \infer{
           \Gamma\vdash \rho\ t\ @\ x.T\ \mhyph\ t' : [t_1/x]T
          }{
           \Gamma \vdash t : \{ t_1 \simeq t_2 \}
          \quad \Gamma\vdash t' : [t_2/x]T
          }
        \\ \\
          \infer{
           \Gamma \vdash \varphi\ t -\ t_1\ \{t_2\} : T
          }{
           \Gamma \vdash t : \{t_1 ≃ t_2 \}
          \quad \Gamma \vdash t_1 : T
          }
        & \infer{
         \Gamma\vdash \delta\ T - t : T
        }{
         \Gamma\vdash t : \{ \absu{\lambda}{x}{\absu{\lambda}{y}{x}} \simeq
          \absu{\lambda}{x}{\absu{\lambda}{y}{y}}\}
          \quad \Gamma \vdash T : \star
        } 
      \end{array}
        &
          \begin{array}{lll}
            |\beta| & = & \absu{\lambda}{x}{x}
            \\ |\rho\ t\ @\ x.T - t'| & = & |t'|
            \\ |\varphi\ t - t_1\ \{t_2\}| & = & |t_2|
            \\ |\delta\ T - t| & = & |t|
          \end{array}
      \end{array}
    \]
  \end{subfigure}
  \begin{subfigure}{1\linewidth}
    \caption{Dependent Intersection}
    \label{sfig:cdle-depint}
    \[\small
      \begin{array}{cr}
        \begin{array}{c}
          \infer{
          \Gamma\vdash [t_1,t_2] : \abs{\iota}{x}{T_1}{T_2}
          }{
          \Gamma\vdash t_1 : T_1
          \quad \Gamma\vdash t_2 : [t_1/x]T_2
          \quad \Gamma \vdash \abs{\iota}{x}{T_1}{T_2} : \star
          \quad |t_1| = |t_2|
          }
          \\ \\
          \begin{array}{cc}
            \infer{
             \Gamma\vdash t.1 : T_1
            }{
             \Gamma\vdash t : \abs{\iota}{x}{T_1}{T_2}
            }
            &
            \infer{
             \Gamma\vdash t.2 : [t.1/x]T_2
            }{
             \Gamma\vdash t : \abs{\iota}{x}{T_1}{T_2}
            }
          \end{array}
        \end{array}
        &
          \begin{array}{lll}
            |[ t , t' ]| & = & |t|
            \\ |t.1| & = & |t|
            \\ |t.2| & = & |t|
          \end{array}
      \end{array}
    \]
  \end{subfigure}
  \begin{subfigure}{1\linewidth}
    \caption{Implicit Products}
    \label{sfig:clde-imp}
    \[\small
      \begin{array}{cr}
        \begin{array}{cc}
          \infer{
          \Gamma\vdash\abs{\Lambda}{x}{T}{t'} : \abs{\forall}{x}{T}{T'}
          }{
          \Gamma,x:T\vdash t':T'
          \quad x\not\in\textit{FV}(|t'|)
          \quad \Gamma \vdash \abs{\forall}{x}{T}{T'} : \star
          }
          &
            \infer{
            \Gamma\vdash t\ \mhyph t' : [t'/x]T
            }{
            \Gamma\vdash t : \abs{\forall}{x}{T'}{T}
            \quad \Gamma\vdash t' : T'
            }
        \end{array}
        & 
          \begin{array}{lll}
            |\abs{\Lambda}{x}{T}{t}| & = & |t|
            \\ |t\ \mhyph t'| & = & |t|
          \end{array}
      \end{array}
    \]
  \end{subfigure}
  \caption{Kinding, typing, and erasure for a fragment of CDLE}
  \label{fig:cdle-type-constructs}
\end{figure}
We first review CDLE, the type theory of Cedille; a more complete treatment can
be found in \cite{St18_Cedille-Syntax-Semantics}. CDLE is an extension of the
impredicative, Curry-style (i.e. extrinsically typed) Calculus of Constructions
(CC) that adds three new typing constructs: equality of untyped terms ($\{t ≃
t'\}$); the dependent intersection type ($\abs{ι}{x}{T}{T'}$) of
\cite{Ko03_Dependent-Intersection}; and the implicit (erased) product type
($\abs{∀}{x}{T}{T'}$) of \cite{Mi01_ICC}. The pure term language of CDLE is just
that of the untyped $\lambda$-calculus; to make type checking algorithmic,
terms in Cedille are given type annotations, and definitional equality of
terms is modulo erasure of these annotations. The kinding, typing, and erasure
rules for the fragment of CLDE containing these type constructs are given in
Figure \ref{fig:cdle-type-constructs}. We briefly describe these below:

\begin{itemize}
\item $\{t_1 \simeq t_2\}$ is the type of proofs that $t_1$ and $t_2$ are equal
  (modulo erasure). It is introduced with $\beta$ (erasing to
  $\absu{\lambda}{x}{x}$), proving $\{t \simeq t\}$ for any untyped term $t$.
  Combined with definitional equality, $\beta$ can be used to prove $\{t_1 ≃
  t_2\}$ for any $\beta\eta$-convertible $t_1$ and $t_2$ whose
  free variables are declared in the typing context. Equality types can be
  eliminated with $\rho$, $\varphi$, and $\delta$.
  \begin{itemize}
  \item[●] $\rho\ t\ @\ x.T - t'$ (erasing to $|t'|$) rewrites a type
    by an equality: if $t$ proves that $\{t_1 \simeq t_2\}$ and $t'$ has type
    $[t_2/x]T$, then the ρ expression has type $[t_1/x]T$, with the guide $@\
    x.T$ indicating the occurrences of $t_2$ rewritten in the type of
    $t'$.
  \item[●] $\varphi\ t - t_1\ \{t_2\}$ (erasing to $|t_2|$) casts $t_2$ to the
    type of $t_1$  when $t$ proves $t_1$ and $t_2$ equal. 
  \item[●] $\delta\ T\ - t$ (erasing to $|t|$) has type $T$ when $t$ proves that
    Church-encoded \textit{true} equals \textit{false}, enabling a form of proof
    by contradiction. While this is adequate for CDLE, Cedille makes δ more
    practical by implementing the B{\"o}hm-out
    algorithm\cite{Bo68_Bohm-Out} so δ can be used on any proof that $\{t_1 ≃
    t_2\}$ for closed, normalizing, and $\beta\eta$-inconvertible terms $t_1$ and $t_2$.
  \end{itemize}
\item $\abs{\iota}{x}{T}{T'}$ is the type of terms $t$ which can be assigned
  both type $T$ and $[t/x]T'$, and in the annotated language is introduced by
$[t , t']$, where $t$ has type $T$, $t'$ has type $[t/x]T'$, and $|t|
\simeq_{\beta\eta} |t'|$. Dependent intersections are eliminated with
projections $t.1$ and $t.2$, selecting resp. the view that term $t$ has type $T$
or $[t.1/x]T'$
  
\item $\abs{\forall}{x}{T}{T'}$ is the implicit product type, the type of
  functions with an erased argument $x$ of type $T$ 
  and a result of type $T'$. Implicit products are introduced with
  $\abs{\Lambda}{x}{T}{t}$, provided $x$ does not occur in $|t|$, and are
  eliminated with erased application $t\ \mhyph t$. Due to the restriction that
  bound variable $x$ cannot occur in the body $t$ of $\abs{\Lambda}{x}{T}{t}$,
  erased arguments play no computational role and thus exist solely for the
  purposes of typing.
\end{itemize}

Figure \ref{fig:cdle-type-constructs} omits the typing and erasure rules for the
more familiar term and type constructs of CC. When reasoning about definitional
equality of term constructs in CC, all types in type annotations,
quantifications, and applications are erased. Types are quantified over with ∀
within types and abstracted over with Λ in terms, similar to implicit products;
the application of a term $t$ to type $T$ is written $t ·T$, and similarly
application of type $S$ to type $T$ is written $S ·T$. In term-to-term
applications, we omit type arguments when these are inferable from the types of
term arguments.

% The formal specification of Cedille's datatype system as a self-contained
% language feature has a lot in common with CIC -- see in particular Section 8 of
% \cite{In18_Coq-Docs}, which served as the basic template for much of this
% document's formal development.

\subsection{Datatype Declarations}
We begin with a bird's-eye view of the new language features by showing some simple example
data-type definitions and functions over them.

\label{ssec:cedille-standard}
\begin{figure}[h]
  \begin{subfigure}{0.35\linewidth}
\begin{alltt}
data Bool: ★ =
| tt: Bool
| ff: Bool.

data Nat: ★ =
| zero: Nat
| suc: Nat ➔ Nat.
\end{alltt}
  \end{subfigure}%
  \begin{subfigure}{0.4\linewidth}
\begin{alltt}
data List (A: ★): ★ =
| nil: List
| cons: A ➔ List ➔ List.

data Vec (A: ★): Nat ➔ ★ =
| vnil: Vec zero
| vcons: ∀ n: Nat. A ➔ Vec n ➔ Vec (suc n).
\end{alltt}
  \end{subfigure}
  \caption{Example datatype declarations}
  \label{fig:cedille-data-standard}
\end{figure}%
\paragraph{\textbf{Declarations}}
Figure \ref{fig:cedille-data-standard} shows the definitions in Cedille for some
well-known types. Modulo differences in syntax, the general scheme for declaring
datatypes in Cedille should be straightforward to anyone familiar with
GADTs in Haskell or with dependently typed languages like Agda, Coq, or
Idris. Some differences from these languages to note are that:
% some... standard?
\begin{itemize}
\item In constructor types, recursive occurrences of the inductive
  datatype (such as \texttt{\underline{Nat}} in \(\texttt{suc}:
  \texttt{\underline{Nat}} ➔ \texttt{Nat}\) % texttt{suc :
    % \underline{Nat} ➔ Nat})
  must be positive, but \textit{need not be} strictly
  positive.
\item Occurrences of the inductive type being defined are not written applied to
  its parameters. E.g, the constructor \texttt{nil} is written with signature
  \texttt{List} rather than \(\texttt{List} ·A\). Used
  outside of the datatype declaration,
  \texttt{nil} has its usual type: \(\abs{∀}{A}{★}{\texttt{List} ·A}\).
\item Declarations can only refer to the datatype itself and prior
  definitions. Inductive-recursive and inductive-inductive definitions are not
  part of this proposal.
\end{itemize}

\subsection{Function Definitions}
\begin{figure}[h]
\begin{alltt}
pred: Nat ➔ Nat
= λ n. μ' n \{    -- scrutinee: n
  | zero ➔ n    -- case: n is zero
  | suc n' ➔ n' -- case: n is successor to some n'
  \}.

add: Nat ➔ Nat ➔ Nat
= λ m. λ n. μ addN. m \{    -- scrutinee: m, recursive definition: addN
  | zero ➔ n               -- case: m is zero
  | suc m' ➔ suc (addN m') -- case: m is successor to some m'
  \}.

vappend: ∀ A: ★. ∀ m: Nat. ∀ n: Nat. Vec ·A m ➔ Vec ·A n ➔ Vec ·A (add m n)
= Λ A. Λ m. Λ n. λ xs. λ ys. -- explicit motive given below with @
  μ vappendYs. xs @(λ i: Nat. λ x: Vec ·A i. Vec ·A (add i m)) \{
  | vnil ➔             -- expected: Vec ·A n
    ys
  | vcons -m' hd xs' ➔ -- expected: Vec ·A (suc (add m' n))
    vcons -(add m' n) hd (vappendYs -m' xs')
  \}.
\end{alltt}
  \caption{Predecessor, addition, and vector append}
  \label{fig:cedille-standard}
\end{figure}

Figure \ref{fig:cedille-standard} shows a few standard examples of functional
and dependently-typed programming in Cedille. Function \texttt{pred} introduces
operator μ' for \textit{course-of-values (CoV) pattern matching}, which will be
explained in greater detail below. Here it is used for standard pattern
matching: μ' is given scrutinee \texttt{n} of type \texttt{Nat} and a sequence
of case branches for each constructor of \texttt{Nat}. Functions \texttt{add}
and \texttt{vappend} introduce operator μ for \textit{CoV induction} by combined
pattern matching and recursion; the distinction between pattern matching by μ
and μ' will also be made clear below. Here, μ is used for standard structurally
recursive definitions, with \texttt{vappend} showing its use on indexed type
\texttt{Vec} to define recursive function \texttt{vappendYs}, semantically
appending $ys$ to its argument. In the \texttt{vnil} branch, the expected type
is \(\texttt{Vec} ·A\ (\texttt{add}\ \texttt{zero}\ n)\) by the usual index
refinement of pattern matching on indexed types; thanks to the reduction
behavior of \texttt{add} this is convertible with \(\texttt{Vec} ·A\ n\), the
type of \texttt{ys}. Similarly, in the \texttt{vcons} branch the expected type
is \(\texttt{Vec} ·A\ (\texttt{add}\ (\texttt{suc}\ m')\ n)\), convertible with
the type \(\texttt{Vec} ·A\ (\texttt{suc}\ (\texttt{add}\ m'\ n))\) of the body.

\subsection{Reduction Rules of μ and μ'}
In the discussion of \texttt{vappend} above we omitted some details about
checking convertibility of terms defined using μ and μ'. In the \texttt{vcons}
case, the expected type \(\texttt{Vec} ·A\ (\texttt{add}\ (\texttt{suc}\ m')\
n)\) reduces, by β-reduction and erasure alone, to
\begin{alltt}
Vec ·A (μ addN. (suc m') \{zero ➔ n | suc m' ➔ suc (addN m')\})
\end{alltt}

For the length index of this type to be convertible with \(\texttt{suc}\
(\texttt{add}\ m'\ n)\), we need a rule for μ-reduction. μ-reduction is a
combination of fixpoint unrolling and case branch selection. Here, because the
scrutinee is \(\texttt{suc}\ m'\), the case branch selected is the successor
case. The recursive call \(addN\ m'\) that occurs in this branch is replaced (by
substitution on the μ-bound \(addN\)) with another copy of the μ-expression that
defines \texttt{add}. Therefore, the fully normalized type in the \texttt{vcons}
case of \texttt{vappened} is
\begin{alltt}
Vec ·A (suc (μ addN. m' \{zero ➔ n | suc m' ➔ suc (addN m')\}))
\end{alltt}
\noindent which is convertible with the type of the expression given in that branch.

\subsection{Course-of-Value Recursion}
\label{sec:intro-cov}

This section explains \textit{(CoV) pattern matching} in Cedille, which is used
to implement \textit{semantic} (type-based) termination checking and which
facilitates reuse for functions used in ordinary and CoV induction.

The definitions of \texttt{add} and \texttt{vappend} in Figure
\ref{fig:cedille-standard} only require \textit{structural} recursion --
recursive calls are made directly on subdata revealed by one level of pattern
matching. Cedille's datatype system allows programmers to use the much more
powerful form of course-of-values recursion, which allows recursive calls to be
made on arbitrary subdata of a scrutinee. CoV recursion subsumes recursion
subdata produced by a static number of cases analyzed, such as in the case of
\texttt{fib} below:
{
\begin{alltt}
fib: Nat ➔ Nat
= λ n. μ fib. n \{
  | zero ➔ suc zero
  | suc n' ➔ μ' n'. \{| zero ➔ suc zero | suc n' ➔ add (fib n') (fib n'')\}
 \}.
\end{alltt}
}
CoV recursion allows the programmer to recurse on subdata computed
\textit{dynamically}, as well as statically. A good intuitive example is the
definition of division by iterated subtraction. In a Haskell-like language, we
may simply write:
{
\begin{alltt}
0 / d = 0
n / 0 = n
n / d = if (n < d) then zero else 1 + ((n - d) / d)
\end{alltt}
}
This definition is guaranteed to terminate for all inputs, as the first argument
to the recursive call, $n\ \mhyph\ d$, is smaller than the original argument $n$
($d$ is guaranteed to be non-zero). In Cedille, we are able to write a version
of division close to the intuitive way, requiring a few more typing annotations
to enable the termination checker to see that the expression \(n \mhyph d\) is
some subdata of $n$.

\begin{figure}[h!]
\begin{alltt}
predCV: ∀ N: ★. ∀ is: Is/Nat ·N. N ➔ N
= Λ N. Λ is. λ n. μ'<is> n \{| zero ➔ n | suc n' ➔ n'\}.

minusCV: ∀ N: ★. ∀ is: Is/Nat ·N. N ➔ Nat ➔ N
= Λ N. Λ is. λ m. λ n. μ mMinus. n \{
  | zero ➔ m
  | suc n' ➔ predCV -is (mMinus n')
  \}.
minus = minusCV -is/Nat.

lt: Nat ➔ Nat ➔ Bool
= λ m. λ n. μ' (minus (suc m) n) \{| zero ➔ tt | suc r ➔ ff \}.

ite: ∀ X: ★. Bool ➔ X ➔ X ➔ X
= Λ X. λ b. λ t. λ f. μ' b \{| tt ➔ t | ff ➔ f\}.

divide: Nat ➔ Nat ➔ Nat
= λ n. λ d. μ divD. n \{
  | zero ➔ zero
  | suc pn ➔
    [pn' = to/Nat -isType/divD pn] -
    [diff = minusCV -isType/divD pn (pred d)] -
      ite (lt (suc pn') d) zero (suc (divD diff))
  \}.
\end{alltt}
  \caption{Division using course-of-values recursion}
  \label{fig:cov-divide}
\end{figure}

\paragraph{\textbf{CoV Globals}}
We first explain the types and definitions of \texttt{predCV} and
\texttt{minsuCV}. In \texttt{predCV} we see the first use of predicate
\texttt{Is/Nat}. Every datatype declaration in Cedille introduces, in addition
to itself and its constructors, three global names derived from the datatype's
name. For \texttt{Nat}, these are:

\begin{itemize}
\item \(\texttt{Is/Nat}: ★ ➔ ★\)

  A term of type \(\texttt{Is/Nat} ·N\) is a witness that any term of type
  \(N\) may be treated as if has type \texttt{Nat} for the purposes of
  case analysis.

\item \(\texttt{is/Nat} : \texttt{Is/Nat} · \texttt{Nat}\) is the trivial
\texttt{Is/Nat} witness.
\item \(\texttt{to/Nat}: \abs{∀}{N}{★}{\abs{∀}{is}{\texttt{Is/Nat} ·N}{N ➔
      \texttt{Nat}}}\)

  \texttt{to/Nat} is a function that coerces a term of type $N$ to
  \texttt{Nat}, given a witness $is$ that $N$ ``is'' \texttt{Nat}. We will later
  see that \texttt{to/Nat} and all other such cast functions
  elaborate to terms definitionally equal (modulo erasure) to $\absu{λ}{x}{x}$.
  Cedille internalizes this fact: equation
  \(\{\texttt{to/Nat} ≃ \absu{λ}{x}{x}\}\) is true definitionally in the surface
  language. Notice that
  this is possible in part because there is only one \textit{unerased} argument
  to \texttt{to/Nat}. This property is important for CoV induction further on.
\end{itemize}

In \texttt{predCV} the witness $is$ of type \(\texttt{Is/Nat} ·N\) is given
explicitly to μ' with the notation \(μ'\texttt{<}is\texttt{>}\), allowing
argument $n$ (of type $N$) to be a legal scrutinee for \texttt{Nat} pattern
matching. Reasoning by parametricity, the only ways \texttt{predCV} can produce
an $N$ output (i.e, preserve the abstract type) are by returning
$n$ itself or some subdata produced by CoV pattern matching on it -- the
predecessor $n'$ also has type $N$. Thus, the type signature of \texttt{predCV}
has the following intuitive reading: it produces a number no larger than its
argument, as an expression like \(\texttt{suc}\ (\texttt{to/Nat}\ \mhyph is\
n)\) would be type-incorrect to return.

\paragraph{\textbf{Code Reuse}}
What is the relation is between \texttt{predCV}
and the earlier \texttt{pred} of Figure \ref{fig:cedille-standard}? The fully
annotated \texttt{μ'}-expression of the latter is:
{
\begin{alltt}
μ'<is/Nat> n @(λ x: Nat. Nat) \{| zero ➔ n | suc n' ➔ n'\}
\end{alltt}
}
\noindent In \texttt{pred}, the global witness \texttt{is/Nat} of type
\(\texttt{Is/Nat} ·\texttt{Nat}\) need not be passed explicitly, as it is
inferable\footnote{The same holds for the inferability of the local witness
(discussed below) introduced in the body of \texttt{fib}.} by the type
\texttt{Nat} of the scrutinee $n$. Furthermore, the erasures of \texttt{pred}
and \texttt{predCV} are definitionally equal, a fact provable in Cedille (where
\_ indicates an anonymous proof):
{
\begin{alltt}
_ : \{pred ≃ predCV\} = β.
\end{alltt}
}

This leads to a style of programming where, when possible, functions are defined
over an abstract type $N$ for which e.g. \(\texttt{Is/Nat} ·N\) holds, and the
usual version of the functions \textit{reuse} these as a special case. Indeed, this is how
\texttt{minus} is defined -- in terms of the more general \texttt{minsuCV} specialized
to the trivial witness \texttt{is/Nat}. The type signature of \texttt{minsuCV}
yields a similar reading that it produces a result no
larger than its first argument. In the successor case, \texttt{predCV} is invoked
and given the (erased) witness \texttt{is}. That \texttt{minsuCV} preserves the
type of its argument after \texttt{n} uses of \texttt{predCV} is precisely what
allows it to appear in expressions given as arguments to recursive functions.
Function \texttt{minus} is used to define \texttt{lt}, the Boolean predicate
deciding whether its first argument is less than its second; \texttt{ite} is the
usual definition of a conditional expression by case analysis on \texttt{Bool}.

\paragraph{\textbf{CoV Locals}}
The last definition, \texttt{divide}, is as expected except for the successor
case. Here, we make a let binding (the syntax for which in Cedille is \([x = t]
- t'\), analogous to \(\texttt{let}\ x = t\ \texttt{in}\ t'\)) for $pn'$, the
coercion to \texttt{Nat} of the predecessor of the dividend $pn$ (using the
as-yet unexplained \texttt{Is/Nat} witness \texttt{isType/divD}), and for
\difnd, the difference (using \texttt{minsuCV}) between $pn$ and \(\texttt{pred}\
d\). Note that when $d$ is non-zero, \difnd is equal to the different between
the dividend and divisor, and otherwise it is equal to $pn$; in both cases, it
is smaller than the original pattern \(\texttt{suc}\ pn\). Finally, we test
whether the dividend is less than the divisor: if so, return \texttt{zero}, if
not, divide \difnd by $d$ and increment. The only parts of \texttt{divide}
requiring further explanation, then, are the witness \texttt{isType/divD} and the
type of $pn$, which are the keys to CoV recursion and induction in Cedille.

Within the body of the μ-expression defining recursive function
\texttt{divD} over scrutinee $n$ of type \texttt{Nat}, the following
names are automatically bound:
\begin{itemize}
\item \(\texttt{Type/divD}: ★\), the type of recursive occurrences of \texttt{Nat}
  in the types of variables bound in constructor patterns (such as $pn$).
\item \(\texttt{isType/divD}: \texttt{Is/Nat} ·\texttt{Type/divD}\), a witness that terms of the
  recursive-occurrence type may used for further CoV pattern matching.
\item \(\texttt{divD}: \texttt{Type/divD} ➔ \texttt{Nat}\),
  the recursive function being defined, accepting only terms of the
  recursive occurrence type \texttt{Type/divD}. This restriction guarantees that
  \texttt{divD} is only called on expressions smaller than the previous
  argument to recursion.
\end{itemize}

The reader is now invited to revisit the definitions of Figure
\ref{fig:cedille-standard}, keeping in mind that in the μ-expressions of
\texttt{add} and \texttt{vappend} constructor subdata $m'$ and $xs'$
in pattern guards \(\texttt{suc}\ m'\) and \(\texttt{vcons}\ \mhyph m'\ hd\ xs'\)
have abstract types (the subdata of the successor case of the
μ'-expression of \texttt{pred} has the usual type \texttt{Nat}), and
that recursive definitions \texttt{addN} and \texttt{vappendYs} only accept
arguments of such a type. With this understood, so to is the definition
\texttt{divide}: predecessor $pn$ has type \texttt{Type/divD}, witness
\texttt{isType/divD} has type \texttt{Is/Nat ·Type/divD} and so the local
variable \difnd has type \texttt{Type/divD}, exactly as required by
\texttt{divD}.


\subsection{Course-of-values Induction}
CoV recursion is not enough -- in a dependently typed language, one also wishes
sometimes to \textit{prove} properties of recursive definitions. Cedille enables
this with \textit{CoV induction}, which we explain with an example proof below.
Figure \ref{fig:cov-induction} shows its use in \texttt{leDiv} to prove that the
result of division is no larger than its first argument.

\begin{figure}[h]
\begin{alltt}
data LE: Nat ➔ Nat ➔ ★ =
  | leZ: Π n: Nat. LE zero n
  | leS: Π n: Nat. Π m: Nat. LE n m ➔ LE (suc n) (suc m).

leTrans: Π l: Nat. Π m: Nat. Π n: Nat. LE l m ➔ LE m n ➔ LE l n = <..>
leMinus: Π m: Nat. Π n: Nat. LE (minus m n) m = <..>

leDiv: Π n: Nat. Π d: Nat. LE (divide n d) n
  = λ n. λ d. μ leDiv. n @(λ x: Nat. LE (divide x d) x) \{
  | zero ➔ leZ zero
  | suc pn ➔
    [pn' = to/Nat -isType/leDiv pn] -
    [diff = minus pn' (pred d)] -
    [l = divide diff d] -
      μ' (lt (suc pn') d) @(λ x: Bool. LE (ite x zero (suc l)) (suc pn')) \{
      | tt ➔ leZ (suc pn')
      | ff ➔
        [ih: LE l diff   = leDiv (minus' -isType/leDiv pn (pred d))] -
        [mi: LE diff pn' = leMinus pn' (pred d)] -
          leS l pn' (leTrans l diff pn' ih mi)
      \}
  \}.
\end{alltt}
  \caption{Example of course-of-values induction}
  \label{fig:cov-induction}
\end{figure}

We first encode the relation ``less than or equal'' as a datatype \texttt{LE}
and prove two properties of it (definitions omitted, indicated by
\texttt{<..>}): that it is transitive (\texttt{leTrans}) and that
\texttt{minus} produces a result less than or equal to its first argument
(\texttt{leMinus}). In the proof of \texttt{leDiv} itself, we define a
recursive function (also named \texttt{leDiv}) over $n$. When it is
zero, the goal becomes \(\texttt{LE}\ \texttt{zero}\ \texttt{zero}\), provable
by constructor \texttt{leZ}. When it is the successor of some number $pn$, the
expression \(\texttt{divide}\ (\texttt{suc}\ pn')\ d\) in the type of the goal
reduces to a conditional branch on whether the dividend is less than the
divisor. We use μ' to match on the result of \(\texttt{lt}\ (\texttt{suc}\
pn')\ d\) to determine which branch is reached: if it is true, the
goal type reduces further to \(\texttt{LE}\ \texttt{zero}\ (\texttt{suc}\
pn')\), which is again provable by \texttt{leZ}; otherwise, the goal is
\(\texttt{LE}\ (\texttt{suc}\ l)\ (\texttt{suc}\ pn')\), where $l$ is defined
as \difnd divided by $d$.
\underline{Here is where CoV induction is used}: to define $ih$ we invoke the inductive hypothesis
on \(\texttt{minus'}\ \mhyph \texttt{isType/leDiv}\ pn\ (\texttt{pred}\ d)\), a term that is equal (modulo
erasure) to \difnd but has the required abstract type
\texttt{Type/leDiv}, letting us prove \(\texttt{LE}\ l\ \difnd\). We combine this and a
proof of \(\texttt{LE}\ \difnd\ pn'\) (bound to $mi$) with the proof
that \texttt{LE} is transitive, producing a proof that \(\texttt{LE}\ l\ pn'\). The
the final obligation \(\texttt{LE}\ (\texttt{suc}\ l)\ (\texttt{suc}\ pn')\)
is proved by constructor \texttt{leS}.

\subsection{Subtyping and Coercions}
\label{sec:subtyping-coercion}
\begin{figure}[h]
\begin{alltt}
mult : Nat ➔ Nat ➔ Nat
= λ m. λ n. μ multN. m \{
| zero ➔ zero
| suc m ➔ add n (multN m)
\}.

fact1 : Nat ➔ Nat
= λ n. μ fact. n \{
| zero ➔ suc zero
| suc m ➔
  mult (suc (to/Nat -isType/fact m)) (fact m)
\}.

-- not yet supported
fact2 : Nat ➔ Nat
= λ n. μ fact. n \{
| zero ➔ suc zero
| suc m ➔ mult (suc m) (fact m)
\}.
\end{alltt}
  \caption{Factorial with explicit and implicit coercions}
  \label{fig:ex-data-fact}
\end{figure}

In the preceding code examples, every time we wished to use some term of the
abstract recursive-occurrence type (such as \texttt{Type/divD} in
\texttt{divide}) as if it had the concrete datatype (such as \texttt{Nat}), we
explicitly cast the term (using e.g. \texttt{to/Nat}). We now take a moment to
describe a feature we desire to implement in the near future: automatic
inference of these coercions via subtyping. As an example, we provide two
different implementations of the function factorial in Figure
\ref{fig:ex-data-fact}: \texttt{fact1} using an explicit cast and \texttt{fact2}
where these would be inferred.

In the successor case of \texttt{fact1}, we know that the number we are
considering is equal to the \texttt{suc}cessor of another number $m$. We wish to
multiply \(suc\ m\) with the factorial of $m$. However, μ provides access to the
subdata $m$ at an abstract type; this allows $m$ to be a legal argument for a
recursive call as in \(\texttt{fac}\ m\), but not as an argument to constructor
\texttt{suc} which requires a \texttt{Nat}. Thus, in order to multiply the two
expressions, we first cast $m$ to \texttt{Nat} using the CoV global cast function
\texttt{to/Nat} and CoV local evidence \texttt{isType/fact} (of type
\(\texttt{Is/Nat} ·\texttt{Type/fact}\)).

Alternatively, we should be able to infer this coercions by equipping type
inference with a form of \textit{subtyping}. In the successor case of
\texttt{fact2} (which is currently not a legal Cedille definition), when we see
that the expected type of $m$ is \texttt{Nat}, and its actual type is
\texttt{Type/fact}, we could search the typing context for evidence of type
\(\texttt{Is/Nat} ·\texttt{Type/fact}\) and, finding this in the form of
\texttt{isType/fact}, accept this definition.

\begin{figure}[h]
\begin{alltt}
data PTree: ★ =
  | leaf: PTree
  | node: ((PTree ➔ Bool) ➔ PTree) ➔ PTree.

indPTree1 : ∀ P: PTree ➔ ★.
  P leaf ➔ (∀ s: (PTree ➔ Bool) ➔ PTree. (Π p: PTree ➔ Bool. P (s p)) ➔ P (node s)) ➔
  Π t: PTree. P t
= Λ P. λ l. λ n. λ t. μ ih. t @(λ x: PTree. P x) \{
  | leaf ➔ l
  | node s ➔
    [s1 : (PTree ➔ Bool) ➔ Type/ih = λ p. s (λ t. p (to/PTree -isType/ih t))]
  - [s2 : (PTree ➔ Bool) ➔ PTree   = λ p. to/PTree -isType/ih (s1 p)]
  - n -s2 (λ p. ih (s1 p))
  \}.

-- not yet implemented
indPTree2 : ∀ P: PTree ➔ ★.
  P leaf ➔ (∀ s: (PTree ➔ Bool) ➔ PTree. (Π p: PTree ➔ Bool. P (s p)) ➔ P (node s)) ➔
  Π t: PTree. P t
=  Λ P. λ l. λ n. λ t. μ ih. t @(λ x: PTree. P x) \{
| leaf ➔ l
| node s ➔ n -s (λ p. ih (s p))
\}.
\end{alltt}
  \caption{Subtyping for a non-strictly positive type}
  \label{fig:ptree}
\end{figure}

The story becomes more complex in the presence of non-strictly positive
datatypes. Figure \ref{fig:ptree} presents a definition of \texttt{PTree}, an
infinitary tree which a non-strict positive recursive occurrence in the
\texttt{node} constructor, and two proofs of induction for it, one using
explicit coercions and one utilizing subtyping to infer these coercions. As a
type, \texttt{PTree} is a somewhat contrived example, but one intuition for what
kind of terms inhabit it is ``at a \texttt{node}, there must be some way of
selecting some sub-tree using a predicate \texttt{PTree ➔ Bool}''.

In both versions, the branch given by pattern \texttt{leaf} corresponds to the
given assumption $l$ proving \(P\ \texttt{leaf}\). In the \texttt{node} case of
\texttt{indPTree1}, the expected type is \(P\ (\texttt{node}\ s)\). The
pattern-bound variable $s$ has type \((\texttt{Type/ih} ➔ \texttt{Bool}) ➔
\texttt{Type/ih}\), and the two different occurrences of $s$ in the arguments to
the assumed proof $n$ require casting $s$ to two different types, corresponding
to the two explicit type coercions of $s$ locally bound to $s1$ and $s2$ (note
that these two expressions are $β\eta$-convertible with $s$).

In the \texttt{node} case of \texttt{indPTree2}, the two occurrences of $s$ in
the arguments to $n$ correspond to two subtyping problems:
\begin{itemize}
\item \((\texttt{Type/ih} ➔ \texttt{Bool}) ➔ \texttt{Type/ih}\ \les\ (\texttt{PTree} ➔
  \texttt{Bool}) ➔ \texttt{PTree}\)
\item \((\texttt{Type/ih} ➔ \texttt{Bool}) ➔ \texttt{Type/ih}\ \les\ (\texttt{PTree} ➔
  \texttt{Bool}) ➔ \texttt{Type/ih}\)
\end{itemize}

Such subtyping problems can solved algorithmically and the necessary coercions
to the desired type inserted automatically.

\subsection{Program Reuse}
\label{sec:zc-reuse}
We conclude our informal introduction to Cedille's datatype system with a
somewhat more complex example: how to support program reuse over different
data-types at zero run-time cost. For datatypes encoded as λ-terms in Cedille,
it is possible that some constructor between the two types are definitionally
equal. For example, for λ-encoded \texttt{List} and \texttt{Vec} constructors
\texttt{nil} (\texttt{cons}) and \texttt{vnil} (\texttt{vcons}) are indeed equal
modulo erasure. When Cedille elaborates the \textit{declared
  datatypes} \texttt{List} and \texttt{Vec}, this correspondence also holds.
Cedille's datatype system internalizes this fact, meaning
the declared constructors \texttt{nil} (\texttt{cons}) and \texttt{vnil}
(\texttt{vcons}) are \textit{themselves definitionally equal}. This is
shown in the following example with manual zero-cost reuse of
\texttt{map} for \texttt{List} in \texttt{vmap} for \texttt{Vec}.

\begin{figure}[h]
\begin{alltt}
len: ∀ A: ★. List ·A ➔ Nat = <..>
map: ∀ A B: ★. (A ➔ B) ➔ List ·A ➔ List ·B = <..>

v2l: ∀ A: ★. ∀ n: Nat. Vec ·A n ➔ List ·A
  = Λ A. Λ n. λ xs. μ v2l. xs \{
  | vnil ➔ nil ·A
  | vcons -n' hd tl ➔ cons hd (v2l -n' tl)
  \}.

l2v: ∀ A: ★. Π xs: List ·A. Vec ·A (len xs)
  = Λ A. λ xs. μ l2v. xs @(λ x: List ·A. Vec ·A (len x)) \{
  | nil ➔ vnil ·A
  | cons hd tl ➔ vcons -(len (to/List -isType/l2v tl)) hd (l2v tl)
  \}.
\end{alltt}
  \caption{\texttt{len}, \texttt{map}, and linear-time conversion between
    \texttt{List} and \texttt{Vec}}
  \label{fig:cedille-list}
\end{figure}

\paragraph{\textbf{Manual zero-cost reuse of \texttt{map} for \texttt{vmap}}}
Figure \ref{fig:cedille-list} gives the definitions of the linear-time
conversion functions \texttt{v2l} and \texttt{l2v}, as well as the types for
list operations \texttt{len} and \texttt{map} (\texttt{List} is given in Figure
\ref{fig:cedille-data-standard}, \texttt{<..>} and \texttt{\_} indicate resp.
an omitted def. and anonymous proof). First, and as promised, Cedille
considers the corresponding constructors of \texttt{List} and \texttt{Vec}
definitionally equal: 
{
\begin{alltt}
_ : \{nil  ≃ vnil\}  = β.
_ : \{cons ≃ vcons\} = β.
\end{alltt}
}%
This means that the linear-time functions \texttt{v2l} and \texttt{l2v} merely
return a term equal to their argument at a different type. Indeed, this is
provable in Cedille by easy inductive proofs \texttt{vl2Id} and \texttt{l2vId}
(Figure \ref{fig:cedille-convert-int}), rewriting the expected branch type by ρ
(Figure \ref{sfig:cdle-eq}) in the \texttt{cons} and \texttt{vcons} cases using
the inductive hypothesis and making implicit use of constructor equality. Thanks
to $\varphi$ (casting a term to the type of another it is proven equal to, Figure
\ref{sfig:cdle-eq}), these proofs give rise to coercions \texttt{v2l!} and
\texttt{l2v!} between \texttt{List} and \texttt{Vec} that erase to identity
functions -- meaning there is no performance penalty for using them! By
notational convention, identifiers suffixed with the bang (!) character indicate
zero-cost coercions between types.

With \texttt{v2l!} and \texttt{l2v!} and the two lemmas \texttt{mapPresLen} and
\texttt{v2lPresLen} resp. stating that \texttt{map} and \texttt{v2l!} preserve
the length of their inputs, we can now define \texttt{vmap} (Figure
\ref{fig:cedille-vmap}) over \texttt{Vec} by reusing \texttt{map} for
\texttt{List} with no run-time cost, demonstrating that Cedille's datatype
system does not prevent use of this desirable property derived in its core
theory CDLE.

\begin{figure}[h]
  \small
\begin{alltt}
v2lId: ∀ A: ★. ∀ n: Nat. Π vs: Vec ·A n. \{v2l vs ≃ vs\}
  = Λ A. Λ n. λ vs. μ v2lId. vs @(λ i: Nat. λ x: Vec ·A i. \{v2l x ≃ x\}) \{
  | vnil ➔ β
  | vcons -i hd tl ➔ ρ (v2lId -i tl) @ x. \{cons hd x ≃ vcons hd tl\} - β
  \}.

l2vId: ∀ A: ★. Π ls: List ·A. \{l2v ls ≃ ls\}
  = Λ A. λ ls. μ l2vId. ls @(λ x: List ·A. \{l2v x ≃ x\}) \{
  | nil ➔ β
  | cons hd tl ➔ ρ (l2vId tl) @ x. \{vcons hd x ≃ cons hd tl\} - β
  \}.

v2l!: ∀ A : ★. ∀ n: Nat. Π vs: Vec ·A n. List ·A
  = Λ A. Λ n. λ vs. φ (v2lId -n vs) - (v2l -n vs) \{vs\}.
_ : \{v2l! ≃ λ vs. vs\} = β.

l2v!: ∀ A: ★. Π ls: List ·A. Vec ·A (len ls)
  = Λ A. λ ls. φ (l2vId ls) - (l2v ls) \{ls\}.
_ : \{l2v! ≃ λ ls. ls\} = β.
\end{alltt}
  \caption{Zero-cost conversions between \texttt{Vec} and \texttt{List}}
  \label{fig:cedille-convert-int}
\end{figure}

\begin{figure}[h]
\small
\begin{alltt}
mapPresLen: ∀ A: ★. ∀ B: ★. Π f: A ➔ B. Π xs: List ·A. \{len xs ≃ len (map f xs)\} = <..>
v2lPresLen: ∀ A: ★. ∀ n: Nat. Π xs: Vec ·A n. \{n ≃ len (v2l! -n xs)\} = <..>

vmap: ∀ A B: ★. ∀ n: Nat. (A ➔ B) ➔ Vec ·A n ➔ Vec ·B n
  = Λ A B n. λ f xs. ρ (v2lPresLen -n xs) - ρ (mapPresLen f (v2l! -n xs))
  - l2v! (map f (v2l! -n xs)).
_ : \{vmap ≃ map\} = β.
\end{alltt}
  \caption{Zero-cost reuse of \texttt{map} for \texttt{Vec}}
  \label{fig:cedille-vmap}
\end{figure}

\paragraph{\textbf{Definitional Equality of Constructors}}
Under what conditions should users expect Cedille to equate constructors of
different datatypes? Certainly they should \textit{not} be required to know the
details of elaboration to use features like zero-cost reuse that depend
on this. Fortunately, there is a simple, high-level explanation for when
different constructors are considered equal that makes reference only to the
shape of the datatype declaration. We give this here informally, with
the formal statement and soundness property given in the technical portion of
this document.

If $c$, $c{'}$ are resp. constructors of
datatype $D$ and $D'$, then $c$ and $c{'}$ are equal iff:
\begin{itemize}
\item $D$ and $D{'}$ have the same number of constructors;
\item the index of $c$ in the list of constructors for $D$ is the same as
  the index of $c{'}$ in the list of constructors for $D'$; and
\item $c$ and $c{'}$ take the same number of unerased arguments
\end{itemize}

That these three conditions hold for the corresponding constructors of
\texttt{List} and \texttt{Vec} is readily verified: both datatypes have two
constructors; \texttt{nil} (\texttt{cons}) and \texttt{vnil} (\texttt{vcons})
are each the first (second) entries in their datatype's constructor list; and
\texttt{nil} and \texttt{vnil} take no arguments while \texttt{cons} and
\texttt{vcons} take two unerased argument (the \texttt{Nat} argument to
\texttt{vcons} is erased). It is clear also these conditions
prohibit two different constructors of the same datatype from ever being
equated, as their index in the constructor list would necessarily be different.

This scheme for equating data constructors perhaps leads to some
counter-intuitive results. First, changing the order of the constructors of
\texttt{List} prevents zero-cost reuse between it and \texttt{Vec}. Second,
between two datatypes with the same number of constructors, some constructors
may be equal and others not. For example, \texttt{List} and \texttt{Nat} have
two constructors, and the first of both takes no arguments. Thus, equality
between \texttt{zero} and \texttt{nil} holds definitionally, but is not possible for
\texttt{suc} and \texttt{cons}. The very same phenomenon occurs for e.g.
Church-encoded numbers and lists.

\section{Syntax}
\label{sec:syntax}

\paragraph{Identifiers}
\begin{figure}[h]
  \[
    \begin{array}{llll}
      id & &
      & \textnormal{identifiers for definitions}
      \\ u & &
      & \textnormal{term variables}
      \\ c & &
      & \text{constructors}
      \\ X,Y,Z,R & &
      & \textnormal{type variables}
      \\ 𝒌 & &
      & \textnormal{kind variables}
      \\ x & ::= & id\ |\ u\ |\ X\
      & \textnormal{non-kind variables}
      \\ y & ::= & x\ |\ 𝒌 & \text{all variables}
    \end{array}
  \]
  \caption{Identifiers}
  \label{fig:identifiers}
\end{figure}

We now turn to a more formal treatment of Cedilleum. Figure
\ref{fig:identifiers} gives the metavariables used in our grammar for
identifiers. For convenience we consider all identifiers as coming from two
distinct lexical ``pools'' -- regular identifiers (consisting of identifiers
$id$ given for modules and definitions, term variables $u$, and type variables
$X$) and kind identifiers $\kappa$. In Cedilleum source files (as in the parent
language Cedille) kind variables should be literally prefixed with $\kappa$ --
the suffix can be any string that would by itself be a legal non-kind
identifier. For example, \texttt{myDef} is only legal as term and type
identifier, and \texttt{𝒌myDeff} is only legal as a kind identifier.

\paragraph{Untyped Terms}
\begin{figure}[h]
  \[
    \begin{array}{llll}
      f, p
      & ::= & u,v
      & \text{variables}
      \\ & & \absu{\textbf{λ}}{u}{p}
      & \text{functions}
      \\ & & c
      & \text{constructors}
      \\ & & f\ p
      & \text{applications}
      \\ & & \mufix{u}{p}{c_i\ \vars{a_i} ➔ p_i}_{i=1..n}
      & \text{recursive definitions}
      \\ & & \mumat{p}{c_i\ \vars{a_i} ➔ p_i}_{i=1..n}
      & \text{case analysis}
    \end{array}
  \]
  \caption{Untyped terms}
  \label{fig:pure-terms}
\end{figure}

The grammar of pure (untyped) terms that of the untyped λ-calculus augmented
with primitive μ for combined pattern-matching and fixpoint recursion and μ' for
``mere'' pattern-matching.

\begin{figure}[h]
  \[
    \begin{array}{llll}
      % module stuff
      \\ mod
      & ::= & \textbf{module}\ id\ \textbf{.}\ imprt^*\ cmd^*\
      & \textnormal{module declarations}
      \\ imprt
      & ::= & \textbf{import}\ id\ \textbf{.}
      & \textnormal{module imports}
      \\ cmd
      & ::= & defTermOrType
      & \textnormal{definitions}
      \\ & & defDataType
      \\ & & defKind
      % definitions
      \\ 
      \\ defTermOrType
      & ::= & id\ checkType^?\ \textbf{=}\ t\ \textbf{.}
      & \textnormal{term definition}
      \\ & & id\ \textbf{:}\ K\ \textbf{=}\ T\ \textbf{.}
      & \textnormal{type definition}
      \\ defKind
      & ::= & 𝒌\ \textbf{=}\ K
      & \text{kind definition}
      \\ defDataType
      & ::= & \textbf{data}\ id\ param^*\ \textbf{:}\ K\ \textbf{=}\
              constr^*\ \textbf{.}
      & \textnormal{datatype definitions}
     % auxilliary categories for definitions
      \\ 
      \\ checkType
      & ::= & \textbf{:}\ T
      & \textnormal{annotation for term definition}
      \\ param
      & ::= & \textbf{(}x\ \textbf{:}\ C \textbf{)}
      \\ constr
      & ::= & \textbf{\textbar}\ id\ \textbf{:}\ T
    \end{array}
  \]
  \caption{Modules and definitions}
  \label{fig:mods-defs}
\end{figure}

\paragraph{Modules and Definitions}
All Cedilleum source files start with production $mod$, which consists of a module
declaration, a sequence of import statements which bring into scope definitions
from other source files, and a sequence of \textit{commands} defining terms,
types, and kinds. As an illustration, consider the first few lines of a
hypothetical \texttt{list.ced}:

\begin{verbatim}
module list .

import nat .
\end{verbatim}
% TODO it also searches all ancestor directories
\noindent Imports are handled first by consulting a global options files
known to the Cedilleum compiler (on *nix systems \verb|~/.cedille/options|)
containing a search path of directories, and next (if that fails) by searching
the directory containing the file being checked.

Term and type definitions are given with an identifier, a classifier (type or
kind, resp.) to check the definition against, and the definition. For term
definitions, giving classifier (i.e. the type) is optional. As an example,
consider the definitions for the type of Church-encoded lists and two variants
of the nil constructor, the first with a top-level type annotation and the
second with annotations sprinkled on binders:

\begin{verbatim}
cList : ★ ➔ ★
      = λ A : ★ . ∀ X : ★ . (A ➔ X ➔ X) ➔ X ➔ X .

cNil  : ∀ A : ★ . cList · A
      = Λ A . Λ X . λ c . λ n . n .
cNil' = Λ A : ★ . Λ X : ★ . λ c : A ➔ X ➔ X . λ n : X . n .
\end{verbatim}

Kind definitions are given without classifiers (all kinds have super-kind
$\Box$), e.g. \verb;𝒌func = ★ ➔ ★;

Inductive datatype definitions take a set of \textit{parameters} (term and type
variables which remain constant throughout the definition) well as a set of
\textit{indices} (term and type variables which can vary in constructor type
signatures), followed by zero or more constructors. Each constructor begins with
``\textbf{\textbar}'' (though the grammar can be relaxed so that the first of
these is optional) and then an identifier and type is given. As an example,
consider the following two definitions for lists and vectors (length-indexed
lists).

\begin{verbatim}
data Bool : ★ =
  | tt : Bool
  | ff : Bool
  .
data Nat : ★ =
  | zero : Nat
  | suc  : Nat ➔ Nat
  .
data List (A : ★) : ★ =
  | nil  : List
  | cons : A ➔ List ➔ List
  .
data Vec (A : ★) : Nat ➔ ★ =
  | vnil  : Vec zero
  | vcons : ∀ n: Nat. A ➔ Vec n ➔ Vec (succ n)
  .
\end{verbatim}

\paragraph{Types and Kinds}
\begin{figure}[h]
  \[
    \begin{array}{rlll}
      \text{Sorts } \mathcal{S}
      & ::= & \square & \text{sole super-kind}
      \\ & & K & \text{kinds}
      \\ \text{Classifiers } C
      & ::= & K & \text{kinds}
      \\ & & T & \text{types}
      \\ \text{Kinds } K
      & ::= & \textbf{Π}\ x\ \textbf{:}\ C\ \textbf{.}\ K
      & \textnormal{explicit product}
      \\ & & C\ \textbf{➔}\ K
      & \textnormal{kind arrow}
      \\ & & \textbf{★}
      & \text{the kind of types that classify terms}
      \\ 
      \\ \text{Types } S,T,P
      & ::= & \textbf{Π}\ x\ \textbf{:}\ T\ \textbf{.}\ T'
         & \textnormal{explicit product}
      \\ & &  \textbf{∀}\ x\ \textbf{:}\ C\ \textbf{.}\ T'
         & \textnormal{implicit product}
      \\ & &  \textbf{λ}\ x\ \textbf{:}\ C\ \textbf{.}\ T'
         & \textnormal{type-level function}
      \\ & & T\ \textbf{➾}\ T'
         & \textnormal{arrow with erased domain}
      \\ & & T\ \textbf{➔}\ T'
         & \textnormal{normal arrow type}
      \\ & & T\ \textbf{·}\ T'
         & \text{application to another type}
      \\ & & T\ t
         & \text{application to a term}
      \\ & & \textbf{\{}\ p\ ≃\ p' \textbf{\}}
                      & \textnormal{untyped equality}
      % \\ & & \textbf{ι}\ x: T.\ T'
      %                 & \textnormal {dependent intersection}
      \\ & & X
         & \text{type variable}
    \end{array}
  \]
  \caption{Kinds and types}
  \label{fig:kinds-types}
\end{figure}

In Cedilleum, the expression language is stratified into three main ``classes'':
kinds, types, and terms. Kinds and types are listed in Figure
\ref{fig:kinds-types} and terms are listed in Figure \ref{fig:ann-terms} along
with some auxiliary grammatical categories. In both of these figures, the
constructs forming expressions are listed from lowest to highest precedence --
``abstractors'' ($\lambda\ \Lambda\ \Pi\ \forall$) bind most loosely and
parentheses most tightly. Associativity is as-expected, with arrows (➔ ➾) and
abstractors being right-associative and applications being left-associative.

% TODO cite
The language of kinds and types is similar to that found in the Calculus of
Implicit Constructions\footnote{Cite}. Kinds are formed by dependent and
non-dependent products (Π and ➔) and a base kind for types which can classify
terms (★). Types are also formed by the usual (dependent and non-dependent)
products (Π and ➔) and also \textit{implicit} products (∀ and ➾) which quantify
over erased arguments (that is, arguments that disappear at run-time).
Π-products are only allowed to quantify over terms as all types occurring in
terms are erased at run-time, but ∀-products can quantify over types
\textit{and} terms because terms can be erased. Meanwhile, non-dependent
products (➔ and ➾) can only ``quantify'' over terms because non-dependent type
quantification does not seem particularly useful. Besides these, Cedilleum
features type-level functions and applications (with term and type arguments),
and a primitive equality type for untyped terms. Last of all is the ``hole''
type (●) for writing partial type signatures or incomplete type applications.
There are term-level holes as well, and together the two are intended to help
facilitate ``hole-driven development'': any hole automatically generates a type
error and provides the user with useful contextual information.

We illustrate with another example: what follows is a module stub for
\textbf{DepCast} defining dependent casts -- intuitively, functions from $a : A$
to $B\ a$ that are also equal\footnote{Module erasure, discussed below} to
identity -- where the definitions \texttt{CastE} and \texttt{castE} are
incomplete.

\begin{verbatim}
module DepCast .

CastE ◂ Π A : ★ . (A ➔ ★) ➔ ★ = ● .
castE ◂ ∀ A : ★ . ∀ B : A ➔ ★ . CastE · A · B ➾ Π a : A . B a = ● .
\end{verbatim}
  
\paragraph{Annotated Terms}
\begin{figure}[h]
  \[
    \begin{array}{rlll}
      \text{Subjects } s
      & ::= & t & \text{term}
      \\ & & T & \text{type}
      \\ \text{Terms } t
      & ::= & \absu{λ}{x}{t}
      & \textnormal{normal abstraction}
      \\ & & \absu{Λ}{x}{t}
      & \textnormal{erased abstraction}
      \\ & & \textbf{[}\ defTermOrType\ \textbf{]}\ \textbf{-}\ t
      & \text{let definitions}
      \\ & & \textbf{ρ}\ t\ @ x.T\ \textbf{-}\ t'
      & \text{equality elimination by rewriting}
      \\ & & \varphi\ t\ \textbf{-}\ t'\ \textbf{\{} t'' \textbf{\}}
      & \text{type cast}
      \\ & & \textbf{χ}\ T\ \textbf{-}\ t
      & \text{check a term against a type}
      \\ & & \textbf{δ}\ \textbf{-}\ t
      & \text{ex falso quodlibet}
      \\ & & t\ t'
      & \text{applications}
      \\ & & t\ \textbf{-}t'
      & \text{application to an erased term}
      \\ & & t\ \textbf{·}T
      & \text{application to a type}
      \\ & & \textbf{β}\ 
      & \textnormal{reflexivity of equality}
      \\ & & \mufix{u}{t\ @P}{c_i\ \vars{a_i} ➔ t_i}_{i=1..n}
      & \textnormal{recursive definitions}
      \\ & & \mumat{t\ @P}{case^*}
      & \text{auxiliary pattern match}
      \\ & & u
      & \text{term variable}
      \\ & & \textbf{(}t\textbf{)}
      \\ & & \bullet
      \\ \\ case
      & ::= & \textbf{\textbar}\ c\ vararg^*\ \textbf{↦}\ t
      & \text{pattern-matching cases}
      \\ vararg
      & ::= & u
      & \text{normal constructor argument}
      \\ & & \textbf{-}u
      & \text{erased constructor argument}
      \\ & & \textbf{·}X
      & \text{type constructor argument}
      \\ class
      & ::= & \textbf{:}\ C
      \\ motive
      & ::= & \textbf{@}\ T
      & \textnormal{motive for induction}
    \end{array}
  \]
  \caption{Annotated Terms}
  \label{fig:ann-terms}
\end{figure}

Terms can be explicit and implicit functions (resp. indicated by λ and Λ) with
optional classifiers for bound variables, let-bindings, applications $t\ t'$,
$t\ \mhyph t'$, and $t\ \cdot T$ (resp. to another term, an erased term, or a
type). In addition to this there are a number of useful operators for
equaltional reasoning, type casting, providing annotations, and pattern
matching. Each operator will be discussed in more detail in Section
\ref{sec:type-system}, but a few concrete programs in Cedilleum are given below
merely to give a better idea of the syntax of the language.

\begin{verbatim}
isvnil : ∀ A: ★. ∀ n: Nat. Vec ·A n ➔ Bool
       = Λ A. Λ n. λ xs. μ' xs @(Λ n . λ xs . Bool) {
           | vnil          ↦ tt
           | vcons -n x xs ↦ ff
           }.
vlength : ∀ A: ★. ∀ n: Nat. Vec ·A n ➔ Nat
        = Λ A. Λ n. λ xs. μ len . xs @(Λ n . λ x . Nat) {
            | vnil          ↦ zero
            | vcons -n x xs ↦ suc (len -n xs)
            }.
\end{verbatim}

\section{Erasure and Reduction}

\begin{figure}[h]
  \[
  \begin{array}{lll}
       |x| & = & x 
    \\ |\star| & = & \star 
    \\ |\Box| & = & \Box 
    \\ |\beta\ \{t\}| & = & |t|
    \\ |\delta\ t| & = & |t|
    \\ |\chi\ T^? \textbf{-}\ t| & = & |t| 
    \\ |\varsigma\ t| & = & |t|
    \\ |t\ t'| & = & |t|\ |t'|
    \\ |t\ \mhyph t'| & = & |t| 
    \\ |t\ \cdot T| & = & |t| 
    \\ |\rho\ t\ \mhyph\ t'| & = & |t'| 
    \\ |\abs{\forall}{x}{C}{C'}| & = & \abs{\forall}{x}{|C|}{|C'|}
    \\ |\abs{\Pi}{x}{C}{C'}| & = & \abs{\Pi}{x}{|C|}{|C'|}
    \\ |\abs{\lambda}{u}{T}{t}| & = &  \absu{\lambda}{u}{|t|} 
    \\ |\absu{\lambda}{u}{t}| & = &  \absu{\lambda}{u}{|t|} 
    \\ |\abs{\lambda}{X}{K}{C}| & = &  \abs{\lambda}{X}{|K|}{|C|} 
    \\ |\abs{\Lambda}{x}{C}{t}| & = &  |t| 
    \\ |\phi\ t\ \mhyph\ t'\ \{t''\}| & = & |t''| 
    \\ |[ x = t : T]|\ \mhyph\ t' | & = & (\absu{\lambda}{x}{|t'|})\ |t|
    \\ |[X = T : K]\ \mhyph\ t | & = & |t| 
    \\ |\{ t \simeq t' \}|| & = & \{ |t| \simeq |t'| \}
    \\ |\mufix{u,}{t\ motive^?}{case^*}|
           & = & \mufix{u}{|t|}{|case^*|}
    \\ |\mumat{t\ motive^?}{case^*}|
           & = & \mumat{|t|}{|case^*|}
    \\ \\ |id\ vararg^* \mapsto t| & = & id\ |vararg^*|\ \mapsto |t|
    \\ 
    \\ |\mhyph u| & = & 
    \\ |\cdot X|  & = &
  \end{array}
  \]
  \caption{Erasure for annotated terms}
  \label{fig:eraser}
\end{figure}

The definition of the erasure function given in Figure \ref{fig:eraser} takes
the annotated terms from Figures \ref{fig:kinds-types} and \ref{fig:ann-terms}
to the untyped terms of Figure \ref{fig:pure-terms}. The last two equations
indicate how the sequence of variables ($varargs$) bound by a constructor
pattern are erased. The additional constructs introduced in the annotated term
language such as β, φ, and ρ, are also all erased to the language of pure terms.

Reduction rules are defined for the untyped term language. In essence, to run a
Cedilleum program you first erase it, then reduce it. Full conversion in
Cedilleum is defined as the compatible closure of $\reduce\ =\ \reduce_{\beta}
\bigcup \reduce_{\mu'} \bigcup \reduce_{\mu}$

\paragraph{$\beta$-reduction}
\[ (\absu{\lambda}{x}{p_1})\ p_2 \reduce_{\beta} [p_2/x]p_1 \]

The rule for $\beta$-reduction is standard: those expressions consisting of a
$\lambda$-abstraction as the left component of an application reduce by having
their bound variable substituted away by the given argument (where $[p_2/x]$ is
the simultaneous and capture-avoiding substitution of $p_2$ for $x$)

\paragraph{$\mu'$-reduction}
\[ \mu'\ (c_i\ p_1 ... p_n)\ \{...\ | c_i\ u_1 ... u_n \mapsto f\ |...\}
  \reduce_{\mu'} [p_1 ... p_n/u_1 ... u_n]f\]

$\mu'$-reduction is a simple pattern-matching reduction rule: if the scrutinee
of $\mu'$ is some variable-headed application $c_i\ p_1 ... p_n$ where the head
$c_i$ matches one of the branch patterns, replace the entire expression with the
branch body $f$ after substituting each of the bound variables of the branch
pattern $u_1 ... u_n$ with the scrutinee's arguments $p_1 ... p_n$

\paragraph{$\mu$-reduction}
\[
  \mu\ u. (c_k\ \vars{t})\ \{ c_i\ \vars{x_i} \mapsto f_i\}_{i=1..n} \reduce_{\mu}
  [p_{\mu}/u][\vars{t/x_k}]\ f_k\
\]
\noindent where $p_{\mu} = \absu{\lambda}{v}{\mu\ u. v \{c_i\ \vars{x_i} \mapsto f_i\}_{i=1..n}}$
\\ 
% \[ \infer[\mu]
%   { \mu\ u. (c\ p_1 ... p_n)\ \{ c_i\ u_{i1} ... u_{ij_i} \mapsto f_i
%     \}_{i=1..n} \reduce_{\mu} [p_1 ... p_n/u_1 ... u_n][u/p_{\mu}]f}
%   {
%     \exists i.\ c\!=\!c_i \land j_i\!=\!n
%     \quad p_{\mu} = \absu{\lambda}{v}{\mu\ u.\ v\ \{c_i\ u_{i1} ... u_{ij_i}
%       \mapsto f_i\}_{i=1..n}}
%   }
% \]

$\mu$-reduction is similar to $\mu'$-reduction, but combines with it fixpoint
reduction. Again, if the scrutinee $c\ p_1 ... p_n$ matches one of the branch
patterns $c_i\ u_{i1} ... u_{ij_i}$ (for some $i$, where $j_i = n$), then we
replace the original $\mu$ expression with the matched branch, replacing each of
the pattern variables $u_1 ... u_n$ with the scrutinee's arguments $p_1 ...
p_n$, but \textit{in addition} we also replace the $\mu$-bound variable $u$
(which represents the entire $\mu$ expression itself) with a function $p_\mu$
that takes its argument $v$ and re-creates the original $\mu$ expression by
scrutinizing $v$.

\section{Type System (sans Inductive Datatypes)}
\label{sec:type-system}

\begin{figure}[h]
  \caption{Contexts}
  \[
    \begin{array}{llll}
      \text{ Typing contexts } \Gamma
      & ::= & \emptyset\ |\ \ann{x}{C},\Gamma\ |\ \ann{x=s}{C},\Gamma
    \end{array}
  \]
\end{figure}
\begin{figure}[h!]
  \[ \small
    \begin{array}{lcr}
      \infer{\Gamma\vdash \star : \Box}{\ }
      & \infer
        { \Gamma\vdash\abs{\Pi}{y}{C}{C'} : S'}
        { \Gamma \vdash C : S
        \quad
        \Gamma,y:C\vdash C' : S'
        }
      & \infer
        {\Gamma\vdash\abs{\forall}{y}{C}{C'} : \star}
        {\Gamma \vdash C : S
        \quad \Gamma,y:C\vdash C' : \star
%        \quad \textit{Var}(y,S)
        }
      \\
      \\ \infer
      { \Gamma \vdash \{p \simeq p' \} : \star}
      { FV(p\ p') \subseteq dom(\Gamma) }
      & \infer
        { \Gamma \vdash \kappa : \Gamma(\kappa)}
        { }
      & \infer
        { \Gamma \vdash X : \Gamma(X)}
        { }
      \\
      \\ \infer
      { \Gamma \vdash \abs{\lambda}{x}{C}{T} : \abs{\Pi}{x}{C}{K}}
      { \Gamma \vdash \abs{\Pi}{x}{C}{K} : \square
      \quad \Gamma, \ann{x}{C} \vdash T : K
      }
      & \infer
        { \Gamma \vdash T\ \cdot T' : [T'/x] K'}
        { \Gamma \vdash T : \abs{\Pi}{x}{K}{K'}
        \quad \Gamma \vdash T' : K}
      & \infer
       { \Gamma \vdash T\ t : [t/x] K}
        { \Gamma \vdash T : \abs{\Pi}{x}{T'}{K}
        \quad \Gamma \decchk t : T' }
    \end{array}
  \]
  \caption{Sort checking \fbox{$\Gamma \vdash C : S$}}
  \label{fig:sort-checking}
\end{figure}

\begin{figure}[h!]
  \[ \small
    \begin{array}{lcr}
      \infer
      { \Gamma \decdir u : \Gamma(u)}{}
      & \infer
        { \Gamma \decdir \abs{\lambda}{x}{T}{t} : \abs{\Pi}{x}{T}{T'}}
        { \Gamma \vdash T : K
        \quad \Gamma, \ann{x}{T} \decdir t : T'}
      & \infer
        { \Gamma \decchk \absu{\lambda}{x}{t} : \abs{\Pi}{x}{T}{T'}}
        { \Gamma, \ann{x}{T} \decchk t : T'}
      \\
      \\ \infer
      { \Gamma \decdir \abs{\Lambda}{x}{C}{t} : \abs{\forall}{x}{C}{T}}
      { \Gamma \vdash C : S
      \quad x \notin FV(|t|)
      \quad \Gamma, \ann{x}{C} \decdir t : T
      }
      & \infer
        { \Gamma \decchk \absu{\Lambda}{x}{t} : \abs{\forall}{x}{C}{T}}
        { x \notin FV(|t|)
        \quad \Gamma, \ann{x}{C} \decdir t : T
        }
      & \infer
        { \Gamma \decdir t\ t' : [t'/x]T}
        { \Gamma \decsyn t : \abs{\Pi}{x}{T'}{T}
        \quad \Gamma \decchk t' : T'}
      \\
      \\ \infer
      { \Gamma \decdir t\ \cdot T : [T/X]T'}
      { \Gamma \decsyn t : \abs{\forall}{X}{K}{T'}
      \quad \Gamma \vdash T : K}
      & \infer
        { \Gamma \decdir t\ \mhyph t' : [t'/x]T}
        { \Gamma \decsyn t : \abs{\forall}{x}{T'}{T}
        \quad \Gamma \decchk t' : T'}
      & \infer % conversion... maybe needs to include phi and rho now?
        { \Gamma \decchk t : T }
        { \Gamma \decsyn t : T'
          & |T'| =_{\beta} |T| }
      \\ \\ \infer
      { \Gamma \decdir [ id : T = t ]\ \mhyph\ t' : T'}
      { \Gamma \vdash T : K
        & \Gamma \decchk t : T
        & \Gamma, \ann{id = t}{T} \decdir t' : T'}
      & \infer
        { \Gamma \decdir [ id = t]\ \mhyph\ t' : T' }
        { \Gamma \decsyn t : T
          & \Gamma, \ann{id = t}{T} \decdir t' : T'
        }
      & \infer[\footnotemark] % TODO
        { \Gamma \decdir \rho\ t\ \mhyph\ t' : [t_2/x]\ T}
        { \Gamma \decsyn t : \{ t_1 \simeq t_2 \}
          & \Gamma \decsyn t' : [t_1/x]\ T
        }
      \\ \\ \infer
      { \Gamma \decdir [ id : K = T ]\ \mhyph\ t' : T'}
      { \Gamma \vdash K : \square
        & \Gamma \vdash T : K
        & \Gamma, \ann{id = T}{K} \decdir t' : T'}
      & \infer
        { \Gamma \decchk \beta \{t\} : \{ t' \simeq t' \}}
        { \Gamma \vdash \{ t' \simeq t' \} : \star }
      & \infer
        { \Gamma \decdir \varsigma\ t : \{ t_2 \simeq t_1 \} }
        { \Gamma \decdir t : \{ t_1 \simeq t_2 \}}
      \\ \\ \infer
      { \Gamma \decdir \phi\ t\ \mhyph\ t_1\ \{t_2\} : T}
      { \Gamma \decchk t : \{ |t_1| \simeq |t_2| \}
        & \Gamma \decdir t_1 : T}
      & \infer
        { \Gamma \decsyn \chi\ T\ \mhyph\ t : T }
        { \Gamma \decchk t : T }
      & \infer[\footnotemark]
        { \Gamma \decchk \delta\ \mhyph\ t : T }
        { \Gamma \decchk t : \{ \texttt{tt}\ \simeq\ \texttt{ff} \}}
    \end{array}
  \]
  \caption{Type checking \fbox{$\Gamma \decdir s : C$} (sans inductive datatypes)}
  \label{fig:type-checking}
\end{figure}
\footnotetext{Where we assume $t$ does not occur anywhere in $T$}
\footnotetext{Where $\texttt{tt} = \absu{\lambda}{x}{\absu{\lambda}{y}{x}}$ and
  $\texttt{ff} = \absu{\lambda}{x}{\absu{\lambda}{y}{y}}$}
% TODO kind-variables... two different rules or Var check?
% TODO equality, now that it can have rho, phi

The inference rules for classifying expressions in Cedilleum are stratified into
two judgments. Figure \ref{fig:sort-checking} gives the uni-directional rules
for ensuring types are well-kinded and kinds are well-formed. Future versions of
Cedilleum will allow for bidirectional checking for both typing \textit{and}
sorting, allowing for a unification of these two figures. Most of these rules
are similar to what one would expect from the Calculus of Implicit
Constructions, so we focus on the typing rules unique to Cedilleum.

The typing rule for ρ shows that ρ is a primitive for rewriting by an (untyped)
equality. If $t$ is an expression that synthesizes a proof that two terms $t_1$
and $t_2$ are equal, and $t'$ is an expression synthesizing type $[t_1/x]\ T$
(where, as per the footnote, $t_1$ does not occur in $T$), then we may
essentially rewrite its type to $[t_2/x]\ T$. The rule for β is reflexivity for
equality -- it witnesses that a term is equal to itself, provided that the type
of the equality is well-formed. The rule for ς is symmetry for equality.
Finally, φ acts as a ``casting'' primitive: the rule for its use says that if
some term $t$ witnesses that two terms $t_1$ and $t_2$ are equal, and $t_1$ has
been judged to have type $T$, then intuitively $t_2$ can also be judged to have
type $T$. (This intuition is justified by the erasure rule for φ -- the
expression erases to $|t_2|$). The last rule involving equality is for δ, which
witnesses the logical principle \textit{ex falso quodlibet} -- if a certain
impossible equation is proved (namely that the two Church-encoded booleans
\texttt{tt} and \texttt{ff} are equal), then \textit{any} type desired is
inhabited. The remaining primitive χ allows the user to provide an
explicit top-level annotation for a term.

\section{Inductive Datatypes}
\label{sec:ind-data}

While the grammatical rule $defDataType$ gives the concrete syntax for datatype
definitions, it is not a very useful notation for representing and manipulating
such an object in the AST. We begin this section, then, by describing a more
concise syntax for datatype definitions. The notation used in this section
borrows heavily from the conventions of the Coq documentations
\footnote{https://coq.inria.fr/refman/language/cic.html\#inductive-definitions}.
One additional abuse of notation we shall use heavily throughout the remainder
of this document is for application and abstraction of a sequence of terms and
types. If $\Gamma$ is an ordered context binding term and type variables, then

\begin{itemize}
\item $t\ \Gamma$ and $T\ \Gamma$ represent the application of term $t$ (resp.
  type $T$) to each variable in $\Gamma$ in order of appearance. The erasure
  modality of the application -- that is, for each variable $x$ in $\Gamma$,
  whether it is passed as a relevant or irrelevant argument to $t$ -- will
  always be disambiguated by the type of term $t$ (there is no erased
  application at the type level).
\item $\absu{\lamLam}{\Gamma}{t}$ and $\absu{\lambda}{\Gamma}{T}$ represents a
  sequence of abstractions at the term (resp. type) level, followed by term $t$
  (resp. type $T$). At the term level, the appropriate abtraction (erased or
  unerased) is determined by the expected type of the expression and the sort
  of the variable (e.g. at the term level all types are abstracted over erased).
\end{itemize}

\subsection{Representation of Datatype Definition in AST}

Notation $\indsche{I}{\Gamma_P}{\Gamma_K}{R}{\Sigma}{\Gamma_G}$ represents a declaration of
an inductive datatype named $I$ where:
\begin{itemize}
\item $\Gamma_P$ is the context of parameters;
\item $\Gamma_K$ binds the indices of type $I$; that is to say type $I\ \Gamma_P$ has kind
  $Π\ \Gamma_K: ★$;
\item $R$ is a (fresh) type variable of kind $Π\ \Gamma_K. ★$, serving as a placeholder for
  recursive occurrences of the inductively defined type in the type signatures
  of the data constructors;
\item $\Sigma$ is the context associating constructors with their type
  signatures;
\item $\Gamma_G$ binds additional fresh (automatically generated) identifiers in
  the global context which help enable CoV induction -- more on this below.
\end{itemize}

For example, the datatype declaration for \texttt{Vec} in the concrete syntax:
\begin{verbatim}
data Vec (A: ★): Nat ➔ ★ =
  | vnil  : Vec zero
  | vcons : ∀ n: Nat. A ➔ Vec n ➔ Vec (succ n)
  .
\end{verbatim}

corresponds to the following object in the abstract syntax:
\[
  \indsche{\texttt{Vec}}{\ann{\texttt{A}}{★}}{\texttt{Π n:Nat.★}}{\texttt{R}}{\Sigma}{\Gamma_G}
\]
\noindent where
\[
  \begin{array}{lcl}
    \Sigma
    & =
    & \begin{array}{lcl}
        \texttt{vnil} & : & \texttt{∀A:★.Vec ·A zero}
        \\ \texttt{vcons} & : & \texttt{∀A:★.∀n:Nat.A ➔ R n ➔ Vec ·A (S n)}
      \end{array}
    \\ \\ \Gamma_G
    & =
    & \begin{array}{lcl}
        \texttt{Is/Vec} & : & \texttt{Π A: ★. (Nat ➔ ★) ➔ ★}
        \\ \texttt{is/Vec} & : & \texttt{∀ A:★. Is/Vec ·A ·(Vec ·A)}
        \\ \texttt{to/Vec} & : & \texttt{∀ A:★. ∀ R: Nat ➔ ★.Is/Vec ·A ·R ➾ ∀ n:Nat.R n ➔ Vec ·A n}
        \\                 & = & \texttt{λ x.x}
      \end{array}
  \end{array}
\]

\noindent In the above definition for $\Gamma_G$, understand that
\begin{itemize}
  \item \texttt{Is/Vec} is an automatically-generated type of ``witnesses''
    that some type can be pattern-matched upon just like \texttt{Vec} can; this
    is exists to support CoV induction
  \item \texttt{is/Vec} is the (trivial) witness that \texttt{Vec} behaves like
    \texttt{Vec} as far as pattern-matching is concerned
  \item \texttt{to/Vec} is a coercion from some type \texttt{R} to \texttt{Vec ·A},
    provided there is an \texttt{Is/Vec ·A ·R} witness.

    This coercions is ``zero-cost'' in the sense that it is defined to be equal
    to \texttt{λx.x}
\end{itemize}

The purposes of these global definitions will become more clear when we give a
formal treatment of μ (combined fixpoint and pattern-matchin) and μ' (``mere''
pattern matching) below.

\subsection{Well-formedness of Datatype Definition}
For an inductive datatype definition
$\indsche{I}{\Gamma_P}{\Gamma_K}{R}{\Sigma}{\Gamma_G}$ to be well-formed, it must satisfy
the following conditions:

\begin{itemize}
\item $I$ must have (well-formed) kind $\absu{\Pi}{\Gamma_P}{\absu{\Pi}{\Gamma_K}{★}}$

  Ensuring this is trivial from the concrete syntax
\item The type $T$ of each constructor $\ann{c}{T} \in \Sigma$ must be a \textit{type of
    constructor of I} (c.f. Section \ref{ssec:inductive-aux-defs})
\item The type $T$ of each constructor $\ann{c}{T} \in \Sigma$ must satisfy the (non-strict)
  positivity condition for $R$ (c.f. Section \ref{ssec:inductive-aux-defs})
\item $\Gamma_G$ must bind precisely the following (these are added to the
  global context):
  \begin{itemize}
  \item \texttt{Is/$I$: Π $\Gamma_P$. K ➔ ★}

    The name bound here is literally the string concatenation of
    ``\texttt{Is/}'' with the user-given name for the data-type $I$
  \item \texttt{is/$I$: ∀ $\Gamma_P$. Is/$I$ $\Gamma_P$ ·$(I$ $\Gamma_P)$}
  \item \texttt{to/$I$: ∀ $\Gamma_P$. ∀ R: K. Is/$I$ $\Gamma_P$ R ➾ ∀
      $\Gamma_K$. R $\Gamma_K$ ➔ $I\ \Gamma_P\ \Gamma_K$ = λ x.x}
  \end{itemize}

  Collision with user-given definitions is avoided by prohibiting such
  user-supplied names from having the character ``\texttt{/}'' present.
\end{itemize}

We will write judgment $\indsche{I}{\Gamma_P}{\Gamma_K}{R}{\Sigma}{\Gamma_G}\ wf$
to indicate that a datatype declaration is well-formed.

\subsection{Fixpoint-style recursion and Pattern Matching}
Similarl to datatype declarations, the notation used in the concrete syntax of
Cedilleum for μ (for combined fixpoint recursion and pattern matching) and μ'
(for mere pattern matching) is inconveneient. In the AST we will represent a μ'
expression as
\[
  \mupsche{t_s}{w}{P}{\vars{t}}
\]
\noindent where
\begin{itemize}
\item $t_s$ is the scrutinee for case analysis;
\item $w$ is the witness that $t_s$ is valid for case-analysis
\item $P$ is the motive for (dependent) pattern matching;
\item $\vars{t}$ are the case branches;
\end{itemize}

For a simple example, the μ'-expression in the body of predecessor in Figure
\ref{fig:ex-data-div}, \texttt{predCV}, would be represented as
\[
  \mupsche{\texttt{r}}{\texttt{muWit}}{\texttt{λx:Nat.R}}{
    \texttt{r}, \texttt{λp.p}
  }
\]

μ-expressions are represented in the AST as
\[
  \musche{x_μ}{t_s}{P}{\Gamma_L}{\vars{t}}
\]
\noindent where
\begin{itemize}
\item $x_{μ}$ is the name given for the function being defined in fixpoint style
\item $t_s$ is the scrutinee for case-analysis and whose recursive subdata will
  recursed upon
\item $P$ is the motive for (dependent) pattern-matching
\item $\vars{t}$ are the case branches
\item $\Gamma_L$ are (automatically generated) definitions in-scope of the case
  branches
\end{itemize}

As an example, in the definition of subtraction in Figure
\ref{fig:ex-data-div}, \texttt{minsuCV}, the μ-expressions would be represented
as
\[
  \musche{\texttt{rec}}{\texttt{n}}{\Gamma_L}{\texttt{λn:Nat.R}}
  {\begin{array}{c}
     \texttt{m}
     \\ \texttt{λ n'.predCV -muWit (rec n')}
   \end{array}
    }
\]
\noindent where
\[
  \begin{array}{lcl}
    \Gamma_P
    & =
    & \begin{array}{lcl}
        \texttt{Type/rec} & : & ★
        \\ \texttt{isType/rec} & : & \texttt{Is/Nat ·Type/rec}
        \\ \texttt{rec} & : & \texttt{Πx:Type/rec. rec/Type}
      \end{array}
  \end{array}
\]
\noindent which is to say that μ introduces a fresh type \texttt{Type/rec}, a
witness \texttt{isType/rec} that terms of this type can be further case
analysed, and binds recursive function (inductive hypothesis) \texttt{rec} which
can operate only on terms of the appropriate (recursive) type.

\subsection{Well-formedness of μ- and μ'-expressions}

\subsection{Auxiliary Definitions}
\label{ssec:inductive-aux-defs}

\paragraph{Contexts}
To ease the notational burden, we will introduce some conventions for writing
contexts within terms and types.

\begin{itemize}
\item We write $\lambda\,\Gamma$, $\Lambda\,\Gamma$, $\forall\,\Gamma$, and
  $\Pi\,\Gamma$ to indicate some form of abstraction over each variable in
  $\Gamma$. For example, if $\Gamma = \ann{x_1}{T_1},\ann{x_2}{T_2}$ then
  $\absu{\lambda}{\Gamma}{t} =
  \abs{\lambda}{x_1}{T_1}{\abs{\lambda}{x_2}{T_2}{t}}$. Additionally, we
  will also write $\piforall\,\Gamma$ to indicate an arbitrary mixture of $\Pi$
  and $\forall$ quantified variables. Note that \textit{if $\piforall\,\Gamma$
  occurs multiple times within a definition or inference rule}, the intended
  interpretation is that \textit{all occurrences have the same mixture of $\Pi$
    and $\forall$ quantifiers}.
\item $\lenc{\Gamma}$ denotes the length of $\Gamma$ (the number of variables it
  binds)
\item We write $s\ \Gamma$ to indicate the sequence of variable arguments in
  $\Gamma$ given as arguments to $s$. Implicit in this notation is the removal
  of typing annotations from the variables $\Gamma$ when these variables are
  given as arguments to $s$.

  Since in Cedilleum there are three flavors of applications (to a type, to an
  erased term, and to an unerased term), we will only us this notion when the type
  or kind of $s$ is known, which is sufficient to disambiguate the flavor of
  application intended for each particular binder in $\Gamma$. For example,
  if $s$ has type
  $\abs{\forall}{X}{★}{\abs{\forall}{x}{X}{\abs{\Pi}{x'}{X}{X}}}$ and $\Gamma =
  \ann{X}{★},\ann{x}{X},\ann{x'}{X}$ then $s\ \Gamma = s\ \cdot X\ \mhyph x\ x'$
\item $\Delta$ and $\Delta'$ are notations we will use
  for a specially designated contexts associating type variables with both global
  ``concrete'' and local ``abstracted'' inductive data-type declarations.
  The purpose of this latter sort of declaration is to enable type-guided
  termination of definitions using fixpoints (see Section \ref{ssec:typing-rules}) For example, given
  just the (global) data type declaration of $Vec$, we would have $\Delta(Vec) =
  \indast{\text{C}}{1}{\Gamma_{Vec}}{\Sigma}$, where $\Gamma_{Vec} = \ann{Vec}{★ ➔ Nat ➔
    ★}$ and  $\Sigma$ binds data constructors $vnil$ and $vcons$ to the
  appropriate types.
\end{itemize}

\paragraph{$p$-arity}

A kind $K$ is a $p$-arity if it can be written as $\absu{\Pi}{\Gamma}{K'}$ for
some $\Gamma$ and $K'$, where $\lenc{\Gamma} = p$. For an inductive definition
$\indast{M}{p}{\Gamma_I}{\Sigma}$, requiring that the kind $\Gamma_{I}(I)$ is a $p$-arity
of ★ ensures that $I$ \textit{really does have} $p$ parameters.

\paragraph{Types of Constructors}
% TODO: if you look at the `generation of abstracted inductive definitions', it
% uses a different format for the types associated with the constructors in
% \Sigma -- that is the \piforall notation. This section probably should be
% reworked to that end.
$T$ is a \textit{type of a constructor of $I$} iff
\begin{itemize}
\item it is $I\ s_1 ... s_n$
\item it can be written as $\abs{\forall}{s}{C}{T}$ or $\abs{\Pi}{s}{C}{T}$,
  where (in either case) $T$ is a type of a constructor of $I$
\end{itemize}

\paragraph{Positivity condition}
The positivity condition is defined in two parts: the positivity condition of
a type $T$ of a constructor of $I$, and the positive occurence of $I$ in $T$.
We say that a type $T$ of a constructor of $I$ satisfies the positivity condition
when

\begin{itemize}
\item $T$ is $I\ s_1... s_n$ and $I$ does not occur anywhere in $s_1...s_n$
\item $T$ is $\abs{\forall}{s}{C}{T'}$ or $\abs{\Pi}{s}{C}{T'}$, $T'$ satisfies
  the positivity condition for $I$, and $I$ occurs \textit{only} positively in $C$ 
\end{itemize}

\noindent We say that $I$ occurs only positively in $T$ when
\begin{itemize}
\item $I$ does not occur in $T$
\item $T$ is of the form $I\ s_1 ... s_n$ and $I$ does not occur in $s_1 ...
  s_n$
\item $T$ is of the form $\abs{\forall}{s}{C}{T'}$ or $\abs{\Pi}{s}{C}{T'}$, $I$
  occurs only positively in $T'$, and $I$ \textit{does not} occur positively in $C$
\end{itemize}

\subsection{Well-formed inductive definitions}
\label{ssec:inductive-wf-def}

Let $\Gamma_{\text{P}},\Gamma_I,$ and $\Sigma$ be contexts such that $\Gamma_I$
associates a single type-variable $I$ to kind $\absu{\Pi}{\Gamma_{\text{p}}}{K}$ and
$\Sigma$ associates term variables $c_1 ... c_n$ with corresponding types
$\absu{\forall}{\Gamma_{\text{P}}}{T_{1}},...\absu{\forall}{\Gamma_{\text{P}}}{T_{n}}$.
Then the rule given in Figure \ref{fig:inductive-intro} states when an inductive
datatype definition may be introduced, provided that the following side
conditions hold:

\begin{figure}[h]
  \caption{Introduction of inductive datatype}
  \label{fig:inductive-intro}
  \[
    \infer
    { \indast{M}{p}{\Gamma_I}{\Sigma}\ wf}
    { \emptyset \vdash \Gamma_I(I) : \square
      \quad \lenc{\Gamma_P} = p
      \quad (\Gamma_I,\Gamma_P \vdash T_i : ★)_{i=1..n}
    }
  \]
\end{figure}

\begin{itemize}
  \item Names $I$ and $c_1..c_n$ are distinct from any other inductive datatype
    type or constructor names, and distinct amongst themselves
  \item Each of $T_1..T_n$ is a type of constructor of $I$ which satisfies the
    positivity condition for $I$. Furthmore, each occurence of $I$ in $T_i$ is
    one which is applied to the parameters $\Gamma_P$.
  \item Identifiers $I$, $c_1,...,c_n$ are fresh w.r.t the global context, and
    do not overlap with each other nor any identifiers in $\Gamma_P$.
\end{itemize}

When an inductive data-type has been defined using the $defDataType$ production,
it is understood that this always a concrete inductive type, and it (implicitly)
adds to a global typing context the variable bindings in $\Gamma_I$ and
$\Sigma$. Similarly, when checking that the kind $\Gamma_I(I)$ and type $T_i$
are well-sorted and well-kinded, we assume an (implicit) global context of
previous definitions.

\subsection{Valid Elimination Kind}
\label{ssec:pattern-valid-elim}

\begin{figure}[h]
  \caption{Valid elimination kinds}
  \label{fig:valid-elim-kind}
  \[
    \begin{array}{ccc}
      \infer
      { \llbracket T : ★\ |\ T \to ★ \rrbracket }
      { }
      & \infer
        { \llbracket T : \abs{\Pi}{s}{C}{K}\ |\ \abs{\Pi}{s}{C}{K'} \rrbracket}
        { \llbracket T\ s : K\ |\ K' \rrbracket }
    \end{array}
  \]
\end{figure}

When type-checking a pattern match (either $\mu$ or $\mu'$), we need to know
that the given motive $P$ has a kind $K$ for which elimination of a term with
some inductive data-type $I$ is permissible. We write this judgment as
$\llbracket \ann{T}{K'} | K \rrbracket$, which should be read ``the type $T$ of kind $K'$ can
be eliminated through pattern-matching with a motive of kind $K$''. This
judgment is defined by the simple rules in Figure \ref{fig:valid-elim-kind}. For
example, a valid elimination kind for the indexed type family $Vec\ \cdot X$
(which has kind $\abs{\Pi}{n}{Nat}{★}$) is $\abs{\Pi}{n}{Nat}{\abs{\Pi}{x}{Vec\
    \cdot X\ n}{★}}$

\subsection{Valid Branch Type}

Another piece of kit we need is a way to ensure that, in a pattern-matching
expression, a particular branch has the correct type given a particular
constructor of an inductive data-type and a motive. We write $\llbrace c : T
\rrbrace^P_I$ to indicate the type corresponding to the (possibly partially
applied) constructor $c$ of $I$ and its type $T$. We
abbreviate this notation to $\llbrace c \rrbrace^P$ when the inductive type
variable $I$, and the type $T$ of $c$, is known from the (meta-language) context.

\[
  \begin{array}{rcl}
    \llbrace c : I\ \vars{T}\ \vars{s} \rrbrace^P_I
    & = & P\ \vars{s}\ c
    \\ \llbrace c : \abs{\forall}{x}{T'}{T} \rrbrace^P_I
    & = & \abs{\forall}{x}{T'}{\llbrace c\ \mhyph x : T \rrbrace^P_I }
    \\ \llbrace c : \abs{\forall}{x}{K}{T} \rrbrace^P_I
    & = & \abs{\forall}{x}{K}{\llbrace c\ \cdot x : T \rrbrace^P_I }
    \\ \llbrace c : \abs{\Pi}{x}{T'}{T} \rrbrace^P_I
    & = & \abs{\Pi}{x}{T'}{\llbrace c\ x : T \rrbrace^P_I }
  \end{array}
\]

\noindent where we leave implicit the book-keeping required to separate the
parameters $\vars{T}$ from the indicies $\vars{s}$.

The biggest difference bewteen this definition and the similar one found in the
Coq documentation is that types can have implicit and explicit quantifiers, so
we must make sure that the types of branches have implicit / explicit
quantifiers (and the subjects $c$ have applications for types, implicit terms, and
explicit terms), corresponding to those of the arguments to the data constructor
for the pattern for the branch.

\subsection{Well-formed Patterns}
\label{ssec:pattern-wf-pat}

\begin{figure}[h]
  \caption{Well-formedness of a pattern}
  \label{fig:wf-pattern}
  \[
    \infer
    { \wfpat{\Gamma,\Delta}{\indast{M}{p}{\Gamma_I}{\Sigma}}{\vars{T}}{\mu'(t,P,t_{i=1..n})}
    }
    { \Gamma \vdash P : K
      \quad \Sigma = \ann{c_1}{\absu{\forall}{\Gamma_P}{T_1}}, ..., \ann{c_n}{\absu{\forall}{\Gamma_P}{T_n}}
      \quad \lenc{\vars{T}} = \lenc{\Gamma_p} = p
      \quad \llbracket I\ \vars{T}\, : \Gamma(I)\, |\, K \rrbracket
      \quad (\Gamma,\Delta \decchk t_i : \llbrace c_i\ \vars{T} \rrbrace^P)_{i=1..n}
    }
  \]
\end{figure}

% TODO 
Figure \ref{fig:wf-pattern} gives the rule for checking that a pattern
$\mu'(t,P,t_{i=1..n})$ is well-formed. We check that the motive $P$ is
well-kinded at kind $K$, that the given parameters $\vars{T}$ match the expected
number $p$ from the inductive data-type declaration, that an inductive data-type
$I$ instantiated with the given parameters $\vars{T}$ can be eliminated to a
type of kind $K$, and that the given branches $t_i$ account for each of the
constructors $c_i$ of $\Sigma$ and have the required branch type $\llbrace c_i\
\vars{T} \rrbrace^P$ under the given local context $\Gamma$ and context of
inductive data-type declarations $\Delta$.

\subsection{Generation of Abstracted Inductive Definitions}
\label{ssec:patern-abstracted-gen}

Cedilleum supports \textit{histomorphic} recursion (that is, having access to
all previous recursive values) where termination is ensured
through typing. In order to make this possible, we need a mechanism for tracking
the global definitions of \textit{concrete} inductive data types as well the
locally-introduced \textit{abstract} inductive data type representing the
recursive occurences suitable for a fixpoint function to be called on.

If $I$ is an inductive type such that $\Delta(I) =
\indast{\text{C}}{p}{\Gamma_I}{\Sigma}$ and $I'$ is a fresh type variable, then we
define function $Hist(\Delta,I,\vars{T},I')$ producing an abstracted (well-formed)
inductive definition $\indast{\text{A}}{0}{\Gamma_{I'}}{\Sigma'}$, where

\begin{itemize}
\item $\Gamma_{I'}(I') = \absu{\forall}{\Gamma_D}{★}$ if $\Gamma_{I}(I) =
  \absu{\forall}{\Gamma_{P}}{\absu{\forall}{\Gamma_D}{★}}$ (and $\lenc{\Gamma_P}
  = \lenc{\vars{T}} = p$)

  That is, the kind of $I'$ is the same as the kind of $I\ \vars{T}$
\item $\Sigma' = \ann{c'_1}{\absu{\forall}{\Gamma_D}
    { \absu{\piforall}{\Gamma_{A'_1}}{I'\ \Gamma_D} }},...,
  \ann{c'_n}{\absu{\forall}{\Gamma_D}
    { \absu{\piforall}{\Gamma_{A'_n}}{I\ \vars{T}\ \Gamma_D} }}$,

  when each of the concrete constructors $c_i$ in $\Sigma$ are associated with
  type $\absu{\forall}{\Gamma_P}{
    \absu{\forall}{\Gamma_D}{ \absu{\piforall}{\Gamma_{A_i}}{I\ \Gamma_P\
        \Gamma_D} } }$ and each $\Gamma_{A'_i} =
  [\absu{\lambda}{\Gamma_P}{I'}/I,\vars{T}/\Gamma_P]\Gamma_{A_i}$.

  That is, trasforming the concrete constructors of the inductive datatype $I$
  to ``abstracted'' constructors involves replacing each recursive occurrence of
  $I\ \Gamma_P$ with the fresh type variable $I$, and instantiating each of the
  parameters $\Gamma_P$ with $\vars{T}$.
\end{itemize}

Users of Cedilleum will see ``punning'' of the concrete constructors $c_i$ and
abstracted constructors $c'_i$. In particular, when using fix-point pattern
matching branch labels will be written with the constructors for the concrete
inductive data-type, and the expected type of a branch given by the motive will
pretty-print using the concrete constructors. In the inference rules, however,
we will take more care to distinguish the abstract constructors (see Subsection
\ref{ssec:typing-rules}).

\subsection{Typing Rules}
\label{ssec:typing-rules}

\begin{figure}[h]
  \caption{Use of an inductive datatype $\indast{M}{p}{\Gamma_I}{\Sigma}$}
  \label{fig:inductive-use}
  \[ \footnotesize
    \begin{array}{c}
      \infer
      { \Gamma,\Delta \decdir \mu'(t,P,t_{i=1..n}) : P\ \vars{s}\ t}
      { \Gamma \decsyn t : I\ \vars{T}\ \vars{s}
      \quad \wfpat{\Gamma,\Delta}{\Delta(I)}{\vars{T}}{\mu'(t,P,t_{i=1..n})}
      }
      \\ \\
      \\ \infer
      { \Gamma,\Delta \decdir \mu(x_{\text{rec}}, I',
      x_{\text{to}},t,P,t_{i=1..n}) : P\ \vars{s}\ t
      }
      {
      \begin{array}{c}
        \begin{array}{cccc}
          \Gamma \decsyn t : I\ \vars{T}\ \vars{s}
          & \Delta(I) = \indast{\text{C}}{p}{I}{K}{\Sigma}
          & \Gamma_I(I) =
            \absu{\Pi}{\Gamma_P}{\absu{\Pi}{\Gamma_{\text{D}}}{★}},\lenc{\Gamma_P}
            = p
          & Hist(\Delta,I,\vars{T},I') = \indast{\text{A}}{0}{I'}{K}{\Sigma'}
        \end{array}
        % \\ \\
        % \begin{array}{cc}
        %   \Gamma' = \Gamma,\Gamma_{I'},
        %   \ann
        %    {x_{\text{to}}=\absu{\Lambda}{\Gamma_D}{\absu{\lambda}{x}{x}}}
        %    { \absu{\forall}{\Gamma_{\text{D}}}{I'\
        %     \Gamma_{\text{D}} \to I\ \vars{T}\
        %     \Gamma_{\text{D}}}},
        %   \ann{x_{\text{rec}}}{\absu{\forall}{\Gamma_{\text{D}}}{\abs{\Pi}{x}{I'\
        %   \Gamma_{\text{D}}}{P\ \Gamma_{\text{D}}\ (x_{\text{to}}\ \Gamma_D\ x)}
        %   }}
        %   & \Delta' = \Delta,Hist(\Delta,I,\vars{T},I')
        % \end{array}
        % \\ \\
        % \begin{array}{cc}
        %   % P' = \absu{\lambda}{\Gamma_D}{\abs{\lambda}{x}{I\ \vars{T}\ \Gamma_D}{P\ 
        %   % \Gamma_D\ x} }
        %   \wfpat{\Gamma',\Delta'}{\Delta'(I')}{\varnothing}{\mu'(t,P,t_{i=1..n})}
        % \end{array}
      \end{array}
      }
    \end{array}
  \]
\end{figure}

The first rule of Figure \ref{fig:inductive-use} is for typing simple pattern
matching with $\mu'$. We need to know that the scrutinee $t$ is well-typed at
some inductive type $I\ \vars{T}\ \vars{s}$, where $\vars{T}$ represents the
parameters and $\vars{s}$ the indicies. Then we defer to the judgment
$WF\mhyph\!Pat$ to ensure that this pattern-matching expression is a valid
elimination of $t$ to type $P$.

The second rule is for typing pattern-matching with fix-points, and is
significantly more involved. As above we check the scrutinee $t$ has some
inductive type $I\ \vars{T}\ \vars{s}$. We confirm that $I$ is a
\textit{concrete} inductive data-type by looking up its definition in $\Delta$,
and then generate the abstracted definition $Hist(\Delta,I,\vars{T},I')$ for some fresh
$I'$. We then add to the local typing context $\Gamma_{I'}$ (the new inductive
type $I'$ with its associated kind) and two new variables $x_{\text{to}}$ and
$x_{\text{rec}}$.

\begin{itemize}
\item $x_{\text{to}}$ is the \textit{revealer}. It casts a term of an abstracted inductive
  data-type $I'\ \Gamma_D$ to the concrete type $I\ \vars{T}\ \Gamma_D$.
  Crucially, it is an \textit{identity} cast (the implicit quantification
  $\Lambda \Gamma_D$ disappears after erasure). The intuition why this should be
  the case is that the abstracted type $I'$ only serves to mark the recursive
  occurrences of $I$ during pattern-matching to guarantee termination.
\item $x_{\text{rec}}$ is the \textit{recursor} (or the inductive hypothesis).
  Its result type $P'\ \Gamma_D\ x$ utilizes $x_{\text{to}}$ in $P'$ to be
  well-typed, as the $x$ in this expression has type $I'\ \Gamma_D$, but $P$
  expects an $I\ \vars{T}\ \Gamma_D$. Because $x_{\text{to}}$ erases to the identity, uses of the
  $x_{\text{rec}}$ will produce expressions whose types will not interfere with
  producing the needed result for a given branch (see the extended example --
  TODO).
\end{itemize}

\noindent With these definitions, we finish the rule by checking that the
pattern is well-formed using the augmented local context $\Gamma'$ and context
of inductive data-type definitions $\Delta'$.

\section{Elaboration of Inductive Datatypes}
As mentioned in Section \ref{sec:intro}, Cedilleum is not based on CIC. Rather,
its core theory is the \textit{Calculus of Dependent Lambda Eliminations}
(CDLE), whose complete typing rules can are those of Section
\ref{sec:type-system} plus rules for dependent intersections (see
\cite{St18_Cedille-Syntax-Semantics}). That is to say, the preceding treatment
for inductive datatypes (Section \ref{sec:ind-data}) is a high-level and
convenient interface for \textit{derivable} inductive λ-encodings. This section
explains the elaboration process. Since the generic derivation of inductive
data-types with course-of-value induction has been covered in-depth in [TODO],
we omit these details and instead describe the \textit{interface} such
developments provide which data-type elaboration targets.

At a high level, inductive data-types in Cedilleum are first translated to
\textit{identity mappings}, which are (in the non-indexed case) a class of type
schemes \verb;F: ★ ➔ ★; that are more general than functors. The parameter of
the identity scheme replaces all recursive occurrences of the data-type in the
signatures of the constructor and a quantified type variable replaces all
``return type'' occurrences. For example, the type scheme for data-type
\verb;Nat; is \verb;λ R: ★. ∀ X: ★. X ➔ (R ➔ X) ➔ X;, with \verb;R; the
parameter and \verb;X; the quantified variable. For the rest of this
section we assume the reader has at least a basic understanding of impredicative
encodings of datatypes (see \cite{PP89_Inductive-Types-CC} and
\cite{Wa90_Rec-Types-For-Free}) and taking the least fix-point of functors (see
\cite{MFP91_Bananas-Lenses-Envelopes-Barbed-Wire}).

% TODO parameters
The following developments are parameterized by an indexed type scheme $F$ of
kind \verb;(Π Γᵢ. ★) → (Π Γᵢ. ★); corresponding to the kind
\verb;Π Γᵢ. ★; of inductive data-type $I$ declared as $\indast{I}{p}{\Gamma_I}{\Sigma}$

\subsection{Identity Mappings}
Our first task is to describe identity mappings, the class of type schemes
\verb;F: (Π Γᵢ. ★) ➔ Π Γᵢ. ★; we concerned with. Identity mappings are similar to functors
in that they come equipped with a function that resembles
\verb;fmap: ∀ Γᵢ. ∀ A B: Π Γᵢ. ★. Π f: (A ·Γᵢ ➔ B ·Γᵢ). F ·(A ·Γᵢ) ➔ F ·(B ·Γᵢ);
except that it need only be defined for an argument \verb;f; that is equal to the
identity function. We define the type \verb;Id; of such functions and declare
(indicated by \verb;<..>;) its elimination principle \verb;elimIdᵢ;:

\begin{verbatim}
Idᵢ : Π A B: (Π Γᵢ. ★). ι id: ∀ Γᵢ. A Γᵢ ➔ B Γᵢ. {id ≃ λ x. x}.
elimIdᵢ : ∀ A B: (Γᵢ. ★). Idᵢ ·A ·B ➾ A ➔ B = <..>
\end{verbatim}

Recall that since Cedilleum has a Curry-style type system and implicit
products there are many non-trivial functions that erase to identity.
While the definition of \verb;elimIdᵢ; is omitted, it is important to note that
it enjoys the property of erasing to the identity function:
\begin{verbatim}
elimIdᵢ-prop : {elimIdᵢ ≃ λ x. x} = β.
\end{verbatim}

We may now define \verb;IdMapping; as a scheme \verb;F; that comes with a way to
lift identity functions:
\begin{verbatim}
IdMappingᵢ : Π F: (Γᵢ ➔ ★) ➔ (Γᵢ ➔ ★). ★
  = λ F. ∀ A B: (Γᵢ ➔ ★). Ψ Γᵢ. Idᵢ ·A ·B ➔ Idᵢ ·(F ·A) ·(F ·B).
\end{verbatim}

Finally, it is convenient to define \verb;fimap; which given an
\verb;IdMapping; and an \verb;Id; function performs the lifting:
\begin{verbatim}
fimapᵢ : ∀ F: (Π Γᵢ. ★) ➔ (Π Γᵢ. ★). ∀ im: IdMappingᵢ ·F. Castᵢ ·A ·B ➾ F ·A ➔ F ·B
  = Λ F im c. λ f. elimIdᵢ -(im c) f.
\end{verbatim}

From \verb;elimIdᵢ-prop; it should be clear that \verb;fimapᵢ; also erases to
\verb;λ x. x;.

% TODO Re-do View with indexes, too!
\subsection{Type-views of Terms}
A crucial component of course-of-value is the ability to view some term as having
two different types. The idea behind a \verb;View; is similar to that behind the
type \verb;Id; from the previous section, except now we explicitly name the
doubly-typed term:
\begin{verbatim}
View : Π A: ★. A ➔ ★ ➔ ★ = λ A a B. ι b: B. {a ≃ b}
elimView : ∀ A B: ★. Π a: A. View ·A a ·B ➾ B = <..>
elimView-prop : {elimView ≃ λ x. x} = β.
\end{verbatim}

\subsection{λ-encoding Interface}
This subsection describes the interface to which data-type declarations are
elaborated; it is parameterized by an identity mapping.

% TODO module parameters!
\begin{verbatim}
module (Fᵢ: (Π Γᵢ. ★) → (Π Γᵢ. ★)){im: IdMapping ·Fᵢ}.
\end{verbatim}

% TODO explain derivation?
\noindent where parameters \verb;Fᵢ; and \verb;im; are automatically derived from the
declaration of a positive data-type.

With these two parameters alone, the generic developments of [TODO] provide the
following interface for inductive λ-encodings of data-types:

\begin{verbatim}
Fixᵢ : Π Γᵢ. ★ = <..>
inᵢ  : ∀ Γᵢ. Fᵢ ·Fixᵢ Γᵢ ➔ Fixᵢ Γᵢ = <..>
outᵢ : ∀ Γᵢ. Fixᵢ Γᵢ ➔ Fᵢ ·Fixᵢ Γᵢ = <..>

PrfAlgᵢ : Π P: (Π Γᵢ. Π d: Fixᵢ Γᵢ. ★). ★
  = λ P. ∀ R: (Π Γᵢ. ★).
      ∀ c: Idᵢ ·R ·Fixᵢ.
      Π v: View ·(∀ Γᵢ. Fixᵢ Γᵢ ➔ Fᵢ ·Fixᵢ Γᵢ) out ·(∀ Γᵢ. R Γᵢ ➔ Fᵢ ·R Γᵢ).
      Π ih: (∀ Γᵢ. Π r: R Γᵢ. P Γᵢ (elimIdᵢ -c -Γᵢ r)).
      Π Γᵢ. Π fr. F ·R Γᵢ.
      P Γᵢ (inᵢ -Γᵢ (fimapᵢ -im -c fr)).
inductionᵢ : ∀ P: (Π Γᵢ. Π d: Fixᵢ Γᵢ. ★). PrfAlgᵢ ·P ➔ ∀ Γᵢ. Π d: Fixᵢ Γᵢ. P Γᵢ d
  = <..>
\end{verbatim}

The first three definitions give \verb;Fixᵢ; as the (least) fixed-point of
\verb;Fᵢ;, with \verb;inᵢ; and \verb;outᵢ; representing resp. a generic set of
constructors and destructors. \verb;inductionᵢ; of course is the proof-principle
stating that if one can provide a \verb;PrfAlg; for property \verb;P; (that is,
\verb;P; holds for all \verb;Fixᵢ; generated by (generic) constructor
\verb;inᵢ;) then this suffices to show that \verb;P; holds for \textit{all}
\verb;Fixᵢ;.

We now explain the definition of \verb;PrfAlgᵢ; in more detail:
\begin{itemize}
  \item \verb;R; is the type of recursive occurrences of the data-type
    \verb;Fixᵢ;.

    It corresponds directly to types like \verb;rec/Nat; when using
    \verb;μ; in Cedilleum
  \item \verb;c; is a ``revealer'', that is to say a proof that \verb;R; really
    \textit{is} \verb;Fixᵢ; witnessed by an identity function.

    It corresponds directly to functions like \verb;rec/cast; when using \verb;μ;
  \item \verb;v; is evidence that the (generic) destructor \verb;outᵢ; can be
    used on the recursive occurrence type \verb;R; for further pattern-matching.

    It corresponds directly to \verb;μ'; (when used outside of \verb;μ; it
    corresponds to the ``trivial'' view that \verb;outᵢ; has the type it is
    already declared to have).

  \item \verb;ih; is the inductive hypothesis, stating that property \verb;P;
    holds for all recursive occurrences \verb;R; of an inductive case

    It corresponds directly to the \verb;μ;-bound variable for fix-point recursion.
  \item \verb;fr; represents the collection of constructors that each \verb;μ;
    branch must account for.

    For example, for the data-type \verb;Nat; we have identity mapping
    \verb;fr: ∀ X: ★. X ➔ (R ➔ X) ➔ X; and Cedilleum cases branches
    \verb;{| zero ➔ zcase | succ r ➔ scase r }; translate to
    \verb;fr zcase (λ r. scase r);

  \item Finally, result type \verb;P Γᵢ (inᵢ -Γᵢ (fimapᵢ -im -c fr)); accounts
    for the return type of each case branch.

    Since \verb;P; is phrased over \verb;Fixᵢ;, and we have by assumption
    \verb;fr: Fᵢ ·R Γᵢ;, we must first use our identity mapping \verb;im; to
    traverse \verb;fr; and cast each recursive occurrence \verb;R Γᵢ; to
    \verb;Fixᵢ Γᵢ;, producing an expression of type \verb;F ·Fixᵢ Γᵢ; which we are
    then able to transform into \verb;Fixᵢ Γᵢ; using (generic) constructor \verb;inᵢ;.
\end{itemize}

While the definitions of \verb;inᵢ;, \verb;outᵢ;, and \verb;inductionᵢ; are
omitted, it is important that they have the following computational behavior
(guaranteed by [TODO]):
\begin{verbatim}
lambek1ᵢ : ∀ Γᵢ. Π gr: Fᵢ Fixᵢ Γᵢ. {outᵢ (inᵢ gr) ≃ gr} = β.
lambek2ᵢ : ∀ Γᵢ. Π d: Fixᵢ Γᵢ. {in (out d) ≃ d}
  = inductionᵢ ·(λ Γᵢ. λ x: Fixᵢ Γᵢ. {in (out x) ≃ x})
     (Λ R. Λ c. λ o. Λ eq. λ ih. λ gr. β).

inductionCancelᵢ : ∀ P: (Π Γᵢ. Fixᵢ Γᵢ ➔ ★).
    Π alg: PrfAlg ·P ➔ ∀ Γᵢ. Π fr: F ·Fixᵢ Γᵢ.
    { inductionᵢ alg (in gr) ≃ alg outᵢ (inductionᵢ alg) fr}
  = λ _. λ _. β.
\end{verbatim}
That is, \verb;inᵢ; and \verb;outᵢ; are inverses of each other and
\verb;inductionᵢ; behaves like a fold (where the algebra takes the additional
\verb;outᵢ; argument).

\subsection{Sum-of-Products Induction}
As stated above, every inductive data-type declaration
$\indast{I}{p}{Γ_I}{\Sigma}$ is first translated to a type-scheme \verb;IF;
where all recursive occurrences of type \verb;I; in the constructor signatures
$\Sigma$ have been replaced by the scheme's argument \verb;R;. In this
subsection describe that process more precisely and explain ``sum-of-products''
induction for \verb;IF;

First, as the kind of \verb;I; is \verb;Π Γₚ. Π Γᵢ. ★;, where \verb;Γₚ; are the
parameters and \verb;Γᵢ; the indices, it follows that the kind of \verb;IF; is
\verb;Π Γₚ. Π R: (Π Γᵢ. ★). (Π Γᵢ. ★);. Next, each constructor $c_j$ has type
$\Sigma(c_j)$ which we know has the form $\piforall\ \Gamma_j.\ I\ \Gamma_p\
\vars{t_j}$ (that is, some number of arguments $\Gamma_j$ with a return type
constructing the inductive data-type $I$). All recursive occurrences of $I$ in
$\Gamma_j$ are substituted away with \verb;λ Γₚ. R; to produce $Γ^R_j$. With
that, we may defined \verb;IF; as

\[ λ\ Γₚ\ \texttt{R}\ Γᵢ.\ ∀ X: Π\ Γᵢ. ★. (Π\ c_j: (\piforall Γ^R_j.\ X\
  \vars{t_j}))_{j=1..n}.\ X\ Γᵢ\]

\paragraph{Example}

The data-type declaration of \verb;Vec; translates to:
\begin{verbatim}
VecF : Π A: ★. (Nat ➔ ★) ➔ Nat ➔ ★
  = λ A R n. ∀ X: Nat ➔ ★. X zero ➔ (∀ n: Nat. A ➔ R n ➔ X (succ n)) ➔ X n.
\end{verbatim}

An induction principle for each of these non-recursive sum-of-products types
\verb;IF; can be defined in an automated way following the recipe given by
[TODO]; in general these have the following shape:

\begin{verbatim}
indIF : ∀ Γₚ. ∀ R: (Π Γᵢ. ★). ∀ Γᵢ. Π fr: IF Γₚ ·R Γᵢ. ∀ P: (Π Γᵢ. IF Γₚ ·R Γᵢ ➔ ★)
    (Π pⱼ: Ψ Γᴿⱼ. P (cⱼ Γᴿⱼ))ⱼ₌₁⋯ₙ. P Γᵢ fr = <..>
\end{verbatim}

\appendix
\section{Deriving \texttt{IdMappingᵢ} for a Data-type Type Scheme}
A type scheme \verb;F; derived from a data-type declaration has by assumption a
definition following the pattern:

\begin{verbatim}
F : Π Γₚ. (Π Γᵢ. ★) → Π Γᵢ. ★
  = λ Γₚ R Γᵢ. ∀ X: (Π Γᵢ. ★). (Π cⱼ: (Ψ Γᴿⱼ. X ₸ⱼ))ⱼ₌₁₋ₙ. X Γᵢ
\end{verbatim}

\noindent where \verb;R; occurs only positively. From this we must give a
witness that \verb;F; is an identity mapping over \verb;R;

\begin{verbatim}
idmap : ∀ Γₚ. IdMappingᵢ ·(F Γₚ)
  = Λ Γₚ. Λ R1. Λ R2. Λ id. ●
\end{verbatim}

\noindent where the expected type of \verb;●; is \verb;Idᵢ ·(F ·Γₚ R1) ·(F ·Γ R2);

We refine \verb;●; by the introduction rule for intersections (which \verb;Idᵢ; is) and
introduce the assumption \verb;fr1: F ·Γₚ R1 ·Γᵢ;

\begin{verbatim}
[ Λ Γᵢ. λ fr1. ●₁ , ●₂]
\end{verbatim}

\noindent where \verb;●₁: F ·Γₚ R2 ·Γᵢ; and \verb;●₂: {λ fr1. ●₁ ≃ λ x. x};. As
the only (non-hole) refinements we will make to \verb;●₁; are converting terms to $\eta$-long
form and applying \verb;elimIdᵢ -id; to subterms (which reduces to the identity
function), we are justified in replacing \verb;●₂; with \verb;β;. We now refine
the remaining \verb;●₁; to

\begin{verbatim}
Λ X. λ ş. ● fr1 ş
\end{verbatim}

\noindent where each abstract constructor \texttt{cⱼ} in ş has type
\verb;Ψ Γᴿ²ⱼ. X ₸ⱼ;. Note again the superscript \verb;R2; -- we are now trying
to construct a term of type \verb;F ·Γₚ R2 ·Γᵢ; so we assume the ``abstract''
constructors whose recursive occurence types are \verb;R2;. Correspondingly,
this means that \verb;●: F ·Γₚ R1 ·Γᵢ → (Π cⱼ: (Ψ Γᴿ²ⱼ. X ₸ⱼ))ⱼ₌₁₋ₙ → X Γᵢ;.

Since \verb;fr1; produces a value of type \verb;X Γᵢ; when fed appropriate
arguments, we refine \verb;●; by $n$ holes \verb;●ⱼ; applied to constructor
\verb;cⱼ;. The expression \verb;● fr1 ş; becomes

\begin{verbatim}
fr1 (●ⱼ cⱼ)ⱼ₌₁₋ₙ
\end{verbatim}

\noindent where now \verb;●ⱼ: (Ψ Γᴿ²ⱼ. X ₸ⱼ) → Ψ Γᴿ¹ⱼ. X ₸ⱼ;. We henceforth
dispense with the subscript $j$ numbering the constructor and treat each
abstract constructor uniformly.

\subsection{Conversion of the Abstract constructors}
We first make the expression \verb;● c; $\eta$-long, as in \verb;ψ Γᴿ¹. ● c Γᴿ¹;,
then refine \verb;● c Γᴿ¹; to an expression with $m$ holes \verb;●ₖ; for each $\texttt{y}_k \in
Γ^{\texttt{R1}}$ (where $m\ =\ \lenc{Γ^{\texttt{R1}}}$), yielding

\begin{verbatim}
c (●ₖ yₖ)ₖ₌₁₋ₘ
\end{verbatim}

\noindent where \verb;●ₖ: Γᴿ¹(yₖ) → Γᴿ²ₖ(yₖ); (and the type of \verb;yₖ;
and \verb;●ₖ yₖ; can depend resp. on any \verb;yᴿ¹ⱼ; and \verb;●ⱼ yⱼ; where
$j < k$). We now dispense with the subscript $k$ for arguments and handle each
constructor sub-data uniformly.

\subsection{Conversion of Constructor Sub-data With Positive Recursive Occurences}
\label{ssec:positive}
We now consider \verb;● y; where \verb;y: S; is some sub-data to an
(abstract) constructor with recursive occurence type \verb;R1; passing the
positivity checker. (The expression \verb;● y; has type \verb;[R2/R1]S;).
There are two cases to consider:

\begin{itemize}
\item[1] \verb;R1; does not occur in the type of \verb;y;

  Refine \verb;●; to \verb;unit: ∀ X: ★. X → X = Λ X. λ x. x; and finish.
\item[2] \verb;R1; occurs positively in the type of \verb;y;

  This means $S$ has the shape \verb;Ψ Γᴿ¹ₓ. T; (where \verb;T; is not formed by
  an arrow) with \verb;R1;
  occurring \textit{only negatively} in the type of the
  $\texttt{xⱼ} \in Γ^{R1}_x$ (where $j=1..\lenc{Γ^{R1}ₓ}$). Make \verb;● y;
  $\eta$-long and refine the expression to $\lenc{Γ^{R1}ₓ}$ holes \verb;●ⱼ; such
  that the expression is now
  
\begin{verbatim}
ψ Γᴿ²ₓ. ● y (●ⱼ xⱼ)ⱼ₌₁₋ₙ
\end{verbatim}

  \noindent Where here \verb;xⱼ; is bound by \verb;Γᴿ²; and thus has negative occurences
  of \verb;R2;. Note that we still require \verb;●; since it might be the case that
  \verb;T = R1 Γᵢ; (handled below); it has type \verb;S → Ψ Γᴿ¹ₓ. [R1/R2]T;.
  Each \verb;●ⱼ; has type \verb;Γᴿ²ₓ(xⱼ) → Γᴿ¹ₓ(xⱼ);.

  Perform the steps outlined in Section \ref{ssec:negative} to fill in each
  \verb;●ⱼ; producing from \verb;●ⱼ xⱼ; the sequence of arguments \verb;₸ⱼ; of
  type \verb;Γᴿ¹ₓ; that erase to \verb;xⱼ₌₁₋ₙ; Finally, refine \verb;●; to either \verb;unit; or
  \verb;λ y. λ xⱼ. elimId -c (y xⱼ); depending on whether \verb;T = R1 Γᵢ;

\end{itemize}

\subsection{Conversion of Constructor Sub-data With Negative Recursive
  Occurences}
\label{ssec:negative}
We consider \verb;● x; where \verb;x: Ψ Γᴿ²ᵤ. S;, \verb;S; is not an arrow
and does not contain \verb;R2;, and \verb;R2; occurs positively in the types of
the variables bound by \verb;Γᴿ²ᵤ;. The expression \verb;● x; has type
\verb;Ψ Γᴿ¹ᵤ. S;.

Make \verb;● x; $\eta$-long and introduce holes \verb;●ⱼ; to apply to the
sub-data as in

\begin{verbatim}
ψ Γᴿ¹ᵤ. x (●ⱼ yⱼ)ⱼ₌₁₋ₙ
\end{verbatim}

\noindent where \verb;●ⱼ: Γᴿ¹ᵤ(yⱼ) → Γᴿ²ᵤ(yⱼ);. Perform the steps outlined by
Section \ref{ssec:positive} to fill in each \verb;●ⱼ; producing from
\verb;●ⱼ yⱼ; the sequence of arguments \verb;₸; that erase to \verb;yⱼ₌₁₋ₙ;.


\bibliographystyle{alpha}gygygy
\bibliography{spec}

\end{document}
