\documentclass{article}


% \usepackage{todonotes}
\usepackage{amsmath,amssymb,amsthm}
%\usepackage{unicode-math}
\usepackage{url}
\usepackage{fullpage}

\usepackage{subcaption}
\usepackage{cedilleverbatim}
\usepackage{proof}

\usepackage{stmaryrd}

\usepackage{soul}
% \usepackage{unicode-math}

\DeclareUnicodeCharacter{03BC}{\ensuremath{\mu}}
\DeclareUnicodeCharacter{03B7}{\ensuremath{\eta}}
\DeclareUnicodeCharacter{0393}{\ensuremath{\Gamma}}
\DeclareUnicodeCharacter{21A6}{\ensuremath{\to}}
\DeclareUnicodeCharacter{25CF}{\ensuremath{\bullet}}
\DeclareUnicodeCharacter{1D48C}{\ensuremath{\kappa}}
\DeclareUnicodeCharacter{1D62}{\ensuremath{_{\texttt{D}}}} % maps _i to _d
\DeclareUnicodeCharacter{209A}{\ensuremath{_{\texttt{p}}}}
\DeclareUnicodeCharacter{2C7C}{\ensuremath{_{\texttt{j}}}} % maps _J to _j
\DeclareUnicodeCharacter{2096}{\ensuremath{_{\texttt{k}}}} % maps _J to _j
\DeclareUnicodeCharacter{1D3F}{\ensuremath{^{\texttt{R}}}}
\DeclareUnicodeCharacter{208B}{\ensuremath{_{-}}}
\DeclareUnicodeCharacter{208C}{\ensuremath{_{=}}}
\DeclareUnicodeCharacter{2098}{\ensuremath{_{m}}}
\DeclareUnicodeCharacter{2099}{\ensuremath{_{n}}}
\DeclareUnicodeCharacter{1D64}{\ensuremath{_{\texttt{y}}}}
\DeclareUnicodeCharacter{2093}{\ensuremath{_{x}}}
\DeclareUnicodeCharacter{22EF}{\ensuremath{_{..}}}
\DeclareUnicodeCharacter{2080}{\ensuremath{_0}}
\DeclareUnicodeCharacter{2083}{\ensuremath{_3}}
\DeclareUnicodeCharacter{00B9}{\ensuremath{^1}}
\DeclareUnicodeCharacter{00B2}{\ensuremath{^2}}
\DeclareUnicodeCharacter{20B8}{\ensuremath{\vars{\texttt{t}}}}
\DeclareUnicodeCharacter{015F}{\ensuremath{\vars{\texttt{c}}}}

% useful macros
\newcommand{\ann}[2]{#1\! : \! #2}
\newcommand{\abs}[4]{{#1}\, #2\! : \! #3.\, #4}
\newcommand{\absu}[3]{{#1}\, #2.\, #3}
\mathchardef\mhyph="2D % Define a "math hyphen"
\newcommand{\indast}[5]{\texttt{Ind}_{#1} [#2] (#3 : #4 = #5)}
\newcommand{\lowerc}[1]{\lfloor {#1} \rfloor}
\newcommand{\lenc}[1]{\|#1\|}
\newcommand{\vars}[1]{{\overline{#1}}}

% - type inference
\newcommand{\decdir}{\vdash_{\delta}}
\newcommand{\decsyn}{\vdash_{\Uparrow}}
\newcommand{\decchk}{\vdash_{\Downarrow}}

% - inductive
\newcommand{\mufix}[3]{μ\ #1\ .\ #2\ \textbf{\{} #3 \textbf{\}}}
\newcommand{\mumat}[2]{μ'\ #1\ \textbf{\{}#2\textbf{\}}}
\newcommand{\wfpat}[4]{WF\!\mhyph\!Pat(#1,#2,#3,#4)}
\newcommand{\llbrace}{\{\!\{}
\newcommand{\rrbrace}{\}\!\}}
\newcommand{\piforall}{^{\Pi}_{\forall}}
\newcommand{\lamLam}{^{\lambda}_{\Lambda}}
\DeclareUnicodeCharacter{03A8}{\ensuremath{\piforall}} % maps Ψ to \piforall
\DeclareUnicodeCharacter{03C8}{\ensuremath{\lamLam}}   % maps ψ to \lamLam
\newcommand{\reduce}{\ensuremath{\rightsquigarrow}}

\begin{document}

\title{The Cedilleum Language Specification \\ \large Syntax, Typing, Reduction,
  and Elaboration }

\author{Christopher Jenkins}

\maketitle

\section{Introduction}
\label{sec:intro}
This document describes \textit{Cedilleum}, a general-purpose dependently typed
programming language with inductive datatypes. Unlike most languages of this
description, the underlying theory of Cedilleum is \textit{not} the Calculus of
Inductive Constructions (CIC)\cite{Pa15_Intro-CIC}. Instead, Cedilleum is
designed so that it may easily be translated to \textit{Cedille Core} -- a
compact core theory in which induction is derivable for lambda-encoded datatypes
-- while still providing high-level features like pattern-matching and recursive
definitions. That said, the formal specification of Cedilleum as a
self-contained language has a lot in common with CIC -- see in particular
Section 8 of \cite{In18_Coq-Docs}, which served as the basic template for much
of this document's formal development.

\subsection{Data-type Declarations}
Before diving into the details, let us take a bird's-eye view of the language
by showing some simple example data-type definitions and functions over them.

\begin{figure}[h]
\begin{verbatim}
-- Non-recursive
data Bool: ★ =
  | tt: Bool
  | ff: Bool
.
-- Recursive
data Nat: ★ = 
  | zero: Nat
  | succ: Nat ➔ Nat
.
-- Recursive, parameterized, indexed
data Vec (A: ★): Nat ➔ ★ =
  | vnil : Vec zero
  | vcons: ∀ n: Nat. A ➔ Vec n ➔ Vec (succ n)
.
\end{verbatim}
  \caption{Definition of natural numbers and length-indexed lists}
  \label{fig:ex-data-decl}
\end{figure}
Figure \ref{fig:ex-data-decl} shows some definitions of inductive datatypes, and
modulo differences in syntax should seem straightforward to programmers used
to languages like Agda, Idris, or Coq. Some key differences are:

\begin{itemize}
\item In constructor type signatures, recursive occurrences of the inductive
  data-type being defined (such as in \texttt{suc : \underline{Nat} ➔ Nat}) must
  be positive, \textit{but not strictly positive}.
\item In parameterized types (like \texttt{Vec} with parameter \texttt{(A: ★)})
  occurrences of the inductive type being defined are not written applied to
  its parameters.
  
  For example, the constructor declaration \texttt{vnil : Vec zero} results in
  the term \texttt{vnil} having type \\ \texttt{∀ A: ★. Vec ·A zero} (with \texttt{·}
  denoting type application)
\item In the constructor declaration \texttt{vcons : ∀ n: Nat. A ➔ Vec n ➔ Vec
    (succ n)}, the argument \texttt{n} is \textit{computationally irrelevant}
  (or \textit{erased}). This is because it is introduced by the
  irrelevant dependent function former \texttt{∀}, as opposed to the relevant
  function former \texttt{Π}. More will be said of this when we discuss the type
  system of Cedilleum, but for now it suffices to say that implicit
  quantification comes from the \textit{Implicit Calculus of
    Constructions}\cite{Mi01_ICC}.
\end{itemize}

\subsection{Function Definitions}
\begin{figure}[h]
\begin{verbatim}
-- Non-recursive
ite : ∀ X: ★. Bool ➔ X ➔ X ➔ X
  = Λ X. λ b. λ then. λ else. μ' b {
      | tt ➔ then
      | ff ➔ else
      }.
-- Recursive
add : Nat ➔ Nat ➔ Nat
  = λ n. λ m.
      μ rec. n @(λ x: Nat. Nat) {
      | zero   ➔ m
      | succ p ➔ succ (rec p)
      }.
\end{verbatim}
  \caption{Functions over inductive datatypes}
  \label{fig:ex-data-fun}
\end{figure}

Figure \ref{fig:ex-data-fun} shows functions defined over inductive datatypes
using pattern matching and recursion. The first difference to note between the
definitions is that \texttt{ite} performs ``mere''
pattern matching on its argument by using \texttt{μ'}, whereas \texttt{add}
uses \texttt{μ} which provides combined pattern-matching and fix-point
recursion. In \texttt{add}, \texttt{μ} binds \texttt{rec} as the name of the
fixpoint function for recursion on \texttt{n}. From this alone the reader might
expect that \texttt{μ'} is merely syntactic sugar for the more verbose
\texttt{μ} but without recursion. Actually the difference is a bit more subtle
that this, as we will see below in Section \ref{sec:hist-rec}

The first major departure of Cedilleum from other languages with inductive
datatypes can be seen in the type of \texttt{rec}. The type that the reader
might expect it to have is \verb;Π x: Nat. Nat; (corresponding to the motive
\verb;(λ x: Nat. Nat);), but in Cedilleum, its type is \verb;rec/type ➔ Nat;
(where we read \texttt{rec/type} as a single identifier) and by extension for
the expression \texttt{rec p} to be well-typed, the variable \texttt{p} bound in
the pattern \texttt{succ p} must have type \texttt{rec/type}. The name
\texttt{rec/type} is locally bound in the body of the μ-expression (delimited
by curly braces \texttt{\{...\}}) and is
automatically generated by Cedilleum by using the name of the recursive
function bound by μ (here \texttt{rec}).

Why introduced this new type for the predecessor and, in general, for the
recursive occurrences of the data-type in constructor sub-data? The answer is: for
\textit{termination checking}. Typically, languages that support
pattern-matching and fixpoint-style recursion for inductive data-types require
all recursive calls be made on ``obviously smaller'' arguments. In Cedilleum,
the syntactic check is replaced by type-checking, and types like
\texttt{rec/type} encode the fact that some data is indeed ``obviously smaller''
than the previous invocation and thus legal to recurse on. These
``recursive-occurence'' types appear in the types of sub-data (such as
\texttt{p} in the example) in the constructor patterns of the case branches
introduced by μ (but not necessarily μ'), replacing all occurrences of the
inductive type itself.
% \footnotetext{More precisely, the type of every
% variable bound by a constructor pattern of a case branch introduced by
% \texttt{μ} has all occurences of $\texttt{I}\ \vars{P}$ replaced by
% \texttt{I/fixpoint-name}, where $\vars{P}$ are the parameters.}

% The type \texttt{Nat/add-rec} (and any such type generated by use of
% \texttt{μ}) comes with some restrictions, which will be made more precise
% further on in the document. Informally, such terms cannot themselves be given to
% \texttt{μ} directly as in `\verb;μ add-rec2. r; ...' and despite the deceptive
% case label `\verb;| suc r ↦ ;...' \texttt{r} cannot be given directly to
% constructor \texttt{succ}, as \texttt{Nat} and \texttt{Nat/add-rec} are distinct
% types. However, even so these two types \textit{are} related to each other, most
% notably in the way they are treated by \texttt{μ'} -- terms of type \texttt{Nat}
% and \texttt{Nat/add-rec} alike support mere pattern matching through \texttt{μ'}.

\begin{figure}[h]
\begin{verbatim}
-- Recursive, parameterized, indexed
vappend : ∀ A: ★. ∀ m: Nat. ∀ n: Nat. Vec ·A m ➔ Vec ·A n ➔ Vec ·A (add m n)
  = Λ A. Λ m. Λ n. λ xs. λ ys.
      μ rec. xs @(λ i: Nat. λ zs: Vec ·A i. Vec ·A (add i n)) {
      | vnil            ➔ ys
      | vcons -m' x xs' ➔ [ zs = rec -m' xs' ] - vcons -(add m' n) x zs
      }.
\end{verbatim}
  \caption{Dependent functions over inductive datatypes}
  \label{fig:ex-data-dep}
\end{figure}

Figure \ref{fig:ex-data-dep} shows the classic dependent function
\texttt{vappend} over \texttt{Vec}, the type of length-indexed lists. Like
\texttt{add}, it is defined by fixpoint recursion, here over the argument
\texttt{xs}. Here the fixpoint function \texttt{rec} has type
\texttt{∀ i: Nat. Π zs: rec/type i. Vec ·A (add i n)}, where the
recursive-occurence type has kind \texttt{Nat ➔ ★}. Note again the missing parameter
\texttt{A} in the type \texttt{rec/type i} -- this is not a typo, but rather an
indication that \texttt{A} is ``baked-in'' to the type \texttt{rec/type}. Aside
from this the two cases of \texttt{vappend} are mostly straightforward: in the
\texttt{vnil} branch the expected type is \verb;Vec ·A (add zero n); which
converts to \verb;Vec ·A n;, so \texttt{ys} suffices; in the \texttt{vcons}
branch we bind subdata \verb;m': Nat;, \verb;x: A;, and \verb;xs': rec/type m';,
with \verb;-m'; indicating that \verb;m'; is bound \textit{irrelevantly}, then
we make a local biding \texttt{zs} by invoking recursive function \texttt{rec} on
\texttt{m'} and \texttt{xs'} (where here \texttt{-m'} indicates \texttt{m'}
is an irrelevant \textit{argument} to \texttt{rec}) before producing a result
whose type is convertible with the expected \verb;Vec ·A (add (suc m') n);.

\subsection{Course-of-Value Recursion}
\label{sec:intro-cov}

By supporting type-guided termination checking, Cedilleum enables a form of
reasoning more powerful than what is available with a simple
syntax-based termination checker: ``course-of-value'' recursion (and induction),
allowing the programmer to recurse on arbitrarily deeply-nested sub-data in a
provably terminating way. A compelling example of this can be seen when trying
to implement division of natural numbers through iterated subtraction. In a
language like Haskell, one may simply write:
\begin{verbatim}
-- Haskell snippet
(/) 0 d = 0
n / 0 = 0
n / d = 1 + ((n - d) / d)
\end{verbatim}
This definition of division is terminating for all input; however, syntactic
termination checkers will usually have a hard time seeing that the argument
\texttt{n - d} of the recursive call to \texttt{divide} is legal, as it is in
general hard to determine whether some arbitrary function produces a
structurally smaller result than one of its inputs. Intuitively, we understand
that subtracting \texttt{d} from \texttt{n} never produces a number larger than
\texttt{n}, and one advantage that Cedilleum's type-guided termination checking
has is that it allows us use this intuition to define a version of division in
Figure \ref{fig:ex-data-div} very similar to the one above and which is
``obviously'' terminating.

\label{sec:hist-rec}
\begin{figure}[h]
\begin{verbatim}
pred' : ∀ R: ★. Nat/Mu ·R ➾ R ➔ R
  = Λ R. Λ muWit. λ r. μ'<muWit> r {| zero ➔ r | succ r' ➔ r'}.

pred : Nat ➔ Nat = pred' -Nat/mu .

minus' : ∀ R: ★. Nat/Mu ·R ➾ R ➔ Nat ➔ R
  = Λ R. Λ muWit. λ m. λ n. μ rec. n @(λ _: Nat. R) {
  | zero   ➔ m
  | succ n' ➔ pred' -muWit (rec n')
  }.

minus : Nat ➔ Nat ➔ Nat = minus' -Nat/Rec .

lt : Nat ➔ Nat ➔ Bool
  = λ m. λ n. μ' (minus m n) {
  | zero   ➔ ff
  | succ _ ➔ tt
  }.

divide : Nat ➔ Nat ➔ Nat
  = λ n. λ d. μ rec. n @(λ _: Nat. Nat) {
  | zero   ➔ zero
  | succ n' ➔ succ (rec (minus' -rec/mu n' (pred d)))
  }.
\end{verbatim}
  \caption{Course-of-value recursion and division}
  \label{fig:ex-data-div}
\end{figure}

Our first function, \texttt{pred'}, is crucial for defining \texttt{divide} further
below. The type \texttt{Nat/Mu ·R} in its type signature is the type of
\textit{witnesses} that terms of type \texttt{R} can be pattern-matched (using μ')
as if they had type \texttt{Nat}; in the definition of \texttt{pred'}, this witness
is given name \texttt{muWit}. All such witnesses are introduced in only one of
two ways: once \textit{globally} for each defined data-type (like \texttt{Nat}
itself -- in the definition of \texttt{pred} the term \texttt{Nat/mu} has type
\texttt{Nat/Mu ·Nat}); and \textit{locally} for each recursive-occurence type
introduce by μ (in the body of \texttt{divide}, term \texttt{rec/mu} has type
\texttt{Nat/Mu ·rec/type}). In the definition of \texttt{pred'}, the notation
\texttt{μ'<muWit>} indicates that the witness \texttt{muWit} is given explicitly
to enable (mere) pattern-matching on argument \texttt{r}. After this, the
definition of \texttt{pred} is easy -- it is an instance of \texttt{pred'} where
\texttt{R} is specialized to \texttt{Nat} itself with evidence \texttt{Nat/mu}.

Next we define \texttt{minus'}. One intuition for the type signature \texttt{∀
  R: ★. Nat/Mu ·R ➾ R ➔ Nat ➔ R} of
\texttt{minus'} is that it says ``this function never returns a number larger
than it's \texttt{R} argument.'' That is to say, to
return a term of type \texttt{R}, \texttt{minus'} can only return its \texttt{R}
argument directly or some sub-data produced by pattern-matching on it. In
\texttt{pred'} pattern-matching (via μ') is done only once; in \texttt{minus'} it is done \texttt{n}
times by recursion on subtrahend \texttt{n} by invoking \texttt{pred'} each time.

Finally, we turn to the definition of \texttt{divide} itself. At a high level,
we recurse on dividend \texttt{n}, and in the \texttt{zero} case simply return
\texttt{zero}. In the successor case, we subtract the (predecessor of) the
divisor from the (predecessor of) the dividend, call \texttt{rec} on the result,
and then add one with \texttt{succ}. We must use \texttt{minus'} to perform
subtraction so that the call to \texttt{rec} is well-typed; note how this 
prevents the user from writing \texttt{rec (minus (succ n') d)}, which if
typeable would diverge when the divisor \texttt{d} is \texttt{zero}.

\subsection{Subtyping and Coercions}
\label{sec:subtyping-coercion}
\begin{figure}[h]
\begin{verbatim}
mult : Nat ➔ Nat ➔ Nat
  = λ m. λ n. μ rec. m {
    | zero    ➔ zero
    | succ m' ➔ add n (rec m')
  }.
fact1 : Nat ➔ Nat
  = λ n. μ rec. m {
    | zero    ➔ succ zero
    | succ n' ➔ mult (succ (Nat/cast -rec/mu n')) (rec n')
  }.

NatCast-id : {Nat/cast ≃ λ x. x} = β.

fact2 : Nat ➔ Nat
  = λ n. μ rec. m {
    | zero    ➔ succ zero
    | succ n' ➔ mult (succ n') (rec n')
  }.
\end{verbatim}
  \caption{Factorial with explicit and implicit coercions}
  \label{fig:ex-data-fact}
\end{figure}

The reader may wonder at this point what other ways \texttt{Nat} and
recursive-occurence types like \texttt{rec/type} are related when there is a
witness of type \texttt{Nat/Mu ·rec/type}. In addition to allowing the user to
pattern-match on terms of type \texttt{rec/type} as they would with e.g.
\texttt{Nat}, Cedilleum provides a way for users to coerce (with zero runtime
cost) such terms to the concrete data-type. As a motivating example, consider
trying to implement the factorial function: in the constructor case \texttt{succ
n'}, we want to multiply the original number by the factorial (calculated via
recursion) of its predecessor. Two implementations of factorial are shown in
Figure \ref{fig:ex-data-fact}, showing how this conversion is done in Cedilleum.

In the first version, \texttt{fact1}, an explicit cast \texttt{Nat/cast -rec/mu n'} is used
to convert the \texttt{n'} of type \texttt{rec/type} to a \texttt{Nat};
\texttt{Nat/cast} is a function automatically generated from the definition of datatype
\texttt{Nat} and has type \texttt{∀ R: ★. Nat/Mu ·R ➾ R ➔ Nat}. Furthermore,
Cedilleum's built-in equality type recognizes that this term is equal to the
identity function (after erasure -- recall that \texttt{-rec/mu} inducates that
the witness is given as an irrelevant or erased argument to \texttt{Nat/cast});
this is witnessed by the proof \texttt{NatCast-id}, which holds by conversion
checking.

Frequently, the insertion of such casts can be deduced merely by comparing the
``expected'' and ``actual'' type of an expression, and having these coercions
stated explicitly is both tedious to write and to read. To that end, the type
system of Cedilleum implements a form of subtyping between the
recursive-occurence types and the concrete data-type. Behind the scenes, type
inference will automatically insert the appropriate coercions (possibly after
η-expanding the expression). A simple example of this is shown in definition
\texttt{fact2}: the variable \texttt{n'} has ``actual'' type \texttt{rec/type}, and its
``expected'' type in expression \texttt{succ n'} is \texttt{Nat}, so the
expression is well typed through type subsumption since \texttt{rec/type <:
  Nat}, as witnessed by evidence \texttt{rec/mu} of type \texttt{Nat/Mu
  ·rec/type} (here bound but not used explicitly).

\subsection{Reasoning via Induction}
\label{sec:induction}
\begin{figure}[h]
\begin{verbatim}
add-zero-r : Π m: Nat. {add m zero ≃ m}
  = λ m. μ ih. m @(λ x: Nat. {add x zero ≃ x}) {
         | zero   ➔ β
         | succ r ➔ χ {succ (add r zero) ≃ succ r} - ρ (ih r) - β
         } .
\end{verbatim}
  \caption{A proof via induction}
  \label{fig:ex-data-ind}
\end{figure}
Figure \ref{fig:ex-data-ind} shows a simple proof that \texttt{zero} is the
right identity of \texttt{add} using induction on \texttt{Nat}. In the base
case, pattern \texttt{zero} is substituted for \texttt{x} in the motive, and the
expected result type of the branch is \texttt{\{add zero zero ≃ zero\}}, which
is true by reflexivity (notated \texttt{β}) after conversion. In the step case,
pattern \texttt{succ r} (equivalently \texttt{succ (Nat/cast -ih/mu r)}) is
substituted in for \texttt{x} in the motive, and the expected result type of the
branch is \texttt{\{add (succ r) zero ≃ succ r\}} (\texttt{Nat/cast -ih/mu r}
reduces to \texttt{r}). Operator χ allows users to write type annotations, and
here it is used to converted the expected type to \texttt{\{succ (add r zero) ≃
succ r\}}. Next, the ρ operator allows the user to rewrite the expected type
using an equation, and here the equation used is the one given by the inductive
hypothesis \texttt{ih r} of type \texttt{\{add r zero ≃ r\}}. After rewriting,
the expected type is simply \texttt{\{succ r ≃ succ r\}} which holds by β.

\subsection{Reduction Rules of μ and μ'}
Section \ref{sec:induction} omits some details about checking convertibility of
terms defined using μ and μ'. For example, in Figure \ref{fig:ex-data-ind} the expected type
corresponding to the branch \texttt{succ r} in the definition of
\texttt{add-zero-r} is \texttt{\{add (succ r) zero ≃ succ r\}}. By
β-reduction and erasure alone, this reduces to
\begin{verbatim}
{ μ rec. (succ r) {
  | zero ➔ zero
  | succ p ➔ succ (rec p)
  } ≃ succ r
}
\end{verbatim}

To get the left-hand side of this equation to be convertible with \texttt{succ
(add r zero)}, we need a μ-reduction rule. μ-reduction is a combination of
fix-point unrolling and case-branch selection, the latter of which is usually
called δ-reduction for languages with inductive data-types. Here, because the
scrutinee is \texttt{succ r}, then entire μ-expression reduces to the body of
the case-branch guarded by \texttt{succ p} (case-branch selection), with
recursive function \texttt{rec} replaced by the entire μ-expression itself
(fixpoint unrolling). Thus, the equation above reduces to
\begin{verbatim}
{ succ (μ rec. r {
  | zero ➔ zero
  | succ p ➔ succ (rec p)
  }) ≃ succ r
}
\end{verbatim}

\noindent where the left-hand side is now convertible with \texttt{succ (add r
  zero)}. μ'-reduction only performs case-branch selection.

\subsection{Non-strictly Positive Datatypes}
\label{sec:positive-data}
In the preceeding sections, we have that seen ``cast'' functions like
\texttt{Nat/cast -ih/mu} (in Section \ref{sec:induction}) show up in the the expected
type of a case branch, and also have noted already that Cedilleum allows for
positive but not strictly positive data type defintions. We now examine
how these two things interact.

\begin{figure}[h]
\begin{verbatim}
data PTree : ★ =
  | leaf : PTree
  | node : ((PTree ➔ Bool) ➔ PTree) ➔ PTree
.

indPTree1 : ∀ P: PTree ➔ ★.
    P leaf ➔ (∀ s: (PTree ➔ Bool) ➔ PTree. (Π p: PTree ➔ Bool. P (s p)) ➔ P (node s)) ➔
    Π t: PTree. P t
  = Λ P. λ base. λ step. λ t. μ ih. t @(λ x: PTree. P x) {
  | leaf ➔ base
  | node s ➔
    [ s1 : (PTree ➔ Bool) ➔ ih/type = λ p. s (λ t. p (Nat/cast -ih/mu p)) ]
  - [ s2 : (PTree ➔ Bool) ➔ PTree = λ p. Nat/cast -ih/mu (s1 p) ]
  - step -s2 (λ p. ih (s1 p))
  }.

indPTree2 : ∀ P: PTree ➔ ★.
    P leaf ➔ (∀ s: (PTree ➔ Bool) ➔ PTree. (Π p: PTree ➔ Bool. P (s p)) ➔ P (node s)) ➔
    Π t: PTree. P t
  = Λ P. λ base. λ step. λ t. μ ih. t @(λ x: PTree. P x) {
  | leaf ➔ base
  | node s ➔ step -s (λ p. ih (s p))
  }.
\end{verbatim}
  \caption{A non-strictly positive infinitary tree}
  \label{fig:ptree}
\end{figure}

Figure \ref{fig:ptree} presents a definition of \texttt{PTree}, an infinitary
tree which is not strictly positive in the \texttt{node} constructor, and two
proofs of induction for it, one using explicit coercions and one utilizing
subtyping to infer these coercions. As a type, \texttt{PTree} is a somewhat
contrived example, but one intuition for what kind of terms inhabit it is ``at a
\texttt{node}, there must be some way of selecting some sub-tree using a
predicate \texttt{PTree ➔ Bool}''.

In both versions, the branch given by patterm \texttt{leaf} corresponds to the
\texttt{base} case, requiring a proof of \texttt{P leaf}. For the \texttt{step}
case, the expected type is \texttt{P (node s)} (equivalently \texttt{P (node
  s2)}, where \texttt{s2} is locally defined in \texttt{indPTree1}). Here,
\texttt{s} has type \texttt{(ih/type ➔ Bool) ➔ ih/type}, and the two different
occurences of \texttt{s} in the arguments to \texttt{step} require it to have
two different but related types, corresponding resp. to the types of \texttt{s2}
and \texttt{s1} in \texttt{indPTree1}. Again, the subtyping problems
\texttt{(ih/type ➔ Bool) ➔ ih/type <: (PTree ➔ Bool) ➔ PTree} and
\texttt{(ih/type ➔ Bool) ➔ ih/type <: (PTree ➔ Bool) ➔ ih/type} can be
solved, with coercions implicitly inserted, algorithmically by
inverting the type constructors of the sub- and super-types, so definition
\texttt{indPTree2} is also admissable.

\subsection{Program Reuse}
We conclude our informal introduction to Cedilleum with a somewhat more complex
example: how to support program reuse over different data-types at zero
run-time cost. Often, when working in a setting with dependent types,
programmers find they must write several different versions of a datatype
depending upon the invariants they wish to enfore by the type system. A classic
example is non-indexed \texttt{List} and length-indexed \texttt{Vec} -- if the
programmer has writen several functions for the former, and discovers that they
must rework their code because they need the latter, their choices are usually
either to re-implement the existing \texttt{List} functions for \texttt{Vec}, or to write
conversion functions between \texttt{List} and \texttt{Vec} to re-use the
existing functions. For this second option, such conversion functions usually must
tear down one structure while rebuilding the other, taking linear time. In
Cedileum it is possible to define \textit{zero-cost} coercions between
\texttt{List} and \texttt{Vec} and indeed between many different types, provided
that certain conditions hold.

To start, we give the definitions for \texttt{List} and for function
\texttt{l2v'} which one could write in virtually any dependently typed language.

\begin{verbatim}
data List (A: ★): ★ =
  | nil : List
  | cons : A ➔ List ➔ List
  .

len : ∀ A: ★. List ·A ➔ Nat
  = Λ A. λ xs. μ rec. xs {
  | nil ➔ zero
  | cons x xs ➔ succ (rec xs)
  }.

append : ∀ A: ★. List ·A ➔ List ·A ➔ List ·A
  = Λ A. λ xs. λ ys. μ rec. xs {
  | nil ➔ ys
  | cons x xs ➔ cons x (rec xs)
 }.

l2v' : ∀ A: ★. Π xs: List ·A. Vec ·A (len xs)
  = Λ A. λ xs. μ ih. xs @(λ x: List ·A. Vec ·A (len x)) {
  | nil       ➔ vnil ·A
  | cons x xs ➔ vcons -(len (List/cast -ih/mu xs)) x (ih xs)
  }.
\end{verbatim}

Next we see something unique to Cedilleum: the pairs of constructors \texttt{nil}
and \texttt{vnil}, and \texttt{cons} and \texttt{vcons}, are provably equal.
This is necessary (though not sufficient) for proving
\texttt{l2v-reflection}, which states that conversion function \texttt{l2v}
behaves extensionally like an identity function.

\begin{verbatim}
-- constructor equalities
l2v-eq-nil  : {nil  ≃ vnil}  = β.
l2v-eq-cons : {cons ≃ vcons} = β.

-- reflection law
l2v-reflection : ∀ A: ★. Π xs: List ·A. {l2v xs ≃ xs}
  = Λ A. λ xs. μ ih. xs @(λ x: List ·A. {l2v x ≃ x}) {
  | nil       ➔ χ {nil ≃ vnil} - β
  | cons x xs ➔ χ {vcons x (l2v xs) ≃ cons x xs}
  - ρ (ih xs) - β
  }.
\end{verbatim}

How is it that Cedilleum decides these constructors are convertible? The precise
details depend upon the shape of the λ-terms to which Cedilleum elaborates the
data-type declarations, but, if \texttt{c} is a constructor of type \texttt{C}
and \texttt{d} is a constructor of type \texttt{D} (not necessarily distinct for
\texttt{C}), then the general rules are:

\begin{enumerate}
\item \texttt{C} and \texttt{D} must have the same number of constructors.

  In the definition \texttt{data Unit: ★ = | triv : Unit .}, \texttt{triv} would
  not be equal to any constructor of any data-type seen so far in this document,
  as \texttt{Unit} has only one constructor and \texttt{Nat}, \texttt{Bool},
  \texttt{List}, \texttt{Vec}, and \texttt{PTree} all have two constructors.

\item \texttt{c} and \texttt{d} must occur in the same order in the constructor
  list of their respective data-type declaration

  For example, \texttt{nil} and \texttt{vnil} are both the first listed
  constructor for their types, but for the data-type
\begin{verbatim}
data List' (A: ★): ★ =
  | cons' : A ➔ List' ➔ List'
  | nil'  : List'
.
\end{verbatim}
\noindent which is isomorphic to \texttt{List}, constructor \texttt{nil'} is
\textit{not} convertible with \texttt{nil} and zero-cost reuse between
\texttt{List} and \texttt{List'} is \textit{not} possible. This same condition also
prevents different constructors of the same type from being seen as convertible
(e.g. \texttt{tt} and \texttt{ff} of type \texttt{Bool} are provably distinct).

\item constructors \texttt{c} and \texttt{d} must take the same number of
  unerased arguments. Erased arguments, and even the types of unerased
  arguments, do not matter.

  This is how, in particular, \texttt{cons} and \texttt{vcons} can be equated
  even though \texttt{vcons} takes an additional (erased) \texttt{Nat} argument.
  This also means that some strange constructor equalities hold:

\begin{verbatim}
eq-zero-tt   : {zero ≃ tt} = β. -- {succ ≃ ff} is not provable
eq-zero-leaf : {zero ≃ leaf} = β. 
eq-succ-node : {succ ≃ node} = β.
\end{verbatim}

  Despite the fact that each constructor of \texttt{Nat} is convertible with a
  constructor of \texttt{PTree}, it is not possible to define a conversion
  function \texttt{n2pt : Nat ➔ PTree} for which \texttt{∀ x: Nat. \{n2pt x ≃
    x\}} is provable, which (we will see next) is needed for zero-cost conversions.
\end{enumerate}

To recapitulate, we have a linear-time conversion function \texttt{l2v'} that
we proved behaves extensionally like an identity function. With this, and with the term
construct \texttt{φ}, we can write a conversion function that after erasure is
\textit{intensionally} equal to the identity:

\begin{verbatim}
l2v : ∀ A: ★. Π xs: List ·A. Vec ·A (len xs)
  = Λ A. λ xs. φ (l2v-reflection xs) - (l2v' xs) {xs}.

eq-l2v-id = {l2v ≃ λ x. x} = β.
\end{verbatim}
\noindent In \texttt{l2v}, the entire φ expression erases to the term in curly braces
(\texttt{\{xs\}}), has the type \texttt{Vec ·A (len xs)} of subexpression
\texttt{l2v' xs}, and requires a proof that these two terms are equal (which is
satisfied by \texttt{l2v-reflection xs}).

From this point, the reuse is straight-forward: define reuse in the other
direction (re-use of \texttt{Vec} as \texttt{List}) with \texttt{v2l}, lemma
\texttt{v2l-len} relating the vector index to the length of a list after
conversion, lemma \texttt{append-len} relating the length of the list computed
by \texttt{append} to its two input lists, and finally \texttt{vappend'} which
works by casting its two input \texttt{Vec}s to \texttt{List}s,
\texttt{append}ing them, and casting the result back to \texttt{Vec}. The payoff
comes at the last line of the code listing below: \texttt{v2l-eq-append} proves
that function \texttt{vappend'} is definitionally equal to \texttt{append},
meaning our conversions between the two data-structures required no run-time cost!

\begin{verbatim}
v2l' : ∀ A: ★. ∀ n: Nat. Vec ·A n ➔ List ·A
  = Λ A. Λ n. λ xs. μ rec. xs {
  | vnil ➔ nil ·A
  | vcons -i x xs ➔ cons x xs
  }.

v2l-reflection : ∀ A: ★. ∀ n: Nat. Π xs: Vec ·A n. {v2l' xs ≃ xs}
  = Λ A. Λ n. λ xs. μ ih. v @(λ i: Nat. λ x: Vec ·A i. {v2l' x ≃ x}) {
  | vnil ➔ β
  | vcons -i x xs ➔
    χ {cons x (v2l' xs) ≃ vcons x xs}
  - ρ (ih -i xs) - β
  }.

v2l : ∀ A: ★. ∀ n: Nat. Vec ·A n ➔ List ·A
  = Λ A. Λ n. λ xs. φ (v2l-reflection -n xs) - (v2l' -n xs) {xs}.

v2l-len : ∀ A: ★. ∀ n: Nat. Π xs: Vec ·A n. {n ≃ len (v2l xs)}
  = Λ A. Λ n. λ xs. μ ih. xs @(λ i: Nat. λ x: Vec ·A i. {i ≃ len (v2l x)}) {
  | vnil ➔ β
  | vcons -n' x xs ➔ ρ (ih -n' xs) - β
  }.

append-len : ∀ A: ★. Π xs: List ·A. Π ys: List ·A.
    {add (len xs) (len ys) ≃ len (append xs ys)}
  = Λ A. λ xs. λ ys. μ ih. xs @(λ x: List ·A. {add (len x) (len ys) ≃ len (append x ys)}) {
  | nil ➔ β
  | cons x xs ➔
    χ {succ (add (len xs) (len ys)) ≃ succ (len (append xs ys))}
  - ρ (ih xs) - β
  }.

vappend' : ∀ A: ★. ∀ m: Nat. ∀ n: Nat. Vec ·A m ➔ Vec ·A n ➔ Vec ·A (add m n)
  = Λ A. Λ m. Λ n. λ xs. λ ys.
    [ xs' = v2l -m xs] - [ m-eq = v2l-len -m xs ]
  - [ ys' = v2l -n ys] - [ n-eq = v2l-len -n ys ]
  - ρ m-eq - ρ n-eq - ρ (append-len (v2l -m xs) (v2l -n ys))
  - l2v (append xs' ys').

v2l-eq-append : {append ≃ vappend'} = β.
\end{verbatim}

\section{Syntax}
\label{sec:syntax}

\paragraph{Identifiers}
\begin{figure}[h]
  \[
    \begin{array}{llll}
      id & &
      & \textnormal{identifiers for definitions}
      \\ u,c & &
      & \textnormal{term variables}
      \\ X & &
      & \textnormal{type variables}
      \\ 𝒌 & &
      & \textnormal{kind variables}
      \\ x & ::= & id\ |\ u\ |\ X\
      & \textnormal{non-kind variables}
      \\ y & ::= & x\ |\ 𝒌 & \text{all variables}
    \end{array}
  \]
  \caption{Identifiers}
  \label{fig:identifiers}
\end{figure}

We now turn to a more formal treatment of Cedilleum. Figure
\ref{fig:identifiers} gives the metavariables used in our grammar for
identifiers. For convenience we consider all identifiers as coming from two
distinct lexical ``pools'' -- regular identifiers (consisting of identifiers
$id$ given for modules and definitions, term variables $u$, and type variables
$X$) and kind identifiers $\kappa$. In Cedilleum source files (as in the parent
language Cedille) kind variables should be literally prefixed with $\kappa$ --
the suffix can be any string that would by itself be a legal non-kind
identifier. For example, \texttt{myDef} is only legal as term and type
identifier, and \texttt{𝒌myDeff} is only legal as a kind identifier.

\paragraph{Untyped Terms}
\begin{figure}[h]
  \[
    \begin{array}{llll}
      f, p
      & ::= & u,v,c
      & \text{variables}
      \\ & & \absu{\textbf{λ}}{u}{p}
      & \text{functions}
      \\ & & f\ p
      & \text{applications}
      \\ & & \mufix{u}{p}{pcase^*}
      & \text{fixed-point and pattern matching}
      \\ & & \mumat{p}{pcase^*}
      & \text{simple pattern matching}
      \\ \\ pcase
      & ::= & \textbf{\textbar}\ u\ u^* \mapsto f
    \end{array}
  \]
  \caption{Untyped terms}
  \label{fig:pure-terms}
\end{figure}

The grammar of pure (untyped) terms that of the untyped λ-calculus augmented
with primitive μ for combined pattern-matching and fixpoint recursion and μ' for
``mere'' pattern-matching.

\begin{figure}[h]
  \[
    \begin{array}{llll}
      % module stuff
      \\ mod
      & ::= & \textbf{module}\ id\ \textbf{.}\ imprt^*\ cmd^*\
      & \textnormal{module declarations}
      \\ imprt
      & ::= & \textbf{import}\ id\ \textbf{.}
      & \textnormal{module imports}
      \\ cmd
      & ::= & defTermOrType
      & \textnormal{definitions}
      \\ & & defDataType
      \\ & & defKind
      % definitions
      \\ 
      \\ defTermOrType
      & ::= & id\ checkType^?\ \textbf{=}\ t\ \textbf{.}
      & \textnormal{term definition}
      \\ & & id\ \textbf{:}\ K\ \textbf{=}\ T\ \textbf{.}
      & \textnormal{type definition}
      \\ defKind
      & ::= & 𝒌\ \textbf{=}\ K
      & \text{kind definition}
      \\ defDataType
      & ::= & \textbf{data}\ id\ param^*\ \textbf{:}\ K\ \textbf{=}\
              constr^*\ \textbf{.}
      & \textnormal{datatype definitions}
     % auxilliary categories for definitions
      \\ 
      \\ checkType
      & ::= & \textbf{:}\ T
      & \textnormal{annotation for term definition}
      \\ param
      & ::= & \textbf{(}x\ \textbf{:}\ C \textbf{)}
      \\ constr
      & ::= & \textbf{\textbar}\ id\ \textbf{:}\ T
    \end{array}
  \]
  \caption{Modules and definitions}
  \label{fig:mods-defs}
\end{figure}

\paragraph{Modules and Definitions}
All Cedilleum source files start with production $mod$, which consists of a module
declaration, a sequence of import statements which bring into scope definitions
from other source files, and a sequence of \textit{commands} defining terms,
types, and kinds. As an illustration, consider the first few lines of a
hypothetical \texttt{list.ced}:

\begin{verbatim}
module list .

import nat .
\end{verbatim}
% TODO it also searches all ancestor directories
\noindent Imports are handled first by consulting a global options files
known to the Cedilleum compiler (on *nix systems \verb|~/.cedille/options|)
containing a search path of directories, and next (if that fails) by searching
the directory containing the file being checked.

Term and type definitions are given with an identifier, a classifier (type or
kind, resp.) to check the definition against, and the definition. For term
definitions, giving classifier (i.e. the type) is optional. As an example,
consider the definitions for the type of Church-encoded lists and two variants
of the nil constructor, the first with a top-level type annotation and the
second with annotations sprinkled on binders:

\begin{verbatim}
cList : ★ ➔ ★
      = λ A : ★ . ∀ X : ★ . (A ➔ X ➔ X) ➔ X ➔ X .

cNil  : ∀ A : ★ . cList · A
      = Λ A . Λ X . λ c . λ n . n .
cNil' = Λ A : ★ . Λ X : ★ . λ c : A ➔ X ➔ X . λ n : X . n .
\end{verbatim}

Kind definitions are given without classifiers (all kinds have super-kind
$\Box$), e.g. \verb;𝒌func = ★ ➔ ★;

Inductive datatype definitions take a set of \textit{parameters} (term and type
variables which remain constant throughout the definition) well as a set of
\textit{indices} (term and type variables which can vary in constructor type
signatures), followed by zero or more constructors. Each constructor begins with
``\textbf{\textbar}'' (though the grammar can be relaxed so that the first of
these is optional) and then an identifier and type is given. As an example,
consider the following two definitions for lists and vectors (length-indexed
lists).

\begin{verbatim}
data Bool : ★ =
  | tt : Bool
  | ff : Bool
  .
data Nat : ★ =
  | zero : Nat
  | suc  : Nat ➔ Nat
  .
data List (A : ★) : ★ =
  | nil  : List
  | cons : A ➔ List ➔ List
  .
data Vec (A : ★) : Nat ➔ ★ =
  | vnil  : Vec zero
  | vcons : ∀ n: Nat. A ➔ Vec n ➔ Vec (succ n)
  .
\end{verbatim}

\paragraph{Types and Kinds}
\begin{figure}[h]
  \[
    \begin{array}{rlll}
      \text{Sorts } S
      & ::= & \square & \text{sole super-kind}
      \\ & & K & \text{kinds}
      \\ \text{Classifiers } C
      & ::= & K & \text{kinds}
      \\ & & T & \text{types}
      \\ \text{Kinds } K
      & ::= & \textbf{Π}\ x\ \textbf{:}\ C\ \textbf{.}\ K
      & \textnormal{explicit product}
      \\ & & C\ \textbf{➔}\ K
      & \textnormal{kind arrow}
      \\ & & \textbf{★}
      & \text{the kind of types that classify terms}
      \\ & & \textbf{(}K\textbf{)}
      \\ 
      \\ \text{Types } T
      & ::= & \textbf{Π}\ x\ \textbf{:}\ T\ \textbf{.}\ T'
         & \textnormal{explicit product}
      \\ & &  \textbf{∀}\ x\ \textbf{:}\ C\ \textbf{.}\ T'
         & \textnormal{implicit product}
      \\ & &  \textbf{λ}\ x\ \textbf{:}\ C\ \textbf{.}\ T'
         & \textnormal{type-level function}
      \\ & & T\ \textbf{➾}\ T'
         & \textnormal{arrow with erased domain}
      \\ & & T\ \textbf{➔}\ T'
         & \textnormal{normal arrow type}
      \\ & & T\ \textbf{·}\ T'
         & \text{application to another type}
      \\ & & T\ t
         & \text{application to a term}
      \\ & & \textbf{\{}\ p\ ≃\ p' \textbf{\}}
                      & \textnormal{untyped equality}
      % \\ & & \textbf{ι}\ x: T.\ T'
      %                 & \textnormal {dependent intersection}
      \\ & & \textbf{(}T\textbf{)}
      \\ & & X
         & \text{type variable}
      \\ & & \bullet
         & \text{hole for incomplete types}
    \end{array}
  \]
  \caption{Kinds and types}
  \label{fig:kinds-types}
\end{figure}

In Cedilleum, the expression language is stratified into three main ``classes'':
kinds, types, and terms. Kinds and types are listed in Figure
\ref{fig:kinds-types} and terms are listed in Figure \ref{fig:ann-terms} along
with some auxiliary grammatical categories. In both of these figures, the
constructs forming expressions are listed from lowest to highest precedence --
``abstractors'' ($\lambda\ \Lambda\ \Pi\ \forall$) bind most loosely and
parentheses most tightly. Associativity is as-expected, with arrows (➔ ➾) and
abstractors being right-associative and applications being left-associative.

% TODO cite
The language of kinds and types is similar to that found in the Calculus of
Implicit Constructions\footnote{Cite}. Kinds are formed by dependent and
non-dependent products (Π and ➔) and a base kind for types which can classify
terms (★). Types are also formed by the usual (dependent and non-dependent)
products (Π and ➔) and also \textit{implicit} products (∀ and ➾) which quantify
over erased arguments (that is, arguments that disappear at run-time).
Π-products are only allowed to quantify over terms as all types occurring in
terms are erased at run-time, but ∀-products can quantify over types
\textit{and} terms because terms can be erased. Meanwhile, non-dependent
products (➔ and ➾) can only ``quantify'' over terms because non-dependent type
quantification does not seem particularly useful. Besides these, Cedilleum
features type-level functions and applications (with term and type arguments),
and a primitive equality type for untyped terms. Last of all is the ``hole''
type (●) for writing partial type signatures or incomplete type applications.
There are term-level holes as well, and together the two are intended to help
facilitate ``hole-driven development'': any hole automatically generates a type
error and provides the user with useful contextual information.

We illustrate with another example: what follows is a module stub for
\textbf{DepCast} defining dependent casts -- intuitively, functions from $a : A$
to $B\ a$ that are also equal\footnote{Module erasure, discussed below} to
identity -- where the definitions \texttt{CastE} and \texttt{castE} are
incomplete.

\begin{verbatim}
module DepCast .

CastE ◂ Π A : ★ . (A ➔ ★) ➔ ★ = ● .
castE ◂ ∀ A : ★ . ∀ B : A ➔ ★ . CastE · A · B ➾ Π a : A . B a = ● .
\end{verbatim}
  
\paragraph{Annotated Terms}
\begin{figure}[h]
  \[
    \begin{array}{rlll}
      \text{Subjects } s
      & ::= & t & \text{term}
      \\ & & T & \text{type}
      \\ \text{Terms } t
      & ::= & \textbf{λ}\, x\ class^?\! \textbf{.}\, t
      & \textnormal{normal abstraction}
      \\ & & \textbf{Λ}\, x\ class^?\! \textbf{.}\, t
      & \textnormal{erased abstraction}
      \\ & & \textbf{[}\ defTermOrType\ \textbf{]}\ \textbf{-}\ t
      & \text{let definitions}
      \\ & & \textbf{ρ}\ t\ \textbf{-}\ t'
      & \text{equality elimination by rewriting}
      \\ & & \textbf{φ}\ t\ \textbf{-}\ t'\ \textbf{\{} t'' \textbf{\}}
      & \text{type cast}
      \\ & & \textbf{χ}\ T\ \textbf{-}\ t
      & \text{check a term against a type}
      \\ & & \textbf{δ}\ \textbf{-}\ t
      & \text{ex falso quodlibet}
      \\ & & \textbf{θ}\ t\ t'^*
      & \text{elimination with a motive}
      \\ & & t\ t'
      & \text{applications}
      \\ & & t\ \textbf{-}t'
      & \text{application to an erased term}
      \\ & & t\ \textbf{·}T
      & \text{application to a type}
      \\ & & \textbf{β}\ \textbf{\{} t \textbf{\}}
      & \textnormal{reflexivity of equality}
      \\ & & \textbf{ς}\ t
      & \textnormal{symmetry of equality}
      \\ & & \mufix{u}{t\ motive^?}{case^*}
      & \textnormal{type-guarded pattern match and fixpoint}
      \\ & & \mumat{t\ motive^?}{case^*}
      & \text{auxiliary pattern match}
      \\ & & u
      & \text{term variable}
      \\ & & \textbf{(}t\textbf{)}
      \\ & & \bullet
      & \text{hole for incomplete term}
      \\ \\ case
      & ::= & \textbf{\textbar}\ c\ vararg^*\ \textbf{↦}\ t
      & \text{pattern-matching cases}
      \\ vararg
      & ::= & u
      & \text{normal constructor argument}
      \\ & & \textbf{-}u
      & \text{erased constructor argument}
      \\ & & \textbf{·}X
      & \text{type constructor argument}
      \\ class
      & ::= & \textbf{:}\ C
      \\ motive
      & ::= & \textbf{@}\ T
      & \textnormal{motive for induction}
    \end{array}
  \]
  \caption{Annotated Terms}
  \label{fig:ann-terms}
\end{figure}

Terms can be explicit and implicit functions (resp. indicated by λ and Λ) with
optional classifiers for bound variables, let-bindings, applications $t\ t'$,
$t\ \mhyph t'$, and $t\ \cdot T$ (resp. to another term, an erased term, or a
type). In addition to this there are a number of useful operators for
equaltional reasoning, type casting, providing annotations, and pattern
matching. Each operator will be discussed in more detail in Section
\ref{sec:type-system}, but a few concrete programs in Cedilleum are given below
merely to give a better idea of the syntax of the language.

\begin{verbatim}
isvnil : ∀ A: ★. ∀ n: Nat. Vec ·A n ➔ Bool
       = Λ A. Λ n. λ xs. μ' xs @(Λ n . λ xs . Bool) {
           | vnil          ↦ tt
           | vcons -n x xs ↦ ff
           }.
vlength : ∀ A: ★. ∀ n: Nat. Vec ·A n ➔ Nat
        = Λ A. Λ n. λ xs. μ len . xs @(Λ n . λ x . Nat) {
            | vnil          ↦ zero
            | vcons -n x xs ↦ suc (len -n xs)
            }.
\end{verbatim}

\section{Erasure and Reduction}

\begin{figure}[h]
  \[
  \begin{array}{lll}
       |x| & = & x 
    \\ |\star| & = & \star 
    \\ |\Box| & = & \Box 
    \\ |\beta\ \{t\}| & = & |t|
    \\ |\delta\ t| & = & |t|
    \\ |\chi\ T^? \textbf{-}\ t| & = & |t| 
    \\ |\varsigma\ t| & = & |t|
    \\ |t\ t'| & = & |t|\ |t'|
    \\ |t\ \mhyph t'| & = & |t| 
    \\ |t\ \cdot T| & = & |t| 
    \\ |\rho\ t\ \mhyph\ t'| & = & |t'| 
    \\ |\abs{\forall}{x}{C}{C'}| & = & \abs{\forall}{x}{|C|}{|C'|}
    \\ |\abs{\Pi}{x}{C}{C'}| & = & \abs{\Pi}{x}{|C|}{|C'|}
    \\ |\abs{\lambda}{u}{T}{t}| & = &  \absu{\lambda}{u}{|t|} 
    \\ |\absu{\lambda}{u}{t}| & = &  \absu{\lambda}{u}{|t|} 
    \\ |\abs{\lambda}{X}{K}{C}| & = &  \abs{\lambda}{X}{|K|}{|C|} 
    \\ |\abs{\Lambda}{x}{C}{t}| & = &  |t| 
    \\ |\phi\ t\ \mhyph\ t'\ \{t''\}| & = & |t''| 
    \\ |[ x = t : T]|\ \mhyph\ t' | & = & (\absu{\lambda}{x}{|t'|})\ |t|
    \\ |[X = T : K]\ \mhyph\ t | & = & |t| 
    \\ |\{ t \simeq t' \}|| & = & \{ |t| \simeq |t'| \}
    \\ |\mufix{u,}{t\ motive^?}{case^*}|
           & = & \mufix{u}{|t|}{|case^*|}
    \\ |\mumat{t\ motive^?}{case^*}|
           & = & \mumat{|t|}{|case^*|}
    \\ \\ |id\ vararg^* \mapsto t| & = & id\ |vararg^*|\ \mapsto |t|
    \\ 
    \\ |\mhyph u| & = & 
    \\ |\cdot X|  & = &
  \end{array}
  \]
  \caption{Erasure for annotated terms}
  \label{fig:eraser}
\end{figure}

The definition of the erasure function given in Figure \ref{fig:eraser} takes
the annotated terms from Figures \ref{fig:kinds-types} and \ref{fig:ann-terms} to
the untyped terms of Figure \ref{fig:pure-terms}. The last two equations
indicate that any type or erased arguments in the the zero or more $vararg$'s of
pattern-match case are indeed erased. The additional constructs introduced in
the annotated term language such as β, φ, and ρ, are all erased to the language
of pure terms.

Reduction rules are defined for the untyped term language. In essence, to run a
Cedilleum program you first erase it, then reduce it.

\paragraph{$\beta$-reduction}
\[ (\absu{\lambda}{x}{p_1})\ p_2 \reduce_{\beta} [p_2/x]p_1 \]

The rule for $\beta$-reduction is standard: those expressions consisting of a
$\lambda$-abstraction as the left component of an application reduce by having
their bound variable substituted away by the given argument (where $[p_2/x]$ is
the simultaneous and capture-avoiding substitution of $p_2$ for $x$)

\paragraph{$\mu'$-reduction}
\[ \mu'\ (c_i\ p_1 ... p_n)\ \{...\ | c_i\ u_1 ... u_n \mapsto f\ |...\}
  \reduce_{\mu'} [p_1 ... p_n/u_1 ... u_n]f\]

$\mu'$-reduction is a simple pattern-matching reduction rule: if the scrutinee
of $\mu'$ is some variable-headed application $c_i\ p_1 ... p_n$ where the head
$c_i$ matches one of the branch patterns, replace the entire expression with the
branch body $f$ after substituting each of the bound variables of the branch
pattern $u_1 ... u_n$ with the scrutinee's arguments $p_1 ... p_n$

\paragraph{$\mu$-reduction}
\[ \infer[\mu]
  { \mu\ u. (c\ p_1 ... p_n)\ \{ c_i\ u_{i1} ... u_{ij_i} \mapsto f_i
    \}_{i=1..n} \reduce_{\mu} [p_1 ... p_n/u_1 ... u_n][u/p_{\mu}]f}
  {
    \exists i.\ c\!=\!c_i \land j_i\!=\!n
    \quad p_{\mu} = \absu{\lambda}{v}{\mu\ u.\ v\ \{c_i\ u_{i1} ... u_{ij_i}
      \mapsto f_i\}_{i=1..n}}
  }
\]

$\mu$-reduction is similar to $\mu'$-reduction, but combines with it fixpoint
reduction. Again, if the scrutinee $c\ p_1 ... p_n$ matches one of the branch
patterns $c_i\ u_{i1} ... u_{ij_i}$ (for some $i$, where $j_i = n$), then we
replace the original $\mu$ expression with the matched branch, replacing each of
the pattern variables $u_1 ... u_n$ with the scrutinee's arguments $p_1 ...
p_n$, but \textit{in addition} we also replace the $\mu$-bound variable $u$
(which represents the entire $\mu$ expression itself) with a function $p_\mu$
that takes its argument $v$ and re-creates the original $\mu$ expression by
scrutinizing $v$.

\section{Type System (sans Inductive Datatypes)}
\label{sec:type-system}

\begin{figure}[h]
  \caption{Contexts}
  \[
    \begin{array}{llll}
      \text{ Typing contexts } \Gamma
      & ::= & \emptyset\ |\ \ann{x}{C},\Gamma\ |\ \ann{x=s}{C},\Gamma
    \end{array}
  \]
\end{figure}
\begin{figure}[h!]
  \[ \small
    \begin{array}{lcr}
      \infer{\Gamma\vdash \star : \Box}{\ }
      & \infer
        { \Gamma\vdash\abs{\Pi}{y}{C}{C'} : S'}
        { \Gamma \vdash C : S
        \quad
        \Gamma,y:C\vdash C' : S'
%        \quad \textit{Var}(y,S)
        }
      & \infer
        {\Gamma\vdash\abs{\forall}{y}{C}{C'} : \star}
        {\Gamma \vdash C : S
        \quad \Gamma,y:C\vdash C' : \star
%        \quad \textit{Var}(y,S)
        }
      \\
      \\ \infer
      { \Gamma \vdash \{p \simeq p' \} : \star}
      { FV(p\ p') \subseteq dom(\Gamma) }
      & \infer
        { \Gamma \vdash \kappa : \Gamma(\kappa)}
        { }
      & \infer
        { \Gamma \vdash X : \Gamma(X)}
        { }
      \\
      \\ \infer
      { \Gamma \vdash \abs{\lambda}{x}{C}{T} : \abs{\Pi}{x}{C}{K}}
      { \Gamma \vdash \abs{\Pi}{x}{C}{K} : \square
      \quad \Gamma, \ann{x}{C} \vdash T : K
      }
      & \infer
        { \Gamma \vdash T\ \cdot T' : [T'/x] K'}
        { \Gamma \vdash T : \abs{\Pi}{x}{K}{K'}
        \quad \Gamma \vdash T' : K}
      & \infer
       { \Gamma \vdash T\ t : [t/x] K}
        { \Gamma \vdash T : \abs{\Pi}{x}{T'}{K}
        \quad \Gamma \decchk t : T' }
    \end{array}
  \]
  \caption{Sort checking \fbox{$\Gamma \vdash C : S$}}
  \label{fig:sort-checking}
\end{figure}

\begin{figure}[h!]
  \[ \small
    \begin{array}{lcr}
      \infer
      { \Gamma \decdir u : \Gamma(u)}{}
      & \infer
        { \Gamma \decdir \abs{\lambda}{x}{T}{t} : \abs{\Pi}{x}{T}{T'}}
        { \Gamma \vdash T : K
        \quad \Gamma, \ann{x}{T} \decdir t : T'}
      & \infer
        { \Gamma \decchk \absu{\lambda}{x}{t} : \abs{\Pi}{x}{T}{T'}}
        { \Gamma, \ann{x}{T} \decchk t : T'}
      \\
      \\ \infer
      { \Gamma \decdir \abs{\Lambda}{x}{C}{t} : \abs{\forall}{x}{C}{T}}
      { \Gamma \vdash C : S
      \quad x \notin FV(|t|)
      \quad \Gamma, \ann{x}{C} \decdir t : T
      }
      & \infer
        { \Gamma \decchk \absu{\Lambda}{x}{t} : \abs{\forall}{x}{C}{T}}
        { x \notin FV(|t|)
        \quad \Gamma, \ann{x}{C} \decdir t : T
        }
      & \infer
        { \Gamma \decdir t\ t' : [t'/x]T}
        { \Gamma \decsyn t : \abs{\Pi}{x}{T'}{T}
        \quad \Gamma \decchk t' : T'}
      \\
      \\ \infer
      { \Gamma \decdir t\ \cdot T : [T/X]T'}
      { \Gamma \decsyn t : \abs{\forall}{X}{K}{T'}
      \quad \Gamma \vdash T : K}
      & \infer
        { \Gamma \decdir t\ \mhyph t' : [t'/x]T}
        { \Gamma \decsyn t : \abs{\forall}{x}{T'}{T}
        \quad \Gamma \decchk t' : T'}
      & \infer % conversion... maybe needs to include phi and rho now?
        { \Gamma \decchk t : T }
        { \Gamma \decsyn t : T'
          & |T'| =_{\beta} |T| }
      \\ \\ \infer
      { \Gamma \decdir [ id : T = t ]\ \mhyph\ t' : T'}
      { \Gamma \vdash T : K
        & \Gamma \decchk t : T
        & \Gamma, \ann{id = t}{T} \decdir t' : T'}
      & \infer
        { \Gamma \decdir [ id = t]\ \mhyph\ t' : T' }
        { \Gamma \decsyn t : T
          & \Gamma, \ann{id = t}{T} \decdir t' : T'
        }
      & \infer[\footnotemark] % TODO
        { \Gamma \decdir \rho\ t\ \mhyph\ t' : [t_2/x]\ T}
        { \Gamma \decsyn t : \{ t_1 \simeq t_2 \}
          & \Gamma \decsyn t' : [t_1/x]\ T
        }
      \\ \\ \infer
      { \Gamma \decdir [ id : K = T ]\ \mhyph\ t' : T'}
      { \Gamma \vdash K : \square
        & \Gamma \vdash T : K
        & \Gamma, \ann{id = T}{K} \decdir t' : T'}
      & \infer
        { \Gamma \decchk \beta \{t\} : \{ t' \simeq t' \}}
        { \Gamma \vdash \{ t' \simeq t' \} : \star }
      & \infer
        { \Gamma \decdir \varsigma\ t : \{ t_2 \simeq t_1 \} }
        { \Gamma \decdir t : \{ t_1 \simeq t_2 \}}
      \\ \\ \infer
      { \Gamma \decdir \phi\ t\ \mhyph\ t_1\ \{t_2\} : T}
      { \Gamma \decchk t : \{ |t_1| \simeq |t_2| \}
        & \Gamma \decdir t_1 : T}
      & \infer
        { \Gamma \decsyn \chi\ T\ \mhyph\ t : T }
        { \Gamma \decchk t : T }
      & \infer[\footnotemark]
        { \Gamma \decchk \delta\ \mhyph\ t : T }
        { \Gamma \decchk t : \{ \texttt{tt}\ \simeq\ \texttt{ff} \}}
    \end{array}
  \]
  \caption{Type checking \fbox{$\Gamma \decdir s : C$} (sans inductive datatypes)}
  \label{fig:type-checking}
\end{figure}
\footnotetext{Where we assume $t$ does not occur anywhere in $T$}
\footnotetext{Where $\texttt{tt} = \absu{\lambda}{x}{\absu{\lambda}{y}{x}}$ and
  $\texttt{ff} = \absu{\lambda}{x}{\absu{\lambda}{y}{y}}$}
% TODO kind-variables... two different rules or Var check?
% TODO equality, now that it can have rho, phi

The inference rules for classifying expressions in Cedilleum are stratified into
two judgments. Figure \ref{fig:sort-checking} gives the uni-directional rules
for ensuring types are well-kinded and kinds are well-formed. Future versions of
Cedilleum will allow for bidirectional checking for both typing \textit{and}
sorting, allowing for a unification of these two figures. Most of these rules
are similar to what one would expect from the Calculus of Implicit
Constructions, so we focus on the typing rules unique to Cedilleum.

The typing rule for ρ shows that ρ is a primitive for rewriting by an (untyped)
equality. If $t$ is an expression that synthesizes a proof that two terms $t_1$
and $t_2$ are equal, and $t'$ is an expression synthesizing type $[t_1/x]\ T$
(where, as per the footnote, $t_1$ does not occur in $T$), then we may
essentially rewrite its type to $[t_2/x]\ T$. The rule for β is reflexivity for
equality -- it witnesses that a term is equal to itself, provided that the type
of the equality is well-formed. The rule for ς is symmetry for equality.
Finally, φ acts as a ``casting'' primitive: the rule for its use says that if
some term $t$ witnesses that two terms $t_1$ and $t_2$ are equal, and $t_1$ has
been judged to have type $T$, then intuitively $t_2$ can also be judged to have
type $T$. (This intuition is justified by the erasure rule for φ -- the
expression erases to $|t_2|$). The last rule involving equality is for δ, which
witnesses the logical principle \textit{ex falso quodlibet} -- if a certain
impossible equation is proved (namely that the two Church-encoded booleans
\texttt{tt} and \texttt{ff} are equal), then \textit{any} type desired is
inhabited. The remaining primitive χ allows the user to provide an
explicit top-level annotation for a term.

\section{Inductive Datatypes}
\label{sec:ind-data}

Before we can provide the typing rules for introduction and usage of inductive
datatypes, some auxiliary definitions must be given. The syntax for these, and
the structure of this entire section, borrows heavily from the conventions of the Coq
documentation\footnote{https://coq.inria.fr/refman/language/cic.html\#inductive-definitions}.
The author believes it is worthwhile to restate this development in terms of the
Cedilleum type system, rather than merely pointing readers to the Coq
documentation and asking them to infer the differences between the two systems.

To begin with, the production $defDataType$ gives the concrete syntax for datatype definitions,
but it is not a very useful notation for representing one in the abstract syntax
tree. In our typing rules we will instead use the notation
$\indast{M}{p}{I}{K}{\Sigma}$, where

\begin{itemize}
\item $M$ is a meta-variable ranging over
  constant labels ``C'' and ``A'' (used to distinguish \textbf{c}oncrete and
  \textbf{a}bstracted inductive definitions -- more on this below)
\item $p$ is the number of \textbf{p}arameters of the inductive definition
\item $\Gamma_I$ is a typing context binding \textit{one} type variable $I$, the
  inductive type being defined
\item $\Sigma$ is a typing context containing the $n$ data constructors
  $c_1,...,c_n$ of $I$.
\end{itemize}

For example, consider the \texttt{List} and \texttt{Vec} definitions from
Section \ref{sec:syntax}. These will be represented in the AST as
\\ \\
\[\indast{\text{C}}{1}{List : ★ ➔ ★}
{\begin{array}{lcl}
   nil & : & ∀ A : ★ . List \cdot A
   \\ cons & : & ∀ A : ★ . A ➔ List \cdot A ➔ List \cdot A
 \end{array}
}\] and
\\
\[\indast{\text{C}}{1}{Vec : ★ ➔ Nat ➔ ★}
{\begin{array}{lcl}
   vnil & : & ∀ A: ★.Vec \cdot\!A\ zero
   \\ vcons & : & ∀ A: ★. ∀ n :Nat. A ➔ Vec \cdot\!A\ n ➔ Vec \cdot\!A\ (succ\ n)
 \end{array}
}\]

\noindent All inductive types the user will define will be concrete inductive
defintions, and have global scope. Abstracted definitions are automiatically
generated during fix-point pattern matching, and have local scope.

For an inductive datatype definition to be well-formed, it must satisfy the
following conditions (each of which is explained in more detail in Subsections
\ref{ssec:inductive-aux-defs} and \ref{ssec:inductive-wf-def}):

\begin{itemize}
\item The kind of $I$ must be (at least) a \textit{p-arity of kind ★}.
\item The types of each $id \in \Sigma$ must be \textit{types of constructors
    of $I$}
\item The definition must satisfy the \textit{non-strict} positivity condition.
\end{itemize}

Similarly, the notation in the grammar of Cedilleum $\mu'$ and $\mu$ for pattern
matching is inconvenient, and we will represent them in the AST as resp.
$\mu'(t,P,t_{i=1..n})$ and
$\mu(x_{\text{rec}},I',x_{\text{to}},t,P,t_{i=1..n})$. Translation from the form
given in the grammar to this form is discussed in detail below, but is as
expected. In particular, we enforce that patterns are exhaustive and
non-overlapping, and that $I'$ and $x_{\text{to}}$ (which correspond to the
automatically generated identifiers like \texttt{Nat/ih} and \texttt{fromNat/ih}
from the introduction) are fresh w.r.t the global and local
context. For example, consider the pattern-matches given in the code listings
for \texttt{isvnil} and \texttt{vlength} above. These would be translated into
the AST as
\\ \\
\[
  \mu'(xs,\absu{\Lambda}{n}{\absu{\lambda}{x}{Bool}},
  \begin{array}{l}
    \absu{\texttt{tt}}
    \\ \absu{\Lambda}{n}{\absu{\lambda}{x}{\absu{\lambda}{xs}{\texttt{ff}}}}
  \end{array}
  )
\] and
\[ \mu(len, Vec/len, fromVec/len,xs,\absu{\Lambda}{n}{\absu{\lambda}{x}{Nat}},
  \begin{array}{l}
    \texttt{zero}
    \\ \absu{\Lambda}{n}{\absu{\lambda}{x}{\absu{\lambda}{xs}{succ\ (len\ \mhyph
    n\ xs)}}}
    % \absu{\Lambda}{n}{\absu{\Lambda}{m}{\absu{\lambda}{x}{\absu{\lambda}{xs}{\absu{\Lambda}{eq}{suc\
    % (len\ \mhyph n\ xs)}}}}}
  \end{array})
\]

\noindent In general, the generated name for $I'$ and $x_{\text{to}}$ that users
will write in Cedilleum programs will be of the form ``$I\texttt{/}x_{\text{rec}}$''
and ``$\texttt{from}I\texttt{/}x_{\text{rec}}$''.

For a pattern construct ($\mu$ or $\mu'$) in the AST to be well-formed, it must satisfy the
following conditions (each of which is, again, explained in more detail in
Subsections \ref{ssec:pattern-valid-elim}, \ref{ssec:pattern-wf-pat}, and
\ref{ssec:patern-abstracted-gen}):

\begin{itemize}
\item The motive $P$ must be well-kinded
\item $P$ must be a legal motive to be used in eliminating the inductive type
  $I$ of the scrutinee $t$
\item Each branch $t_i$ must have the type expected given the constructor $c_i
  \in \Sigma$ and the motive $P$.
\end{itemize}

\subsection{Auxiliary Definitions}
\label{ssec:inductive-aux-defs}

\paragraph{Contexts}
To ease the notational burden, we will introduce some conventions for writing
contexts within terms and types.

\begin{itemize}
\item We write $\lambda\,\Gamma$, $\Lambda\,\Gamma$, $\forall\,\Gamma$, and
  $\Pi\,\Gamma$ to indicate some form of abstraction over each variable in
  $\Gamma$. For example, if $\Gamma = \ann{x_1}{T_1},\ann{x_2}{T_2}$ then
  $\absu{\lambda}{\Gamma}{t} =
  \abs{\lambda}{x_1}{T_1}{\abs{\lambda}{x_2}{T_2}{t}}$. Additionally, we
  will also write $\piforall\,\Gamma$ to indicate an arbitrary mixture of $\Pi$
  and $\forall$ quantified variables. Note that \textit{if $\piforall\,\Gamma$
  occurs multiple times within a definition or inference rule}, the intended
  interpretation is that \textit{all occurrences have the same mixture of $\Pi$
    and $\forall$ quantifiers}.
\item $\lenc{\Gamma}$ denotes the length of $\Gamma$ (the number of variables it
  binds)
\item We write $s\ \Gamma$ to indicate the sequence of variable arguments in
  $\Gamma$ given as arguments to $s$. Implicit in this notation is the removal
  of typing annotations from the variables $\Gamma$ when these variables are
  given as arguments to $s$.

  Since in Cedilleum there are three flavors of applications (to a type, to an
  erased term, and to an unerased term), we will only us this notion when the type
  or kind of $s$ is known, which is sufficient to disambiguate the flavor of
  application intended for each particular binder in $\Gamma$. For example,
  if $s$ has type
  $\abs{\forall}{X}{★}{\abs{\forall}{x}{X}{\abs{\Pi}{x'}{X}{X}}}$ and $\Gamma =
  \ann{X}{★},\ann{x}{X},\ann{x'}{X}$ then $s\ \Gamma = s\ \cdot X\ \mhyph x\ x'$
\item $\Delta$ and $\Delta'$ are notations we will use
  for a specially designated contexts associating type variables with both global
  ``concrete'' and local ``abstracted'' inductive data-type declarations.
  The purpose of this latter sort of declaration is to enable type-guided
  termination of definitions using fixpoints (see Section \ref{ssec:typing-rules}) For example, given
  just the (global) data type declaration of $Vec$, we would have $\Delta(Vec) =
  \indast{\text{C}}{1}{\Gamma_{Vec}}{\Sigma}$, where $\Gamma_{Vec} = \ann{Vec}{★ ➔ Nat ➔
    ★}$ and  $\Sigma$ binds data constructors $vnil$ and $vcons$ to the
  appropriate types.
\end{itemize}

\paragraph{$p$-arity}

A kind $K$ is a $p$-arity if it can be written as $\absu{\Pi}{\Gamma}{K'}$ for
some $\Gamma$ and $K'$, where $\lenc{\Gamma} = p$. For an inductive definition
$\indast{M}{p}{\Gamma_I}{\Sigma}$, requiring that the kind $\Gamma_{I}(I)$ is a $p$-arity
of ★ ensures that $I$ \textit{really does have} $p$ parameters.

\paragraph{Types of Constructors}
% TODO: if you look at the `generation of abstracted inductive definitions', it
% uses a different format for the types associated with the constructors in
% \Sigma -- that is the \piforall notation. This section probably should be
% reworked to that end.
$T$ is a \textit{type of a constructor of $I$} iff
\begin{itemize}
\item it is $I\ s_1 ... s_n$
\item it can be written as $\abs{\forall}{s}{C}{T}$ or $\abs{\Pi}{s}{C}{T}$,
  where (in either case) $T$ is a type of a constructor of $I$
\end{itemize}

\paragraph{Positivity condition}
The positivity condition is defined in two parts: the positivity condition of
a type $T$ of a constructor of $I$, and the positive occurence of $I$ in $T$.
We say that a type $T$ of a constructor of $I$ satisfies the positivity condition
when

\begin{itemize}
\item $T$ is $I\ s_1... s_n$ and $I$ does not occur anywhere in $s_1...s_n$
\item $T$ is $\abs{\forall}{s}{C}{T'}$ or $\abs{\Pi}{s}{C}{T'}$, $T'$ satisfies
  the positivity condition for $I$, and $I$ occurs \textit{only} positively in $C$ 
\end{itemize}

\noindent We say that $I$ occurs only positively in $T$ when
\begin{itemize}
\item $I$ does not occur in $T$
\item $T$ is of the form $I\ s_1 ... s_n$ and $I$ does not occur in $s_1 ...
  s_n$
\item $T$ is of the form $\abs{\forall}{s}{C}{T'}$ or $\abs{\Pi}{s}{C}{T'}$, $I$
  occurs only positively in $T'$, and $I$ \textit{does not} occur positively in $C$
\end{itemize}

\subsection{Well-formed inductive definitions}
\label{ssec:inductive-wf-def}

Let $\Gamma_{\text{P}},\Gamma_I,$ and $\Sigma$ be contexts such that $\Gamma_I$
associates a single type-variable $I$ to kind $\absu{\Pi}{\Gamma_{\text{p}}}{K}$ and
$\Sigma$ associates term variables $c_1 ... c_n$ with corresponding types
$\absu{\forall}{\Gamma_{\text{P}}}{T_{1}},...\absu{\forall}{\Gamma_{\text{P}}}{T_{n}}$.
Then the rule given in Figure \ref{fig:inductive-intro} states when an inductive
datatype definition may be introduced, provided that the following side
conditions hold:

\begin{figure}[h]
  \caption{Introduction of inductive datatype}
  \label{fig:inductive-intro}
  \[
    \infer
    { \indast{M}{p}{\Gamma_I}{\Sigma}\ wf}
    { \emptyset \vdash \Gamma_I(I) : \square
      \quad \lenc{\Gamma_P} = p
      \quad (\Gamma_I,\Gamma_P \vdash T_i : ★)_{i=1..n}
    }
  \]
\end{figure}

\begin{itemize}
  \item Names $I$ and $c_1..c_n$ are distinct from any other inductive datatype
    type or constructor names, and distinct amongst themselves
  \item Each of $T_1..T_n$ is a type of constructor of $I$ which satisfies the
    positivity condition for $I$. Furthmore, each occurence of $I$ in $T_i$ is
    one which is applied to the parameters $\Gamma_P$.
  \item Identifiers $I$, $c_1,...,c_n$ are fresh w.r.t the global context, and
    do not overlap with each other nor any identifiers in $\Gamma_P$.
\end{itemize}

When an inductive data-type has been defined using the $defDataType$ production,
it is understood that this always a concrete inductive type, and it (implicitly)
adds to a global typing context the variable bindings in $\Gamma_I$ and
$\Sigma$. Similarly, when checking that the kind $\Gamma_I(I)$ and type $T_i$
are well-sorted and well-kinded, we assume an (implicit) global context of
previous definitions.

\subsection{Valid Elimination Kind}
\label{ssec:pattern-valid-elim}

\begin{figure}[h]
  \caption{Valid elimination kinds}
  \label{fig:valid-elim-kind}
  \[
    \begin{array}{ccc}
      \infer
      { \llbracket T : ★\ |\ T \to ★ \rrbracket }
      { }
      & \infer
        { \llbracket T : \abs{\Pi}{s}{C}{K}\ |\ \abs{\Pi}{s}{C}{K'} \rrbracket}
        { \llbracket T\ s : K\ |\ K' \rrbracket }
    \end{array}
  \]
\end{figure}

When type-checking a pattern match (either $\mu$ or $\mu'$), we need to know
that the given motive $P$ has a kind $K$ for which elimination of a term with
some inductive data-type $I$ is permissible. We write this judgment as
$\llbracket \ann{T}{K'} | K \rrbracket$, which should be read ``the type $T$ of kind $K'$ can
be eliminated through pattern-matching with a motive of kind $K$''. This
judgment is defined by the simple rules in Figure \ref{fig:valid-elim-kind}. For
example, a valid elimination kind for the indexed type family $Vec\ \cdot X$
(which has kind $\abs{\Pi}{n}{Nat}{★}$) is $\abs{\Pi}{n}{Nat}{\abs{\Pi}{x}{Vec\
    \cdot X\ n}{★}}$

\subsection{Valid Branch Type}

Another piece of kit we need is a way to ensure that, in a pattern-matching
expression, a particular branch has the correct type given a particular
constructor of an inductive data-type and a motive. We write $\llbrace c : T
\rrbrace^P_I$ to indicate the type corresponding to the (possibly partially
applied) constructor $c$ of $I$ and its type $T$. We
abbreviate this notation to $\llbrace c \rrbrace^P$ when the inductive type
variable $I$, and the type $T$ of $c$, is known from the (meta-language) context.

\[
  \begin{array}{rcl}
    \llbrace c : I\ \vars{T}\ \vars{s} \rrbrace^P_I
    & = & P\ \vars{s}\ c
    \\ \llbrace c : \abs{\forall}{x}{T'}{T} \rrbrace^P_I
    & = & \abs{\forall}{x}{T'}{\llbrace c\ \mhyph x : T \rrbrace^P_I }
    \\ \llbrace c : \abs{\forall}{x}{K}{T} \rrbrace^P_I
    & = & \abs{\forall}{x}{K}{\llbrace c\ \cdot x : T \rrbrace^P_I }
    \\ \llbrace c : \abs{\Pi}{x}{T'}{T} \rrbrace^P_I
    & = & \abs{\Pi}{x}{T'}{\llbrace c\ x : T \rrbrace^P_I }
  \end{array}
\]

\noindent where we leave implicit the book-keeping required to separate the
parameters $\vars{T}$ from the indicies $\vars{s}$.

The biggest difference bewteen this definition and the similar one found in the
Coq documentation is that types can have implicit and explicit quantifiers, so
we must make sure that the types of branches have implicit / explicit
quantifiers (and the subjects $c$ have applications for types, implicit terms, and
explicit terms), corresponding to those of the arguments to the data constructor
for the pattern for the branch.

\subsection{Well-formed Patterns}
\label{ssec:pattern-wf-pat}

\begin{figure}[h]
  \caption{Well-formedness of a pattern}
  \label{fig:wf-pattern}
  \[
    \infer
    { \wfpat{\Gamma,\Delta}{\indast{M}{p}{\Gamma_I}{\Sigma}}{\vars{T}}{\mu'(t,P,t_{i=1..n})}
    }
    { \Gamma \vdash P : K
      \quad \Sigma = \ann{c_1}{\absu{\forall}{\Gamma_P}{T_1}}, ..., \ann{c_n}{\absu{\forall}{\Gamma_P}{T_n}}
      \quad \lenc{\vars{T}} = \lenc{\Gamma_p} = p
      \quad \llbracket I\ \vars{T}\, : \Gamma(I)\, |\, K \rrbracket
      \quad (\Gamma,\Delta \decchk t_i : \llbrace c_i\ \vars{T} \rrbrace^P)_{i=1..n}
    }
  \]
\end{figure}

% TODO 
Figure \ref{fig:wf-pattern} gives the rule for checking that a pattern
$\mu'(t,P,t_{i=1..n})$ is well-formed. We check that the motive $P$ is
well-kinded at kind $K$, that the given parameters $\vars{T}$ match the expected
number $p$ from the inductive data-type declaration, that an inductive data-type
$I$ instantiated with the given parameters $\vars{T}$ can be eliminated to a
type of kind $K$, and that the given branches $t_i$ account for each of the
constructors $c_i$ of $\Sigma$ and have the required branch type $\llbrace c_i\
\vars{T} \rrbrace^P$ under the given local context $\Gamma$ and context of
inductive data-type declarations $\Delta$.

\subsection{Generation of Abstracted Inductive Definitions}
\label{ssec:patern-abstracted-gen}

Cedilleum supports \textit{histomorphic} recursion (that is, having access to
all previous recursive values) where termination is ensured
through typing. In order to make this possible, we need a mechanism for tracking
the global definitions of \textit{concrete} inductive data types as well the
locally-introduced \textit{abstract} inductive data type representing the
recursive occurences suitable for a fixpoint function to be called on.

If $I$ is an inductive type such that $\Delta(I) =
\indast{\text{C}}{p}{\Gamma_I}{\Sigma}$ and $I'$ is a fresh type variable, then we
define function $Hist(\Delta,I,\vars{T},I')$ producing an abstracted (well-formed)
inductive definition $\indast{\text{A}}{0}{\Gamma_{I'}}{\Sigma'}$, where

\begin{itemize}
\item $\Gamma_{I'}(I') = \absu{\forall}{\Gamma_D}{★}$ if $\Gamma_{I}(I) =
  \absu{\forall}{\Gamma_{P}}{\absu{\forall}{\Gamma_D}{★}}$ (and $\lenc{\Gamma_P}
  = \lenc{\vars{T}} = p$)

  That is, the kind of $I'$ is the same as the kind of $I\ \vars{T}$
\item $\Sigma' = \ann{c'_1}{\absu{\forall}{\Gamma_D}
    { \absu{\piforall}{\Gamma_{A'_1}}{I'\ \Gamma_D} }},...,
  \ann{c'_n}{\absu{\forall}{\Gamma_D}
    { \absu{\piforall}{\Gamma_{A'_n}}{I\ \vars{T}\ \Gamma_D} }}$,

  when each of the concrete constructors $c_i$ in $\Sigma$ are associated with
  type $\absu{\forall}{\Gamma_P}{
    \absu{\forall}{\Gamma_D}{ \absu{\piforall}{\Gamma_{A_i}}{I\ \Gamma_P\
        \Gamma_D} } }$ and each $\Gamma_{A'_i} =
  [\absu{\lambda}{\Gamma_P}{I'}/I,\vars{T}/\Gamma_P]\Gamma_{A_i}$.

  That is, trasforming the concrete constructors of the inductive datatype $I$
  to ``abstracted'' constructors involves replacing each recursive occurrence of
  $I\ \Gamma_P$ with the fresh type variable $I$, and instantiating each of the
  parameters $\Gamma_P$ with $\vars{T}$.
\end{itemize}

Users of Cedilleum will see ``punning'' of the concrete constructors $c_i$ and
abstracted constructors $c'_i$. In particular, when using fix-point pattern
matching branch labels will be written with the constructors for the concrete
inductive data-type, and the expected type of a branch given by the motive will
pretty-print using the concrete constructors. In the inference rules, however,
we will take more care to distinguish the abstract constructors (see Subsection
\ref{ssec:typing-rules}).

\subsection{Typing Rules}
\label{ssec:typing-rules}

\begin{figure}[h]
  \caption{Use of an inductive datatype $\indast{M}{p}{\Gamma_I}{\Sigma}$}
  \label{fig:inductive-use}
  \[ \footnotesize
    \begin{array}{c}
      \infer
      { \Gamma,\Delta \decdir \mu'(t,P,t_{i=1..n}) : P\ \vars{s}\ t}
      { \Gamma \decsyn t : I\ \vars{T}\ \vars{s}
      \quad \wfpat{\Gamma,\Delta}{\Delta(I)}{\vars{T}}{\mu'(t,P,t_{i=1..n})}
      }
      \\ \\
      \\ \infer
      { \Gamma,\Delta \decdir \mu(x_{\text{rec}}, I',
      x_{\text{to}},t,P,t_{i=1..n}) : P\ \vars{s}\ t
      }
      {
      \begin{array}{c}
        \begin{array}{cccc}
          \Gamma \decsyn t : I\ \vars{T}\ \vars{s}
          & \Delta(I) = \indast{\text{C}}{p}{\Gamma_I}{\Sigma}
          & \Gamma_I(I) =
            \absu{\Pi}{\Gamma_P}{\absu{\Pi}{\Gamma_{\text{D}}}{★}},\lenc{\Gamma_P}
            = p
          & Hist(\Delta,I,\vars{T},I') = \indast{\text{A}}{0}{\Gamma_{I'}}{\Sigma'}
        \end{array}
        \\ \\
        \begin{array}{cc}
          \Gamma' = \Gamma,\Gamma_{I'},
          \ann
           {x_{\text{to}}=\absu{\Lambda}{\Gamma_D}{\absu{\lambda}{x}{x}}}
           { \absu{\forall}{\Gamma_{\text{D}}}{I'\
            \Gamma_{\text{D}} \to I\ \vars{T}\
            \Gamma_{\text{D}}}},
          \ann{x_{\text{rec}}}{\absu{\forall}{\Gamma_{\text{D}}}{\abs{\Pi}{x}{I'\
          \Gamma_{\text{D}}}{P\ \Gamma_{\text{D}}\ (x_{\text{to}}\ \Gamma_D\ x)}
          }}
          & \Delta' = \Delta,Hist(\Delta,I,\vars{T},I')
        \end{array}
        \\ \\
        \begin{array}{cc}
          % P' = \absu{\lambda}{\Gamma_D}{\abs{\lambda}{x}{I\ \vars{T}\ \Gamma_D}{P\ 
          % \Gamma_D\ x} }
          \wfpat{\Gamma',\Delta'}{\Delta'(I')}{\varnothing}{\mu'(t,P,t_{i=1..n})}
        \end{array}
      \end{array}
      }
    \end{array}
  \]
\end{figure}

The first rule of Figure \ref{fig:inductive-use} is for typing simple pattern
matching with $\mu'$. We need to know that the scrutinee $t$ is well-typed at
some inductive type $I\ \vars{T}\ \vars{s}$, where $\vars{T}$ represents the
parameters and $\vars{s}$ the indicies. Then we defer to the judgment
$WF\mhyph\!Pat$ to ensure that this pattern-matching expression is a valid
elimination of $t$ to type $P$.

The second rule is for typing pattern-matching with fix-points, and is
significantly more involved. As above we check the scrutinee $t$ has some
inductive type $I\ \vars{T}\ \vars{s}$. We confirm that $I$ is a
\textit{concrete} inductive data-type by looking up its definition in $\Delta$,
and then generate the abstracted definition $Hist(\Delta,I,\vars{T},I')$ for some fresh
$I'$. We then add to the local typing context $\Gamma_{I'}$ (the new inductive
type $I'$ with its associated kind) and two new variables $x_{\text{to}}$ and
$x_{\text{rec}}$.

\begin{itemize}
\item $x_{\text{to}}$ is the \textit{revealer}. It casts a term of an abstracted inductive
  data-type $I'\ \Gamma_D$ to the concrete type $I\ \vars{T}\ \Gamma_D$.
  Crucially, it is an \textit{identity} cast (the implicit quantification
  $\Lambda \Gamma_D$ disappears after erasure). The intuition why this should be
  the case is that the abstracted type $I'$ only serves to mark the recursive
  occurrences of $I$ during pattern-matching to guarantee termination.
\item $x_{\text{rec}}$ is the \textit{recursor} (or the inductive hypothesis).
  Its result type $P'\ \Gamma_D\ x$ utilizes $x_{\text{to}}$ in $P'$ to be
  well-typed, as the $x$ in this expression has type $I'\ \Gamma_D$, but $P$
  expects an $I\ \vars{T}\ \Gamma_D$. Because $x_{\text{to}}$ erases to the identity, uses of the
  $x_{\text{rec}}$ will produce expressions whose types will not interfere with
  producing the needed result for a given branch (see the extended example --
  TODO).
\end{itemize}

\noindent With these definitions, we finish the rule by checking that the
pattern is well-formed using the augmented local context $\Gamma'$ and context
of inductive data-type definitions $\Delta'$.

\section{Elaboration of Inductive Datatypes}
As mentioned in Section \ref{sec:intro}, Cedilleum is not based on CIC. Rather,
its core theory is the \textit{Calculus of Dependent Lambda Eliminations}
(CDLE), whose complete typing rules can are those of Section
\ref{sec:type-system} plus rules for dependent intersections (see
\cite{St18_Cedille-Syntax-Semantics}). That is to say, the preceding treatment
for inductive datatypes (Section \ref{sec:ind-data}) is a high-level and
convenient interface for \textit{derivable} inductive λ-encodings. This section
explains the elaboration process. Since the generic derivation of inductive
data-types with course-of-value induction has been covered in-depth in [TODO],
we omit these details and instead describe the \textit{interface} such
developments provide which data-type elaboration targets.

At a high level, inductive data-types in Cedilleum are first translated to
\textit{identity mappings}, which are (in the non-indexed case) a class of type
schemes \verb;F: ★ ➔ ★; that are more general than functors. The parameter of
the identity scheme replaces all recursive occurrences of the data-type in the
signatures of the constructor and a quantified type variable replaces all
``return type'' occurrences. For example, the type scheme for data-type
\verb;Nat; is \verb;λ R: ★. ∀ X: ★. X ➔ (R ➔ X) ➔ X;, with \verb;R; the
parameter and \verb;X; the quantified variable. For the rest of this
section we assume the reader has at least a basic understanding of impredicative
encodings of datatypes (see \cite{PP89_Inductive-Types-CC} and
\cite{Wa90_Rec-Types-For-Free}) and taking the least fix-point of functors (see
\cite{MFP91_Bananas-Lenses-Envelopes-Barbed-Wire}).

% TODO parameters
The following developments are parameterized by an indexed type scheme $F$ of
kind \verb;(Π Γᵢ. ★) → (Π Γᵢ. ★); corresponding to the kind
\verb;Π Γᵢ. ★; of inductive data-type $I$ declared as $\indast{I}{p}{\Gamma_I}{\Sigma}$

\subsection{Identity Mappings}
Our first task is to describe identity mappings, the class of type schemes
\verb;F: (Π Γᵢ. ★) ➔ Π Γᵢ. ★; we concerned with. Identity mappings are similar to functors
in that they come equipped with a function that resembles
\verb;fmap: ∀ Γᵢ. ∀ A B: Π Γᵢ. ★. Π f: (A ·Γᵢ ➔ B ·Γᵢ). F ·(A ·Γᵢ) ➔ F ·(B ·Γᵢ);
except that it need only be defined for an argument \verb;f; that is equal to the
identity function. We define the type \verb;Id; of such functions and declare
(indicated by \verb;<..>;) its elimination principle \verb;elimIdᵢ;:

\begin{verbatim}
Idᵢ : Π A B: (Π Γᵢ. ★). ι id: ∀ Γᵢ. A Γᵢ ➔ B Γᵢ. {id ≃ λ x. x}.
elimIdᵢ : ∀ A B: (Γᵢ. ★). Idᵢ ·A ·B ➾ A ➔ B = <..>
\end{verbatim}

Recall that since Cedilleum has a Curry-style type system and implicit
products there are many non-trivial functions that erase to identity.
While the definition of \verb;elimIdᵢ; is omitted, it is important to note that
it enjoys the property of erasing to the identity function:
\begin{verbatim}
elimIdᵢ-prop : {elimIdᵢ ≃ λ x. x} = β.
\end{verbatim}

We may now define \verb;IdMapping; as a scheme \verb;F; that comes with a way to
lift identity functions:
\begin{verbatim}
IdMappingᵢ : Π F: (Γᵢ ➔ ★) ➔ (Γᵢ ➔ ★). ★
  = λ F. ∀ A B: (Γᵢ ➔ ★). Ψ Γᵢ. Idᵢ ·A ·B ➔ Idᵢ ·(F ·A) ·(F ·B).
\end{verbatim}

Finally, it is convenient to define \verb;fimap; which given an
\verb;IdMapping; and an \verb;Id; function performs the lifting:
\begin{verbatim}
fimapᵢ : ∀ F: (Π Γᵢ. ★) ➔ (Π Γᵢ. ★). ∀ im: IdMappingᵢ ·F. Castᵢ ·A ·B ➾ F ·A ➔ F ·B
  = Λ F im c. λ f. elimIdᵢ -(im c) f.
\end{verbatim}

From \verb;elimIdᵢ-prop; it should be clear that \verb;fimapᵢ; also erases to
\verb;λ x. x;.

% TODO Re-do View with indexes, too!
\subsection{Type-views of Terms}
A crucial component of course-of-value is the ability to view some term as having
two different types. The idea behind a \verb;View; is similar to that behind the
type \verb;Id; from the previous section, except now we explicitly name the
doubly-typed term:
\begin{verbatim}
View : Π A: ★. A ➔ ★ ➔ ★ = λ A a B. ι b: B. {a ≃ b}
elimView : ∀ A B: ★. Π a: A. View ·A a ·B ➾ B = <..>
elimView-prop : {elimView ≃ λ x. x} = β.
\end{verbatim}

\subsection{λ-encoding Interface}
This subsection describes the interface to which data-type declarations are
elaborated; it is parameterized by an identity mapping.

% TODO module parameters!
\begin{verbatim}
module (Fᵢ: (Π Γᵢ. ★) → (Π Γᵢ. ★)){im: IdMapping ·Fᵢ}.
\end{verbatim}

% TODO explain derivation?
\noindent where parameters \verb;Fᵢ; and \verb;im; are automatically derived from the
declaration of a positive data-type.

With these two parameters alone, the generic developments of [TODO] provide the
following interface for inductive λ-encodings of data-types:

\begin{verbatim}
Fixᵢ : Π Γᵢ. ★ = <..>
inᵢ  : ∀ Γᵢ. Fᵢ ·Fixᵢ Γᵢ ➔ Fixᵢ Γᵢ = <..>
outᵢ : ∀ Γᵢ. Fixᵢ Γᵢ ➔ Fᵢ ·Fixᵢ Γᵢ = <..>

PrfAlgᵢ : Π P: (Π Γᵢ. Π d: Fixᵢ Γᵢ. ★). ★
  = λ P. ∀ R: (Π Γᵢ. ★).
      ∀ c: Idᵢ ·R ·Fixᵢ.
      Π v: View ·(∀ Γᵢ. Fixᵢ Γᵢ ➔ Fᵢ ·Fixᵢ Γᵢ) out ·(∀ Γᵢ. R Γᵢ ➔ Fᵢ ·R Γᵢ).
      Π ih: (∀ Γᵢ. Π r: R Γᵢ. P Γᵢ (elimIdᵢ -c -Γᵢ r)).
      Π Γᵢ. Π fr. F ·R Γᵢ.
      P Γᵢ (inᵢ -Γᵢ (fimapᵢ -im -c fr)).
inductionᵢ : ∀ P: (Π Γᵢ. Π d: Fixᵢ Γᵢ. ★). PrfAlgᵢ ·P ➔ ∀ Γᵢ. Π d: Fixᵢ Γᵢ. P Γᵢ d
  = <..>
\end{verbatim}

The first three definitions give \verb;Fixᵢ; as the (least) fixed-point of
\verb;Fᵢ;, with \verb;inᵢ; and \verb;outᵢ; representing resp. a generic set of
constructors and destructors. \verb;inductionᵢ; of course is the proof-principle
stating that if one can provide a \verb;PrfAlg; for property \verb;P; (that is,
\verb;P; holds for all \verb;Fixᵢ; generated by (generic) constructor
\verb;inᵢ;) then this suffices to show that \verb;P; holds for \textit{all}
\verb;Fixᵢ;.

We now explain the definition of \verb;PrfAlgᵢ; in more detail:
\begin{itemize}
  \item \verb;R; is the type of recursive occurrences of the data-type
    \verb;Fixᵢ;.

    It corresponds directly to types like \verb;rec/Nat; when using
    \verb;μ; in Cedilleum
  \item \verb;c; is a ``revealer'', that is to say a proof that \verb;R; really
    \textit{is} \verb;Fixᵢ; witnessed by an identity function.

    It corresponds directly to functions like \verb;rec/cast; when using \verb;μ;
  \item \verb;v; is evidence that the (generic) destructor \verb;outᵢ; can be
    used on the recursive occurrence type \verb;R; for further pattern-matching.

    It corresponds directly to \verb;μ'; (when used outside of \verb;μ; it
    corresponds to the ``trivial'' view that \verb;outᵢ; has the type it is
    already declared to have).

  \item \verb;ih; is the inductive hypothesis, stating that property \verb;P;
    holds for all recursive occurrences \verb;R; of an inductive case

    It corresponds directly to the \verb;μ;-bound variable for fix-point recursion.
  \item \verb;fr; represents the collection of constructors that each \verb;μ;
    branch must account for.

    For example, for the data-type \verb;Nat; we have identity mapping
    \verb;fr: ∀ X: ★. X ➔ (R ➔ X) ➔ X; and Cedilleum cases branches
    \verb;{| zero ➔ zcase | succ r ➔ scase r }; translate to
    \verb;fr zcase (λ r. scase r);

  \item Finally, result type \verb;P Γᵢ (inᵢ -Γᵢ (fimapᵢ -im -c fr)); accounts
    for the return type of each case branch.

    Since \verb;P; is phrased over \verb;Fixᵢ;, and we have by assumption
    \verb;fr: Fᵢ ·R Γᵢ;, we must first use our identity mapping \verb;im; to
    traverse \verb;fr; and cast each recursive occurrence \verb;R Γᵢ; to
    \verb;Fixᵢ Γᵢ;, producing an expression of type \verb;F ·Fixᵢ Γᵢ; which we are
    then able to transform into \verb;Fixᵢ Γᵢ; using (generic) constructor \verb;inᵢ;.
\end{itemize}

While the definitions of \verb;inᵢ;, \verb;outᵢ;, and \verb;inductionᵢ; are
omitted, it is important that they have the following computational behavior
(guaranteed by [TODO]):
\begin{verbatim}
lambek1ᵢ : ∀ Γᵢ. Π gr: Fᵢ Fixᵢ Γᵢ. {outᵢ (inᵢ gr) ≃ gr} = β.
lambek2ᵢ : ∀ Γᵢ. Π d: Fixᵢ Γᵢ. {in (out d) ≃ d}
  = inductionᵢ ·(λ Γᵢ. λ x: Fixᵢ Γᵢ. {in (out x) ≃ x})
     (Λ R. Λ c. λ o. Λ eq. λ ih. λ gr. β).

inductionCancelᵢ : ∀ P: (Π Γᵢ. Fixᵢ Γᵢ ➔ ★).
    Π alg: PrfAlg ·P ➔ ∀ Γᵢ. Π fr: F ·Fixᵢ Γᵢ.
    { inductionᵢ alg (in gr) ≃ alg outᵢ (inductionᵢ alg) fr}
  = λ _. λ _. β.
\end{verbatim}
That is, \verb;inᵢ; and \verb;outᵢ; are inverses of each other and
\verb;inductionᵢ; behaves like a fold (where the algebra takes the additional
\verb;outᵢ; argument).

\subsection{Sum-of-Products Induction}
As stated above, every inductive data-type declaration
$\indast{I}{p}{Γ_I}{\Sigma}$ is first translated to a type-scheme \verb;IF;
where all recursive occurrences of type \verb;I; in the constructor signatures
$\Sigma$ have been replaced by the scheme's argument \verb;R;. In this
subsection describe that process more precisely and explain ``sum-of-products''
induction for \verb;IF;

First, as the kind of \verb;I; is \verb;Π Γₚ. Π Γᵢ. ★;, where \verb;Γₚ; are the
parameters and \verb;Γᵢ; the indices, it follows that the kind of \verb;IF; is
\verb;Π Γₚ. Π R: (Π Γᵢ. ★). (Π Γᵢ. ★);. Next, each constructor $c_j$ has type
$\Sigma(c_j)$ which we know has the form $\piforall\ \Gamma_j.\ I\ \Gamma_p\
\vars{t_j}$ (that is, some number of arguments $\Gamma_j$ with a return type
constructing the inductive data-type $I$). All recursive occurrences of $I$ in
$\Gamma_j$ are substituted away with \verb;λ Γₚ. R; to produce $Γ^R_j$. With
that, we may defined \verb;IF; as

\[ λ\ Γₚ\ \texttt{R}\ Γᵢ.\ ∀ X: Π\ Γᵢ. ★. (Π\ c_j: (\piforall Γ^R_j.\ X\
  \vars{t_j}))_{j=1..n}.\ X\ Γᵢ\]

\paragraph{Example}

The data-type declaration of \verb;Vec; translates to:
\begin{verbatim}
VecF : Π A: ★. (Nat ➔ ★) ➔ Nat ➔ ★
  = λ A R n. ∀ X: Nat ➔ ★. X zero ➔ (∀ n: Nat. A ➔ R n ➔ X (succ n)) ➔ X n.
\end{verbatim}

An induction principle for each of these non-recursive sum-of-products types
\verb;IF; can be defined in an automated way following the recipe given by
[TODO]; in general these have the following shape:

\begin{verbatim}
indIF : ∀ Γₚ. ∀ R: (Π Γᵢ. ★). ∀ Γᵢ. Π fr: IF Γₚ ·R Γᵢ. ∀ P: (Π Γᵢ. IF Γₚ ·R Γᵢ ➔ ★)
    (Π pⱼ: Ψ Γᴿⱼ. P (cⱼ Γᴿⱼ))ⱼ₌₁⋯ₙ. P Γᵢ fr = <..>
\end{verbatim}

\appendix
\section{Deriving \texttt{IdMappingᵢ} for a Data-type Type Scheme}
A type scheme \verb;F; derived from a data-type declaration has by assumption a
definition following the pattern:

\begin{verbatim}
F : Π Γₚ. (Π Γᵢ. ★) → Π Γᵢ. ★
  = λ Γₚ R Γᵢ. ∀ X: (Π Γᵢ. ★). (Π cⱼ: (Ψ Γᴿⱼ. X ₸ⱼ))ⱼ₌₁₋ₙ. X Γᵢ
\end{verbatim}

\noindent where \verb;R; occurs only positively. From this we must give a
witness that \verb;F; is an identity mapping over \verb;R;

\begin{verbatim}
idmap : ∀ Γₚ. IdMappingᵢ ·(F Γₚ)
  = Λ Γₚ. Λ R1. Λ R2. Λ id. ●
\end{verbatim}

\noindent where the expected type of \verb;●; is \verb;Idᵢ ·(F ·Γₚ R1) ·(F ·Γ R2);

We refine \verb;●; by the introduction rule for intersections (which \verb;Idᵢ; is) and
introduce the assumption \verb;fr1: F ·Γₚ R1 ·Γᵢ;

\begin{verbatim}
[ Λ Γᵢ. λ fr1. ●₁ , ●₂]
\end{verbatim}

\noindent where \verb;●₁: F ·Γₚ R2 ·Γᵢ; and \verb;●₂: {λ fr1. ●₁ ≃ λ x. x};. As
the only (non-hole) refinements we will make to \verb;●₁; are converting terms to $\eta$-long
form and applying \verb;elimIdᵢ -id; to subterms (which reduces to the identity
function), we are justified in replacing \verb;●₂; with \verb;β;. We now refine
the remaining \verb;●₁; to

\begin{verbatim}
Λ X. λ ş. ● fr1 ş
\end{verbatim}

\noindent where each abstract constructor \texttt{cⱼ} in ş has type
\verb;Ψ Γᴿ²ⱼ. X ₸ⱼ;. Note again the superscript \verb;R2; -- we are now trying
to construct a term of type \verb;F ·Γₚ R2 ·Γᵢ; so we assume the ``abstract''
constructors whose recursive occurence types are \verb;R2;. Correspondingly,
this means that \verb;●: F ·Γₚ R1 ·Γᵢ → (Π cⱼ: (Ψ Γᴿ²ⱼ. X ₸ⱼ))ⱼ₌₁₋ₙ → X Γᵢ;.

Since \verb;fr1; produces a value of type \verb;X Γᵢ; when fed appropriate
arguments, we refine \verb;●; by $n$ holes \verb;●ⱼ; applied to constructor
\verb;cⱼ;. The expression \verb;● fr1 ş; becomes

\begin{verbatim}
fr1 (●ⱼ cⱼ)ⱼ₌₁₋ₙ
\end{verbatim}

\noindent where now \verb;●ⱼ: (Ψ Γᴿ²ⱼ. X ₸ⱼ) → Ψ Γᴿ¹ⱼ. X ₸ⱼ;. We henceforth
dispense with the subscript $j$ numbering the constructor and treat each
abstract constructor uniformly.

\subsection{Conversion of the Abstract constructors}
We first make the expression \verb;● c; $\eta$-long, as in \verb;ψ Γᴿ¹. ● c Γᴿ¹;,
then refine \verb;● c Γᴿ¹; to an expression with $m$ holes \verb;●ₖ; for each $\texttt{y}_k \in
Γ^{\texttt{R1}}$ (where $m\ =\ \lenc{Γ^{\texttt{R1}}}$), yielding

\begin{verbatim}
c (●ₖ yₖ)ₖ₌₁₋ₘ
\end{verbatim}

\noindent where \verb;●ₖ: Γᴿ¹(yₖ) → Γᴿ²ₖ(yₖ); (and the type of \verb;yₖ;
and \verb;●ₖ yₖ; can depend resp. on any \verb;yᴿ¹ⱼ; and \verb;●ⱼ yⱼ; where
$j < k$). We now dispense with the subscript $k$ for arguments and handle each
constructor sub-data uniformly.

\subsection{Conversion of Constructor Sub-data With Positive Recursive Occurences}
\label{ssec:positive}
We now consider \verb;● y; where \verb;y: S; is some sub-data to an
(abstract) constructor with recursive occurence type \verb;R1; passing the
positivity checker. (The expression \verb;● y; has type \verb;[R2/R1]S;).
There are two cases to consider:

\begin{itemize}
\item[1] \verb;R1; does not occur in the type of \verb;y;

  Refine \verb;●; to \verb;unit: ∀ X: ★. X → X = Λ X. λ x. x; and finish.
\item[2] \verb;R1; occurs positively in the type of \verb;y;

  This means $S$ has the shape \verb;Ψ Γᴿ¹ₓ. T; (where \verb;T; is not formed by
  an arrow) with \verb;R1;
  occurring \textit{only negatively} in the type of the
  $\texttt{xⱼ} \in Γ^{R1}_x$ (where $j=1..\lenc{Γ^{R1}ₓ}$). Make \verb;● y;
  $\eta$-long and refine the expression to $\lenc{Γ^{R1}ₓ}$ holes \verb;●ⱼ; such
  that the expression is now
  
\begin{verbatim}
ψ Γᴿ²ₓ. ● y (●ⱼ xⱼ)ⱼ₌₁₋ₙ
\end{verbatim}

  \noindent Where here \verb;xⱼ; is bound by \verb;Γᴿ²; and thus has negative occurences
  of \verb;R2;. Note that we still require \verb;●; since it might be the case that
  \verb;T = R1 Γᵢ; (handled below); it has type \verb;S → Ψ Γᴿ¹ₓ. [R1/R2]T;.
  Each \verb;●ⱼ; has type \verb;Γᴿ²ₓ(xⱼ) → Γᴿ¹ₓ(xⱼ);.

  Perform the steps outlined in Section \ref{ssec:negative} to fill in each
  \verb;●ⱼ; producing from \verb;●ⱼ xⱼ; the sequence of arguments \verb;₸ⱼ; of
  type \verb;Γᴿ¹ₓ; that erase to \verb;xⱼ₌₁₋ₙ; Finally, refine \verb;●; to either \verb;unit; or
  \verb;λ y. λ xⱼ. elimId -c (y xⱼ); depending on whether \verb;T = R1 Γᵢ;

\end{itemize}

\subsection{Conversion of Constructor Sub-data With Negative Recursive
  Occurences}
\label{ssec:negative}
We consider \verb;● x; where \verb;x: Ψ Γᴿ²ᵤ. S;, \verb;S; is not an arrow
and does not contain \verb;R2;, and \verb;R2; occurs positively in the types of
the variables bound by \verb;Γᴿ²ᵤ;. The expression \verb;● x; has type
\verb;Ψ Γᴿ¹ᵤ. S;.

Make \verb;● x; $\eta$-long and introduce holes \verb;●ⱼ; to apply to the
sub-data as in

\begin{verbatim}
ψ Γᴿ¹ᵤ. x (●ⱼ yⱼ)ⱼ₌₁₋ₙ
\end{verbatim}

\noindent where \verb;●ⱼ: Γᴿ¹ᵤ(yⱼ) → Γᴿ²ᵤ(yⱼ);. Perform the steps outlined by
Section \ref{ssec:positive} to fill in each \verb;●ⱼ; producing from
\verb;●ⱼ yⱼ; the sequence of arguments \verb;₸; that erase to \verb;yⱼ₌₁₋ₙ;.


\bibliographystyle{alpha}
\bibliography{spec}

\end{document}
